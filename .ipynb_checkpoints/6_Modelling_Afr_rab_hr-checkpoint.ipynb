{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311f870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agrid.grid import Grid\n",
    "from pathlib import Path\n",
    "import os, sys, pickle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "\n",
    "from scipy import stats, interpolate, spatial, io\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Arc \n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import pyproj as proj\n",
    "import rasterio\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numba as nb\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# helper function for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer , r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import gstools as gst\n",
    "from pykrige.rk import RegressionKriging\n",
    "import operator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pykrige.rk import Krige\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from skgstat import Variogram\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder , PowerTransformer\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor ,  ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constanst\n",
    "\n",
    "#parent directory\n",
    "\n",
    "dir_p = Path().resolve() \n",
    "\n",
    "#constants\n",
    "km = 1000\n",
    "milli = 0.001\n",
    "micro = 0.000001\n",
    "\n",
    "src_crs=4326\n",
    "\n",
    "# We can exclude Arctic ocean and Antarctica, as there are no HF measurements to use\n",
    "world_lon_min, world_lon_max, world_lat_min, world_lat_max  = -180, 180, -60, 80\n",
    "\n",
    "# map extents of Africa and Australia\n",
    "afr_lon_min, afr_lon_max, afr_lat_min, afr_lat_max =  -20, 52, -37 , 38  \n",
    "\n",
    "\n",
    "# create grid for each region\n",
    "# crs Coordinate reference system\n",
    "\n",
    "#EPSG is projection\n",
    "# 0.2 degrees equal roughly 20 km\n",
    "\n",
    "World = Grid(res=[0.2, 0.2], up=world_lat_max, down=world_lat_min)\n",
    "\n",
    "\n",
    "# africa grid low resolution 50 x 50 km\n",
    "\n",
    "Africa =    Grid(res=[0.5, 0.5],  left = afr_lon_min, right= afr_lon_max, up=afr_lat_max , down=afr_lat_min)\n",
    "\n",
    "\n",
    "#dictionary of all grids\n",
    "\n",
    "grids = {}\n",
    "\n",
    "grids['Afr'] = Africa\n",
    "grids['World'] = World\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215924c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SeabornFig2Grid():\n",
    "\n",
    "    def __init__(self, seaborngrid, fig,  subplot_spec):\n",
    "        self.fig = fig\n",
    "        self.sg = seaborngrid\n",
    "        self.subplot = subplot_spec\n",
    "        if isinstance(self.sg, sns.axisgrid.FacetGrid) or \\\n",
    "            isinstance(self.sg, sns.axisgrid.PairGrid):\n",
    "            self._movegrid()\n",
    "        elif isinstance(self.sg, sns.axisgrid.JointGrid):\n",
    "            self._movejointgrid()\n",
    "        self._finalize()\n",
    "\n",
    "    def _movegrid(self):\n",
    "        \"\"\" Move PairGrid or Facetgrid \"\"\"\n",
    "        self._resize()\n",
    "        n = self.sg.axes.shape[0]\n",
    "        m = self.sg.axes.shape[1]\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(n,m, subplot_spec=self.subplot)\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                self._moveaxes(self.sg.axes[i,j], self.subgrid[i,j])\n",
    "\n",
    "    def _movejointgrid(self):\n",
    "        \"\"\" Move Jointgrid \"\"\"\n",
    "        h= self.sg.ax_joint.get_position().height\n",
    "        h2= self.sg.ax_marg_x.get_position().height\n",
    "        r = int(np.round(h/h2))\n",
    "        self._resize()\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(r+1,r+1, subplot_spec=self.subplot)\n",
    "\n",
    "        self._moveaxes(self.sg.ax_joint, self.subgrid[1:, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_x, self.subgrid[0, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_y, self.subgrid[1:, -1])\n",
    "\n",
    "    def _moveaxes(self, ax, gs):\n",
    "        #https://stackoverflow.com/a/46906599/4124317\n",
    "        ax.remove()\n",
    "        ax.figure=self.fig\n",
    "        self.fig.axes.append(ax)\n",
    "        self.fig.add_axes(ax)\n",
    "        ax._subplotspec = gs\n",
    "        ax.set_position(gs.get_position(self.fig))\n",
    "        ax.set_subplotspec(gs)\n",
    "\n",
    "    def _finalize(self):\n",
    "        plt.close(self.sg.fig)\n",
    "        self.fig.canvas.mpl_connect(\"resize_event\", self._resize)\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def _resize(self, evt=None):\n",
    "        self.sg.fig.set_size_inches(self.fig.get_size_inches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5077a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ease looping with dictionaries\n",
    "\n",
    "regions_a = [ 'Afr' ]\n",
    "\n",
    "\n",
    "regions_Total = ['World' ,'Afr']\n",
    "\n",
    "\n",
    "# raster exenets to adjust map\n",
    "raster_extent_Afr = [grids['Afr'].extent[0], grids['Afr'].extent[1], grids['Afr'].extent[3], grids['Afr'].extent[2]]\n",
    "raster_extent_World = [grids['World'].extent[0], grids['World'].extent[1], grids['World'].extent[3], grids['World'].extent[2]]\n",
    "\n",
    "# to correct plot maps\n",
    "raster_extents = {}\n",
    "\n",
    "raster_extents['Afr'] = raster_extent_Afr\n",
    "raster_extents['World'] = raster_extent_World\n",
    "\n",
    "\n",
    "# list of latitudes and longitudes\n",
    "lon_dict = {}\n",
    "lat_dict = {}\n",
    "\n",
    "lon_dict['Afr'] = [afr_lon_min, afr_lon_max]\n",
    "lon_dict['World'] = [world_lon_min, world_lon_max]\n",
    "\n",
    "lat_dict['Afr'] = [afr_lat_min, afr_lat_max]\n",
    "lat_dict['World'] = [world_lat_min, world_lat_max]\n",
    "\n",
    "\n",
    "\n",
    "print('terminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfba527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance_correlation_coefficient(y_true, y_pred):\n",
    "    \"\"\"Concordance correlation coefficient.\"\"\"\n",
    "    \n",
    "    y_true = y_true.reshape(-1,)\n",
    "    y_pred = y_pred.reshape(-1,)\n",
    "    # Remove NaNs\n",
    "    df = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "    df = df.dropna()\n",
    "    y_true = df['y_true']\n",
    "    y_pred = df['y_pred']\n",
    "    # Pearson product-moment correlation coefficients\n",
    "    cor = np.corrcoef(y_true, y_pred)[0][1]\n",
    "    # Mean\n",
    "    mean_true = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    # Variance\n",
    "    var_true = np.var(y_true)\n",
    "    var_pred = np.var(y_pred)\n",
    "    # Standard deviation\n",
    "    sd_true = np.std(y_true)\n",
    "    sd_pred = np.std(y_pred)\n",
    "    # Calculate CCC\n",
    "    numerator = 2 * cor * sd_true * sd_pred\n",
    "    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pd.DataFrame()\n",
    "\n",
    "\n",
    "''' \n",
    "obs['REF_n'] = [ 'MOHO','LAB', 'RHO_C', 'SV', 'PV', 'CTD',\n",
    "             'RHO_L', 'DEM', \n",
    "                'VOLC_DIST_W', 'A_MEDIAN_W', 'FA', 'SI','LITH_MANTLE', \n",
    "                'EMAG2_CLASS', 'GEOID', 'BG',\n",
    "              'GLIM']'''\n",
    "\n",
    "\n",
    "\n",
    "obs['OBS_REF'] = ['CTD' ,  'SI',\"LAB\", \"MOHO\",\n",
    "            \"SV\",\"PV\", \n",
    "            'GEOID','FA','DEM','BG', 'EMAG2_CLASS',\n",
    "                   'RHO_L', 'RHO_C', \n",
    "                  'VOLC_DIST_W', 'REG', 'GLIM']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "     \n",
    "# Labels for plots etc\n",
    "obs['LABELS'] = ['CTD',  'Shape index', 'LAB depth', 'Moho depth', \n",
    "                'S$_V$ 150km', 'P$_V$ 150km', \n",
    "                'Geoid', 'Free air', 'DEM', 'Bouguer', 'Mag.', \n",
    "                'Lith. ρ', 'Crust ρ',  \n",
    "                 'Volcano d.', 'GliM', 'REG', ]  \n",
    "    \n",
    "    \n",
    "# 'vp/vs'\n",
    "# Units to display in plots etc\n",
    "obs['UNITS'] = ['km',  'si', 'km', 'km',\n",
    "             '$\\delta$ v_s %','$\\delta$ v_p %', \n",
    "             'm', 'mGal', 'm', 'mGal',  'f(nT)', \n",
    "                 'kg/m$^3$', 'kg/m$^3$',\n",
    "                'km',  'class', 'class']\n",
    "        \n",
    "# Range of colormap for plots. Similar data are placed in same ranges for consistancy\n",
    "obs['V_RANGE'] = [(0,50), (-1,1),(0,300),(15,60),\n",
    "              (-0.075,0.075), (-0.02,0.02), \n",
    "              (-45,45), (-100,100) , (-2200, 2200),(-250,100),  (-0.4, 0.4), \n",
    "                   (3260, 3360), (2650, 2950),\n",
    "                  (0,1), (1,6),(1,15),]\n",
    "    \n",
    "obs[\"CMAPS\"] = [\"batlow\",  \"broc\", \"bamako\", \"batlow\", \n",
    "             \"roma\",\"roma\", \n",
    "             \"bamako\", \"broc\", \"bukavu\", \"broc\", \"batlow\",            \n",
    "                \"batlow\", \"batlow\",\n",
    "               \"bamako\",  \"batlowS\",\"topo\", ]\n",
    "\n",
    "#new_index = [4,3,15,6,7,0,14,10,16,17,9, 2,1,5,13,12, 8,11,]\n",
    "\n",
    "#new_index = [4,3,15,6,7,0, 14, 10,16, 8, 9,2, 13, 12, 8, 11, ]\n",
    "\n",
    "#obs = obs.reindex(new_index)\n",
    "\n",
    "obs.index = np.arange(0,len(obs))\n",
    "\n",
    "pd.options.display.width = 370\n",
    "pd.options.display.max_colwidth = 12\n",
    "print(obs)\n",
    "\n",
    "n_obs = len(obs)\n",
    "\n",
    "obs_dict = obs.to_dict(orient='records')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52e68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_afr = xr.load_dataset(dir_p/'Grids'/'inputs'/\"ds_afr.nc\")\n",
    "ds_world = xr.load_dataset(dir_p/'Grids'/'inputs'/\"ds_world.nc\")\n",
    "\n",
    "ds_afr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c78ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "region = 'Afr'\n",
    "files = [filename for filename in os.listdir(dir_p/'Grids'/'inputs') if filename.startswith(f\"{region}\")]\n",
    "labels = [ filename.replace(f'{region}_', '').replace('.nc', '')  for filename in files]\n",
    "for label, file in zip(labels,files):\n",
    "    path = dir_p/'Grids'/'inputs'/f'{file}'\n",
    "    grids[region].ds[f'{label}'] = (('Y', 'X'), grids[region].read_raster(path , src_crs=src_crs))\n",
    "\n",
    "\n",
    "print('terminated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d31693",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'heat-flow (mW/m2)'\n",
    "coord = ['lon', 'lat']\n",
    "grid_index = ['grid_index']\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "features_ex = []\n",
    "features_ghf = []\n",
    "\n",
    "\n",
    "\n",
    "features = obs['OBS_REF'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "in_features = set(features)\n",
    "\n",
    "features_ex = copy.deepcopy(features)\n",
    "features_ex.extend(coord)\n",
    "features_ex.extend(grid_index)\n",
    "\n",
    "features_ex.append(target)\n",
    "\n",
    "features_ghf = copy.deepcopy(features)\n",
    "features_ghf.append(target)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0e3ef",
   "metadata": {},
   "source": [
    "# best fit world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rating = 'rab'\n",
    "outlier = 'OD'\n",
    "\n",
    "\n",
    "file_label = f'{outlier}_{rating}'\n",
    "\n",
    "train_w_f =  dir_p/'data'/'dataset'/'Preprocessed'/f'Training_W_{file_label}.csv'\n",
    "train_W = pd.read_csv(train_w_f, sep='\\t')\n",
    "\n",
    "train_Afr_f =  dir_p/'data'/'dataset'/'Preprocessed'/f'Training_Afr_{file_label}.csv'\n",
    "train_Afr = pd.read_csv(train_Afr_f,  sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "training_Afr_ra_f =  dir_p/'data'/'dataset'/'Preprocessed'/f'Training_Afr_ra_int.csv'\n",
    "training_Afr_ra = pd.read_csv(training_Afr_f)\n",
    "\n",
    "training_Afr_rab_f =  dir_p/'data'/'dataset'/'Preprocessed'/'Training_Afr_rab_int.csv'\n",
    "training_Afr_rab = pd.read_csv(training_Afr_rab_f)\n",
    "\n",
    "train_W['GLIM']  = train_W['GLIM'].astype('category')\n",
    "train_W['REG']  = train_W['REG'].astype('category')\n",
    "\n",
    "train_Afr['GLIM']  = train_Afr['GLIM'].astype('int').astype('category')\n",
    "train_Afr['REG']  = train_Afr['REG'].astype('int').astype('category')\n",
    "\n",
    "\n",
    "X_train_w = train_W[features]\n",
    "y_train_w = train_W[target].values.reshape(-1,1) \n",
    "\n",
    "X_train_afr = train_Afr[features]\n",
    "y_train_afr = train_Afr[target].values.reshape(-1,1) \n",
    "\n",
    "\n",
    "\n",
    "X_train_w.describe(include='all')\n",
    "\n",
    "X_train_afr.describe(include='all')\n",
    "\n",
    "\n",
    "bs_rfr_hyp =  dir_p/'Hyperparameters'/f'RFR_{file_label}.csv'\n",
    "\n",
    "\n",
    "\n",
    "bs_rfr_hyp_df = pd.read_csv(bs_rfr_hyp, sep='\\t')\n",
    "\n",
    "\n",
    "best_params = bs_rfr_hyp_df.to_dict('list')\n",
    "\n",
    "print(file_label)\n",
    "\n",
    "X_train_afr.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429523d6",
   "metadata": {},
   "source": [
    "# Pre-evalaution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 10 \n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "KPI_Afr_50 = pd.DataFrame()\n",
    "results_W = pd.DataFrame()\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) * -1\n",
    "\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for best_features in range(8,16):  \n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "\n",
    "    rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe),   (\"regressor\", regressor)]\n",
    "\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "\n",
    "\n",
    "\n",
    "    model_pipeline.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "    \n",
    "    y_predict = model_pipeline.predict(X_train_afr)\n",
    "    \n",
    "\n",
    "    KPI_Afr_50.loc['NRMSE', f'RFE_{best_features}'] = nrmse(y_train_afr, y_predict) *-1\n",
    "    KPI_Afr_50.loc['RMSE', f'RFE_{best_features}'] =mean_squared_error(y_train_afr, y_predict, squared=False) \n",
    "    KPI_Afr_50.loc['MAE', f'RFE_{best_features}'] = mean_absolute_error(y_train_afr, y_predict)  \n",
    "    KPI_Afr_50.loc['MAPE', f'RFE_{best_features}'] = mean_absolute_percentage_error(y_train_afr, y_predict) \n",
    "    KPI_Afr_50.loc['CD', f'RFE_{best_features}'] = r2_score(y_train_afr, y_predict)\n",
    "    KPI_Afr_50.loc['EV', f'RFE_{best_features}'] = explained_variance_score(y_train_afr, y_predict)\n",
    "    KPI_Afr_50.loc['CCC', f'RFE_{best_features}'] = concordance_correlation_coefficient(y_train_afr, y_predict)\n",
    "    KPI_Afr_50.loc['MAX', f'RFE_{best_features}'] = y_predict.max()\n",
    "    KPI_Afr_50.loc['MIN', f'RFE_{best_features}'] = y_predict.min()\n",
    "    \n",
    "    KPI_Afr_50.loc['MAX_E',  f'RFE_{best_features}'] = round( max_error(y_train_afr, y_predict), 3)\n",
    "    KPI_Afr_50.loc['MedAE',  f'RFE_{best_features}'] = round( median_absolute_error(y_train_afr, y_predict), 3) \n",
    "    KPI_Afr_50.loc['MPE',  f'RFE_{best_features}'] = round(np.mean((y_train_afr -y_predict)/y_train_afr) , 3)\n",
    "    KPI_Afr_50.loc['ACC',  f'RFE_{best_features}'] = round(100 - mean_absolute_percentage_error(y_train_afr, y_predict) *100, 3)\n",
    "    KPI_Afr_50.loc['Mean',  f'RFE_{best_features}'] = round(np.mean(y_predict),3)\n",
    "    KPI_Afr_50.loc['Median',  f'RFE_{best_features}'] = round(np.median(y_predict),3)\n",
    "    KPI_Afr_50.loc['Stdev',  f'RFE_{best_features}'] = round(np.std(y_predict),3)\n",
    "    KPI_Afr_50.loc['RSD',  f'RFE_{best_features}'] = round(np.std(y_predict) / np.mean(y_predict) ,3)\n",
    "    \n",
    "       \n",
    "  \n",
    "\n",
    "    \n",
    "    results_W[f'RFE_{best_features}'] =y_predict.reshape(-1,)\n",
    "    # Print message to user\n",
    "    print('#'*60)\n",
    "\n",
    "\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "\n",
    "scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "numeric_transformer = scaler\n",
    "\n",
    "categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "   (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe), (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "# Initialize Pipeline object\n",
    "pipeline= Pipeline(steps = steps)\n",
    "\n",
    "model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "\n",
    "model_pipeline.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "\n",
    "y_predict = model_pipeline.predict(X_train_afr)\n",
    "\n",
    "\n",
    "KPI_Afr_50.loc['NRMSE', f'RFE_{best_features}'] = nrmse(y_train_afr, y_predict) *-1\n",
    "KPI_Afr_50.loc['RMSE', f'RFE_{best_features}'] =mean_squared_error(y_train_afr, y_predict, squared=False) \n",
    "KPI_Afr_50.loc['MAE', f'RFE_{best_features}'] = mean_absolute_error(y_train_afr, y_predict)  \n",
    "KPI_Afr_50.loc['MAPE', f'RFE_{best_features}'] = mean_absolute_percentage_error(y_train_afr, y_predict) \n",
    "KPI_Afr_50.loc['CD', f'RFE_{best_features}'] = r2_score(y_train_afr, y_predict)\n",
    "KPI_Afr_50.loc['EV', f'RFE_{best_features}'] = explained_variance_score(y_train_afr, y_predict)\n",
    "KPI_Afr_50.loc['CCC', f'RFE_{best_features}'] = concordance_correlation_coefficient(y_train_afr, y_predict)\n",
    "KPI_Afr_50.loc['MAX', f'RFE_{best_features}'] = y_predict.max()\n",
    "KPI_Afr_50.loc['MIN', f'RFE_{best_features}'] = y_predict.min()\n",
    "\n",
    "KPI_Afr_50.loc['MAX_E',  f'RFE_{best_features}'] = round( max_error(y_train_afr, y_predict), 3)\n",
    "KPI_Afr_50.loc['MedAE',  f'RFE_{best_features}'] = round( median_absolute_error(y_train_afr, y_predict), 3) \n",
    "KPI_Afr_50.loc['MPE',  f'RFE_{best_features}'] = round(np.mean((y_train_afr -y_predict)/y_train_afr) , 3)\n",
    "KPI_Afr_50.loc['ACC',  f'RFE_{best_features}'] = round(100 - mean_absolute_percentage_error(y_train_afr, y_predict) *100, 3)\n",
    "KPI_Afr_50.loc['Mean',  f'RFE_{best_features}'] = round(np.mean(y_predict),3)\n",
    "KPI_Afr_50.loc['Median',  f'RFE_{best_features}'] = round(np.median(y_predict),3)\n",
    "KPI_Afr_50.loc['Stdev',  f'RFE_{best_features}'] = round(np.std(y_predict),3)\n",
    "KPI_Afr_50.loc['RSD',  f'RFE_{best_features}'] = round(np.std(y_predict) / np.mean(y_predict) ,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_W[f'RFE_{best_features}'] =y_predict.reshape(-1,)\n",
    "# Print message to user\n",
    "print('#'*60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbd077",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "\n",
    "# Set figure size and create barplot\n",
    "\n",
    "fig, axs = plt.subplots(8,2,figsize=(15, 40))\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 2)\n",
    "#fig.set_size_inches(30,30)\n",
    "\n",
    "#scores = ['RMSE', 'NRMSE','MAE', 'MAPE', 'CD','EV', 'MAX_E','MIN_E' ,'MedAE', 'MPE']\n",
    "\n",
    "scores = ['RMSE', 'MAE', 'NRMSE','MAPE', 'CD','EV', 'MAX_E', 'MAX', \n",
    "          'Stdev', 'RSD', 'Mean','Median','MedAE', 'MPE', 'ACC', 'CCC']\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 2)\n",
    "n_models = 30\n",
    "#subfile = 'HOD'\n",
    "#files_rg = [ x for x in files_rg if subfile in x ]\n",
    "for score, ax in zip(scores, axs.flatten()):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    cols  = KPI_Afr_50.loc[score,:].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "\n",
    "    if score in ['CD','EV' ,'MAX', 'MPE', 'ACC','CCC']:\n",
    "        \n",
    "        \n",
    "        x_data = KPI_Afr_50.loc[score,cols].sort_values(ascending=False).index\n",
    "        y_data = KPI_Afr_50.loc[score,cols].sort_values(ascending=False).round(2)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0])\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        x_data = KPI_Afr_50.loc[score,cols].sort_values().index\n",
    "        y_data = KPI_Afr_50.loc[score,cols].sort_values().round(2)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0], )\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f778c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ['RMSE', 'MAE', 'NRMSE','MAPE', 'CD','EV', 'MAX_E', 'MAX', 'Stdev', 'RSD', 'Mean','Median','MedAE', 'MPE', 'Acc']\n",
    "# False ['CD','EV' ,'MAX', 'MPE']\n",
    "\n",
    "#len(KPI_Afr_50)\n",
    "n_models = 10\n",
    "\n",
    "rfe_range = [col for col in KPI_Afr_50.columns]\n",
    "\n",
    "score = 'NRMSE'\n",
    "columns_W = KPI_Afr_50.loc[score,rfe_range].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "results_W['y_train_afr'] = y_train_afr\n",
    "\n",
    "threshold = 20\n",
    "\n",
    "for column in columns_W[:n_models]:\n",
    "    mask = np.abs(results_W['y_train_afr'] - results_W[column]) > threshold\n",
    "    y_predict = results_W[column]\n",
    "    \n",
    "    g0 =sns.jointplot( x=column, y='y_train_afr', data=results_W, kind='reg', size=12,   ratio=4, \n",
    "                        marginal_kws={'lw':1, 'color':'blue'}, \n",
    "                  scatter_kws={\"color\": \"grey\", \"edgecolor\":\"w\"}, line_kws={\"color\": \"blue\"},\n",
    "    label=   \n",
    "    f'''\n",
    "    best fit\n",
    "    {column}\n",
    "    RMSE     = {round(KPI_Afr_50.loc['RMSE', column],2)}\n",
    "    NRMSE    = {round(KPI_Afr_50.loc['NRMSE', column],2)} %\n",
    "    MAE      = {round(KPI_Afr_50.loc['MAE', column],2)}\n",
    "    MAPE     = {round(KPI_Afr_50.loc['MAPE', column],2)} %\n",
    "    MAX       = {round(KPI_Afr_50.loc['MAX', column],2)}\n",
    "    RSD       = {round(KPI_Afr_50.loc['RSD', column],2)}\n",
    "    $R^2$    = {round(KPI_Afr_50.loc['CD', column],2)}\n",
    "    Total count    : {len(y_predict) - len(y_predict[mask])}   \n",
    "        ''' )\n",
    "\n",
    "    sns.regplot([results_W[column].min(), results_W[column].max()], [results_W['y_train_afr'].min(), results_W['y_train_afr'].max()], \\\n",
    "                ci=None, scatter=False, ax= g0.ax_joint, line_kws={\"color\": \"grey\", 'ls':'--'} , label = 'Identity')\n",
    "\n",
    "    sns.scatterplot(results_W[column][mask],results_W['y_train_afr'][mask], color=\"#ce1414\",\\\n",
    "                    s=30,  ax= g0.ax_joint, edgecolor=\"white\",\n",
    "    label = \n",
    "    f'''Error > {threshold}    = {len(y_predict[mask])}\n",
    "    Realtive error       = {round(len(y_predict[mask]) / len(y_predict), 1)  *100} %\n",
    "\n",
    "    ''' )\n",
    "\n",
    "    g0.set_axis_labels( '$\\hat{y}$','$_y$', fontsize=30, fontweight='bold')\n",
    "    g0.fig.suptitle('PREDICTED vs ACTUAL',fontsize=20)\n",
    "\n",
    "    g0.ax_marg_y.grid('on') \n",
    "\n",
    "    #plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    #####\n",
    "    \n",
    "    g1 = sns.jointplot( x=column, y='y_train_afr', data=results_W, kind=\"resid\", size=12, \n",
    "                         line_kws={\"color\": \"blue\", 'lowess':True, 'robust':True},     \n",
    "                         )\n",
    "\n",
    "\n",
    "    #plot.ax_joint.axvline(x=6)\n",
    "    g1.ax_joint.axhline(y=threshold )\n",
    "    g1.ax_joint.axhline(y=-threshold)\n",
    "\n",
    "\n",
    "    g1.set_axis_labels('$_y$', 'Residuals', fontsize=30, fontweight='bold')\n",
    "    g1.fig.suptitle(column,fontsize=20)\n",
    "\n",
    "    g1.ax_marg_y.grid('on') \n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    fig.set_size_inches(16,9)\n",
    "\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "    mg0 = SeabornFig2Grid(g0, fig, gs[0])\n",
    "    mg1 = SeabornFig2Grid(g1, fig, gs[1])\n",
    "\n",
    "    gs.tight_layout(fig)\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112c3d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "kfold = 5\n",
    "\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) \n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "ccc_score = make_scorer(concordance_correlation_coefficient , greater_is_better=True)\n",
    "\n",
    "scoring = {\n",
    "    'NRMSE':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    'CD':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'CCC': ccc_score,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "results ={}\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize RFECV object\n",
    "    feature_selector = RFECV(regressor, cv = cv, step = 1, #n_jobs=-1, \n",
    "                             scoring = score, verbose = 1)\n",
    "    \n",
    "\n",
    "    # Fit RFECV\n",
    "    feature_selector .fit(X_train_afr, np.ravel(y_train_afr))\n",
    "    results[key] = feature_selector\n",
    "\n",
    "    # Get selected features\n",
    "    #feature_names = X_train_corr.columns\n",
    "    #selected_features = feature_names[feature_selector.support_].tolist()\n",
    "\n",
    "    print(f'terminated {key} {score}\\n')\n",
    "    print('terminated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for key, score in scoring.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X_train_afr.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "    if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "        plt.plot(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1)*-1, label=key)\n",
    "        plt.scatter(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1)*-1, marker='x')\n",
    "\n",
    "    else:\n",
    "        plt.plot(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1), label=key)\n",
    "        plt.scatter(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1), marker='x')\n",
    "        \n",
    "    \n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score\")\n",
    "    plt.legend(loc=[.79,0.26])\n",
    "plt.axvline(results[key].n_features_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6431a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ebd8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "total_features = features\n",
    "\n",
    "feature_names = train_Afr[total_features].columns\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "best_features = 4\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_4 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_4)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "######\n",
    "\n",
    "best_features = 5\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_5 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_5)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "######\n",
    "best_features = 6\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_6 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_6)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "######\n",
    "\n",
    "best_features = 7\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_7 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_7)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "######\n",
    "\n",
    "best_features = 8\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_8 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_8)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "######\n",
    "\n",
    "best_features = 9\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_9 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_9)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "######\n",
    "\n",
    "\n",
    "######\n",
    "\n",
    "best_features = 10\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_10 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_10)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "######\n",
    "\n",
    "best_features = 11\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_11 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_11)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "######\n",
    "\n",
    "best_features = 12\n",
    "\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_12 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_12)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "#####\n",
    "\n",
    "best_features = 13\n",
    "\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_13 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_13)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "######\n",
    "\n",
    "best_features = 14\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_14 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_14)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "best_features = 15\n",
    "\n",
    "\n",
    "\n",
    "feature_selector = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "# Fit RFE\n",
    "feature_selector.fit(X_train_afr, y_train_afr)\n",
    "\n",
    "# Get selected features labels\n",
    "selected_features_15 = feature_names[feature_selector.support_].to_list()\n",
    "\n",
    "print(selected_features_15)\n",
    "\n",
    "print('RFE fitting is terminated')\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8962c92b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline_dict = {}\n",
    "grids_dict = {}\n",
    "selected_features_dict = {}\n",
    "\n",
    "\n",
    "best_features = ['16', '15','14', '13','12', '11','10',\n",
    "                 '09','08', '07','06','05','04'\n",
    "                 ]\n",
    "\n",
    "selected_features = [ total_features,\n",
    "                selected_features_15, selected_features_14,  \n",
    "                      selected_features_13, selected_features_12,\n",
    "                      selected_features_11, selected_features_10, \n",
    "                      selected_features_9, selected_features_8,\n",
    "    selected_features_7, selected_features_6,  \n",
    "    selected_features_5, selected_features_4  \n",
    "         ]\n",
    "\n",
    "scoring = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "\n",
    "kfold =10\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "\n",
    "label = 'AFR' \n",
    "\n",
    "for best_feature, selected_feature in zip(best_features ,selected_features) :\n",
    "\n",
    "    y_Afr = train_Afr[target]\n",
    "    x_Afr = train_Afr[selected_feature]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "    \n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[ (\"preprocessor\", preprocessor),  (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "    \n",
    "    trained_model = model_pipeline.fit(x_Afr, y_Afr )\n",
    "    \n",
    "   \n",
    "\n",
    "    ######### save\n",
    "\n",
    "   \n",
    "    pipeline_dict[f'RFE_{best_feature}'] = trained_model\n",
    "    \n",
    "    grids_dict[f'RFE_{best_feature}'] =  grids[region].ds[selected_feature].to_array().values\n",
    "    \n",
    "    selected_features_dict[f'RFE_{best_feature}']   = selected_feature\n",
    "\n",
    "    print(f'RFE_{best_feature} fitting is terminated' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bdf4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5c48fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xs = range(grids[region].nx)\n",
    "ys = range(grids[region].ny)\n",
    "\n",
    "#key = 'RFE_11'\n",
    "\n",
    "for key, pipeline in pipeline_dict.items():\n",
    "    pipeline = pipeline_dict[key]\n",
    "    AFR_Q_RFR = np.zeros(grids[region].nn) # predicted HF value\n",
    "    AFR_grid = grids_dict[key]\n",
    "    #AFR_grid  = grids[region].ds[selected_feature].to_array().values\n",
    "    print(key)\n",
    "    print(grids_dict[key][0].shape)\n",
    "    for x in xs:\n",
    "        print(x,end='\\n')\n",
    "        #print(y,end=',')\n",
    "        for y in ys:  \n",
    "            #if np.isfinite(grids[region].ds['LAND'][y,x].values):\n",
    "            if np.isfinite(sum(AFR_grid[:,y,x])):\n",
    "\n",
    "                AFR_Q_RFR_df = pd.DataFrame(AFR_grid[:,y,x].reshape(1,-1), \n",
    "                                              columns=selected_features_dict[key])\n",
    "                if 'GLIM' in selected_features_dict[key]:\n",
    "                    AFR_Q_RFR_df['GLIM']  = AFR_Q_RFR_df['GLIM'].astype('int').astype('category')\n",
    "                if 'REG' in selected_features_dict[key]:\n",
    "                    AFR_Q_RFR_df['REG']  = AFR_Q_RFR_df['REG'].astype('int').astype('category')\n",
    "\n",
    "\n",
    "                AFR_Q_RFR[y,x] = pipeline.predict(AFR_Q_RFR_df)\n",
    "\n",
    "\n",
    "\n",
    "    print(f'terminated {key}',end='\\n')\n",
    "\n",
    "    grids[region].ds[f'{key}'] = (('Y', 'X'), AFR_Q_RFR)\n",
    "\n",
    "    grids[region].grid_to_raster(grids[region].ds[f'{key}'], save_name= dir_p/'Grids'/'outputs'/f'{key}_{rating}.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdaadb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
