{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edac9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311f870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os, sys, pickle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "\n",
    "from scipy import stats, interpolate, spatial, io\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Arc \n",
    "\n",
    "\n",
    "import pyproj as proj\n",
    "import rasterio\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numba as nb\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# helper function for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer , r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#import gstools as gst\n",
    "#from pykrige.rk import RegressionKriging\n",
    "#from pykrige.rk import Krige\n",
    "#from skgstat import Variogram\n",
    "\n",
    "\n",
    "import operator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder , PowerTransformer\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor ,  ColumnTransformer\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from time import sleep\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8a8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constanst\n",
    "crs_to='epsg:4326'\n",
    "crs_from='epsg:4326'\n",
    "projection = 'M5.4i'\n",
    "#parent directory\n",
    "\n",
    "DIR = Path().resolve() \n",
    "\n",
    "\n",
    "# We can exclude Arctic ocean and Antarctica, as there are no HF measurements to use\n",
    "world_lon_min, world_lon_max, world_lat_min, world_lat_max  = -180, 180, -60, 80\n",
    "\n",
    "# map extents of Africa and Australia\n",
    "afr_lon_min, afr_lon_max, afr_lat_min, afr_lat_max =  -20, 52, -37 , 38  \n",
    "\n",
    "\n",
    "# create grid for each region\n",
    "# crs Coordinate reference system\n",
    "\n",
    "#EPSG is projection\n",
    "# 0.2 degrees equal roughly 20 km\n",
    "\n",
    "region_afr = [afr_lon_min, afr_lon_max, afr_lat_min, afr_lat_max]\n",
    "region_world = [world_lon_min, world_lon_max, world_lat_min, world_lat_max]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215924c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SeabornFig2Grid():\n",
    "\n",
    "    def __init__(self, seaborngrid, fig,  subplot_spec):\n",
    "        self.fig = fig\n",
    "        self.sg = seaborngrid\n",
    "        self.subplot = subplot_spec\n",
    "        if isinstance(self.sg, sns.axisgrid.FacetGrid) or \\\n",
    "            isinstance(self.sg, sns.axisgrid.PairGrid):\n",
    "            self._movegrid()\n",
    "        elif isinstance(self.sg, sns.axisgrid.JointGrid):\n",
    "            self._movejointgrid()\n",
    "        self._finalize()\n",
    "\n",
    "    def _movegrid(self):\n",
    "        \"\"\" Move PairGrid or Facetgrid \"\"\"\n",
    "        self._resize()\n",
    "        n = self.sg.axes.shape[0]\n",
    "        m = self.sg.axes.shape[1]\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(n,m, subplot_spec=self.subplot)\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                self._moveaxes(self.sg.axes[i,j], self.subgrid[i,j])\n",
    "\n",
    "    def _movejointgrid(self):\n",
    "        \"\"\" Move Jointgrid \"\"\"\n",
    "        h= self.sg.ax_joint.get_position().height\n",
    "        h2= self.sg.ax_marg_x.get_position().height\n",
    "        r = int(np.round(h/h2))\n",
    "        self._resize()\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(r+1,r+1, subplot_spec=self.subplot)\n",
    "\n",
    "        self._moveaxes(self.sg.ax_joint, self.subgrid[1:, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_x, self.subgrid[0, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_y, self.subgrid[1:, -1])\n",
    "\n",
    "    def _moveaxes(self, ax, gs):\n",
    "        #https://stackoverflow.com/a/46906599/4124317\n",
    "        ax.remove()\n",
    "        ax.figure=self.fig\n",
    "        self.fig.axes.append(ax)\n",
    "        self.fig.add_axes(ax)\n",
    "        ax._subplotspec = gs\n",
    "        ax.set_position(gs.get_position(self.fig))\n",
    "        ax.set_subplotspec(gs)\n",
    "\n",
    "    def _finalize(self):\n",
    "        plt.close(self.sg.fig)\n",
    "        self.fig.canvas.mpl_connect(\"resize_event\", self._resize)\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def _resize(self, evt=None):\n",
    "        self.sg.fig.set_size_inches(self.fig.get_size_inches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330f7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance_correlation_coefficient(y_true, y_pred):\n",
    "    \"\"\"Concordance correlation coefficient.\"\"\"\n",
    "    \n",
    "    y_true = y_true.reshape(-1,)\n",
    "    y_pred = y_pred.reshape(-1,)\n",
    "    # Remove NaNs\n",
    "    df = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "    df = df.dropna()\n",
    "    y_true = df['y_true']\n",
    "    y_pred = df['y_pred']\n",
    "    # Pearson product-moment correlation coefficients\n",
    "    cor = np.corrcoef(y_true, y_pred)[0][1]\n",
    "    # Mean\n",
    "    mean_true = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    # Variance\n",
    "    var_true = np.var(y_true)\n",
    "    var_pred = np.var(y_pred)\n",
    "    # Standard deviation\n",
    "    sd_true = np.std(y_true)\n",
    "    sd_pred = np.std(y_pred)\n",
    "    # Calculate CCC\n",
    "    numerator = 2 * cor * sd_true * sd_pred\n",
    "    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1569405b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBS_AFR</th>\n",
       "      <th>LABELS_gmt</th>\n",
       "      <th>LABELS</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>UNITS_gmt</th>\n",
       "      <th>V_RANGE</th>\n",
       "      <th>V_RANGE_AFR</th>\n",
       "      <th>CMAPS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBS_REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CTD</th>\n",
       "      <td>CTD</td>\n",
       "      <td>CTD</td>\n",
       "      <td>CTD</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>SI</td>\n",
       "      <td>Shape index</td>\n",
       "      <td>Shape index</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAB</th>\n",
       "      <td>LAB</td>\n",
       "      <td>LAB</td>\n",
       "      <td>LAB</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(0, 300)</td>\n",
       "      <td>(50, 250)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOHO</th>\n",
       "      <td>MOHO</td>\n",
       "      <td>Moho</td>\n",
       "      <td>Moho</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(15, 60)</td>\n",
       "      <td>(20, 50)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SV</th>\n",
       "      <td>SV_SPEED</td>\n",
       "      <td>S@_v@ 150km</td>\n",
       "      <td>$S_v$ @150km</td>\n",
       "      <td>$\\delta$$S_v$ %</td>\n",
       "      <td>km/s</td>\n",
       "      <td>(-0.075, 0.075)</td>\n",
       "      <td>(-0.075, 0.075)</td>\n",
       "      <td>SCM/roma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV</th>\n",
       "      <td>PV_SPEED</td>\n",
       "      <td>P@_v@ 150km</td>\n",
       "      <td>$P_v$ @150km</td>\n",
       "      <td>$\\delta$$P_v$ %</td>\n",
       "      <td>km/s</td>\n",
       "      <td>(-0.02, 0.02)</td>\n",
       "      <td>(-0.02, 0.02)</td>\n",
       "      <td>SCM/roma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <td>GEOID</td>\n",
       "      <td>Geoid</td>\n",
       "      <td>Geoid</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>(-45, 45)</td>\n",
       "      <td>(-45, 45)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEM</th>\n",
       "      <td>DEM</td>\n",
       "      <td>DEM</td>\n",
       "      <td>DEM</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>(-2200, 2200)</td>\n",
       "      <td>(-2200, 2200)</td>\n",
       "      <td>SCM/oleron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FA</th>\n",
       "      <td>FA</td>\n",
       "      <td>Free air</td>\n",
       "      <td>Free air</td>\n",
       "      <td>mGal</td>\n",
       "      <td>mGal</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>BG</td>\n",
       "      <td>Bouguer</td>\n",
       "      <td>Bouguer</td>\n",
       "      <td>mGal</td>\n",
       "      <td>mGal</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMAG2_CLASS</th>\n",
       "      <td>EMAG2</td>\n",
       "      <td>Mag.</td>\n",
       "      <td>Mag.</td>\n",
       "      <td>f(nT)</td>\n",
       "      <td>f(nT)</td>\n",
       "      <td>(-0.4, 0.4)</td>\n",
       "      <td>(-200, 200)</td>\n",
       "      <td>SCM/bilbao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RHO_L</th>\n",
       "      <td>RHO_L</td>\n",
       "      <td>Lith. rho</td>\n",
       "      <td>Lith. ρ</td>\n",
       "      <td>kg/m$^3$</td>\n",
       "      <td>kg/m@+3@+</td>\n",
       "      <td>(3260, 3360)</td>\n",
       "      <td>(3260, 3360)</td>\n",
       "      <td>SCM/batlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RHO_C</th>\n",
       "      <td>RHO_C</td>\n",
       "      <td>Crust rho</td>\n",
       "      <td>Crust ρ</td>\n",
       "      <td>kg/m$^3$</td>\n",
       "      <td>kg/m@+3@+</td>\n",
       "      <td>(2650, 2950)</td>\n",
       "      <td>(2650, 2950)</td>\n",
       "      <td>SCM/batlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOLC_DIST_W</th>\n",
       "      <td>VOLC_DIST</td>\n",
       "      <td>Volcano</td>\n",
       "      <td>Volcano</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(0, 100)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REG</th>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>class</td>\n",
       "      <td>class</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>gmt/categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLIM</th>\n",
       "      <td>GLIM</td>\n",
       "      <td>GliM</td>\n",
       "      <td>GliM</td>\n",
       "      <td>class</td>\n",
       "      <td>class</td>\n",
       "      <td>(1, 16)</td>\n",
       "      <td>(1, 15)</td>\n",
       "      <td>gmt/categorical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               OBS_AFR   LABELS_gmt        LABELS            UNITS  UNITS_gmt          V_RANGE      V_RANGE_AFR            CMAPS\n",
       "OBS_REF                                                                                                                         \n",
       "CTD                CTD          CTD           CTD               km         km          (0, 50)          (0, 50)       SCM/bamako\n",
       "SI                  SI  Shape index   Shape index               si         si          (-1, 1)          (-1, 1)         SCM/broc\n",
       "LAB                LAB          LAB           LAB               km         km         (0, 300)        (50, 250)       SCM/bamako\n",
       "MOHO              MOHO         Moho          Moho               km         km         (15, 60)         (20, 50)       SCM/bamako\n",
       "SV            SV_SPEED  S@_v@ 150km  $S_v$ @150km  $\\delta$$S_v$ %       km/s  (-0.075, 0.075)  (-0.075, 0.075)         SCM/roma\n",
       "PV            PV_SPEED  P@_v@ 150km  $P_v$ @150km  $\\delta$$P_v$ %       km/s    (-0.02, 0.02)    (-0.02, 0.02)         SCM/roma\n",
       "GEOID            GEOID        Geoid         Geoid                m          m        (-45, 45)        (-45, 45)       SCM/bamako\n",
       "DEM                DEM          DEM           DEM                m          m    (-2200, 2200)    (-2200, 2200)       SCM/oleron\n",
       "FA                  FA     Free air      Free air             mGal       mGal      (-100, 100)      (-100, 100)         SCM/broc\n",
       "BG                  BG      Bouguer       Bouguer             mGal       mGal      (-100, 100)      (-100, 100)         SCM/broc\n",
       "EMAG2_CLASS      EMAG2         Mag.          Mag.            f(nT)      f(nT)      (-0.4, 0.4)      (-200, 200)       SCM/bilbao\n",
       "RHO_L            RHO_L    Lith. rho       Lith. ρ         kg/m$^3$  kg/m@+3@+     (3260, 3360)     (3260, 3360)       SCM/batlow\n",
       "RHO_C            RHO_C    Crust rho       Crust ρ         kg/m$^3$  kg/m@+3@+     (2650, 2950)     (2650, 2950)       SCM/batlow\n",
       "VOLC_DIST_W  VOLC_DIST      Volcano       Volcano               km         km           (0, 1)         (0, 100)         SCM/broc\n",
       "REG                REG          REG           REG            class      class           (1, 6)           (1, 6)  gmt/categorical\n",
       "GLIM              GLIM         GliM          GliM            class      class          (1, 16)          (1, 15)  gmt/categorical"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = pd.DataFrame()\n",
    "\n",
    "\n",
    "obs[\"OBS_REF\"] = [\"CTD\" ,  \"SI\",\"LAB\", \"MOHO\",\n",
    "            \"SV\",\"PV\", \n",
    "            \"GEOID\",\"FA\",\"DEM\",\"BG\", \"EMAG2_CLASS\",\n",
    "                   \"RHO_L\", \"RHO_C\", \n",
    "                  \"VOLC_DIST_W\", \"REG\", \"GLIM\"]\n",
    "\n",
    "obs[\"OBS_AFR\"] = [\"CTD\" ,  \"SI\",\"LAB\", \"MOHO\",\n",
    "            \"SV_SPEED\",\"PV_SPEED\", \n",
    "            \"GEOID\",\"FA\",\"DEM\",\"BG\", \"EMAG2\",\n",
    "                   \"RHO_L\", \"RHO_C\", \n",
    "                  \"VOLC_DIST\", \"REG\", \"GLIM\"]\n",
    "  \n",
    "     \n",
    "# Labels for plots etc\n",
    "\n",
    "\n",
    "# Labels for plots etc\n",
    "obs[\"LABELS_gmt\"] = [\"CTD\",  \"Shape index\", \"LAB\", \"Moho\", \n",
    "                \"S@_v@ 150km\", \"P@_v@ 150km\", \n",
    "                \"Geoid\", \"Free air\", \"DEM\", \"Bouguer\", \"Mag.\", \n",
    "                \"Lith. rho\", \"Crust rho\",  \n",
    "                 \"Volcano\", \"REG\", \"GliM\", ]  \n",
    "\n",
    "\n",
    "obs[\"LABELS\"] = [\"CTD\",  \"Shape index\", \"LAB\", \"Moho\", \n",
    "                \"$S_v$ @150km\", \"$P_v$ @150km\", \n",
    "                \"Geoid\", \"Free air\", \"DEM\", \"Bouguer\", \"Mag.\", \n",
    "                \"Lith. ρ\", \"Crust ρ\",  \n",
    "                 \"Volcano\", \"REG\", \"GliM\", ]\n",
    "    \n",
    "# \"vp/vs\"\n",
    "# Units to display in plots etc\n",
    "obs[\"UNITS\"] = [\"km\",  \"si\", \"km\", \"km\",\n",
    "             \"$\\delta$$S_v$ %\",\"$\\delta$$P_v$ %\", \n",
    "             \"m\", \"mGal\", \"m\", \"mGal\",  \"f(nT)\", \n",
    "                 \"kg/m$^3$\", \"kg/m$^3$\",\n",
    "                \"km\",  \"class\", \"class\"]\n",
    "\n",
    "\n",
    "\n",
    "obs[\"UNITS_gmt\"] = [\"km\",  \"si\", \"km\", \"km\",\n",
    "             \"km/s\",\"km/s\", \n",
    "             \"m\", \"mGal\", \"m\", \"mGal\",  \"f(nT)\", \n",
    "                 \"kg/m@+3@+\", \"kg/m@+3@+\",\n",
    "                \"km\",  \"class\", \"class\"]\n",
    "        \n",
    "# Range of colormap for plots. Similar data are placed in same ranges for consistancy\n",
    "obs[\"V_RANGE\"] = [(0,50), (-1,1),(0,300),(15,60),\n",
    "              (-0.075,0.075), (-0.02,0.02), \n",
    "              (-45,45), (-100,100) , (-2200, 2200),(-100,100),  (-0.4, 0.4), \n",
    "                   (3260, 3360), (2650, 2950),\n",
    "                  (0,1), (1,6),(1,16),]\n",
    "\n",
    "\n",
    "    \n",
    "obs[\"V_RANGE_AFR\"] = [(0,50), (-1,1),(50,250),(20,50),\n",
    "          (-0.075,0.075), (-0.02,0.02), \n",
    "          (-45,45), (-100,100) , (-2200, 2200),(-100,100),  (-200, 200), \n",
    "               (3260, 3360), (2650, 2950),\n",
    "              (0,100), (1,6),(1,15),]\n",
    "\n",
    "\n",
    "obs[\"CMAPS\"] = [\"batlow\",  \"broc\", \"bamako\", \"batlow\", \n",
    "             \"roma\",\"roma\", \n",
    "             \"bamako\", \"broc\", \"bukavu\", \"broc\", \"batlow\",            \n",
    "                \"batlow\", \"batlow\",\n",
    "               \"bamako\",  \"batlowS\",\"categorical\", ]\n",
    "\n",
    "obs[\"CMAPS\"] = [\"SCM/bamako\",  \"SCM/broc\", \"SCM/bamako\", \"SCM/bamako\", \n",
    "             \"SCM/roma\",\"SCM/roma\", \n",
    "             \"SCM/bamako\", \"SCM/broc\", \"SCM/oleron\", \"SCM/broc\", \"SCM/bilbao\",            \n",
    "                \"SCM/batlow\", \"SCM/batlow\",\n",
    "               \"SCM/broc\",  \"gmt/categorical\",\"gmt/categorical\", ]\n",
    "\n",
    "new_index = [0,1,2,3,4,5,6,8,7,9,10,11,12,13,14,15]\n",
    "\n",
    "#new_index = [4,3,15,6,7,0, 14, 10,16, 8, 9,2, 13, 12, 8, 11, ]\n",
    "\n",
    "obs = obs.reindex(new_index)\n",
    "\n",
    "#obs.index = np.arange(0,len(obs))\n",
    "\n",
    "pd.options.display.width = 370\n",
    "pd.options.display.max_colwidth = 16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "obs_dict = obs.to_dict(orient='records')\n",
    "\n",
    "obs.set_index(['OBS_REF'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52e68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_afr_lr = xr.load_dataset(DIR/'Grids'/'inputs'/\"ds_afr_lr.nc\")\n",
    "ds_afr_hr = xr.load_dataset(DIR/'Grids'/'inputs'/\"ds_afr_hr.nc\")\n",
    "#ds_world = xr.load_dataset(dir_p/'Grids'/'inputs'/\"ds_world.nc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d31693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CTD',\n",
       " 'SI',\n",
       " 'LAB',\n",
       " 'MOHO',\n",
       " 'SV',\n",
       " 'PV',\n",
       " 'GEOID',\n",
       " 'DEM',\n",
       " 'FA',\n",
       " 'BG',\n",
       " 'EMAG2_CLASS',\n",
       " 'RHO_L',\n",
       " 'RHO_C',\n",
       " 'VOLC_DIST_W',\n",
       " 'REG',\n",
       " 'GLIM',\n",
       " 'lon',\n",
       " 'lat',\n",
       " 'grid_index_world',\n",
       " 'grid_index_afr',\n",
       " 'GHF']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "target = 'GHF'\n",
    "coord = ['lon', 'lat']\n",
    "grid_index_world = 'grid_index_world'\n",
    "grid_index_afr ='grid_index_afr'\n",
    "\n",
    "#######\n",
    "\n",
    "features_ex = []\n",
    "features_ghf = []\n",
    "\n",
    "\n",
    "\n",
    "features = obs.index.to_list()\n",
    "\n",
    "\n",
    "\n",
    "in_features = set(features)\n",
    "\n",
    "features_ex = copy.deepcopy(features)\n",
    "features_ex.extend(coord)\n",
    "features_ex.append(grid_index_world)\n",
    "features_ex.append(grid_index_afr)\n",
    "\n",
    "features_ex.append(target)\n",
    "\n",
    "features_ghf = copy.deepcopy(features)\n",
    "features_ghf.append(target)\n",
    "\n",
    "\n",
    "features_ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0e3ef",
   "metadata": {},
   "source": [
    "# best fit world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1e3ded5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OD_ra\n",
      "865\n",
      "5398\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTD</th>\n",
       "      <th>SI</th>\n",
       "      <th>LAB</th>\n",
       "      <th>MOHO</th>\n",
       "      <th>SV</th>\n",
       "      <th>PV</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>DEM</th>\n",
       "      <th>FA</th>\n",
       "      <th>BG</th>\n",
       "      <th>EMAG2_CLASS</th>\n",
       "      <th>RHO_L</th>\n",
       "      <th>RHO_C</th>\n",
       "      <th>VOLC_DIST_W</th>\n",
       "      <th>REG</th>\n",
       "      <th>GLIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.000000</td>\n",
       "      <td>865.0</td>\n",
       "      <td>865.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.0</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.876870</td>\n",
       "      <td>0.050441</td>\n",
       "      <td>131.296939</td>\n",
       "      <td>33.885225</td>\n",
       "      <td>0.020758</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>11.474278</td>\n",
       "      <td>147.472832</td>\n",
       "      <td>4.423719</td>\n",
       "      <td>-14.717862</td>\n",
       "      <td>0.012016</td>\n",
       "      <td>3320.527087</td>\n",
       "      <td>2789.142359</td>\n",
       "      <td>0.005703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.801959</td>\n",
       "      <td>0.414449</td>\n",
       "      <td>39.478027</td>\n",
       "      <td>4.838664</td>\n",
       "      <td>0.030675</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>12.034971</td>\n",
       "      <td>664.831749</td>\n",
       "      <td>23.726995</td>\n",
       "      <td>67.100616</td>\n",
       "      <td>0.137110</td>\n",
       "      <td>30.661087</td>\n",
       "      <td>36.412144</td>\n",
       "      <td>0.052387</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.404036</td>\n",
       "      <td>-0.877965</td>\n",
       "      <td>63.616049</td>\n",
       "      <td>15.100915</td>\n",
       "      <td>-0.072599</td>\n",
       "      <td>-0.018389</td>\n",
       "      <td>-19.114012</td>\n",
       "      <td>-1221.000000</td>\n",
       "      <td>-32.209390</td>\n",
       "      <td>-185.910239</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3258.836570</td>\n",
       "      <td>2719.499856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.225217</td>\n",
       "      <td>-0.321257</td>\n",
       "      <td>78.791160</td>\n",
       "      <td>31.256840</td>\n",
       "      <td>-0.006992</td>\n",
       "      <td>-0.003515</td>\n",
       "      <td>5.999313</td>\n",
       "      <td>-111.000000</td>\n",
       "      <td>-19.465192</td>\n",
       "      <td>-44.043296</td>\n",
       "      <td>-0.025830</td>\n",
       "      <td>3276.738674</td>\n",
       "      <td>2756.409230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.602118</td>\n",
       "      <td>0.097057</td>\n",
       "      <td>146.134097</td>\n",
       "      <td>34.059936</td>\n",
       "      <td>0.034554</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>10.499104</td>\n",
       "      <td>-33.000000</td>\n",
       "      <td>2.922379</td>\n",
       "      <td>8.417811</td>\n",
       "      <td>0.033117</td>\n",
       "      <td>3339.351502</td>\n",
       "      <td>2785.573554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.642644</td>\n",
       "      <td>0.296373</td>\n",
       "      <td>165.748988</td>\n",
       "      <td>35.961792</td>\n",
       "      <td>0.044598</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>18.429691</td>\n",
       "      <td>467.000000</td>\n",
       "      <td>23.171467</td>\n",
       "      <td>26.226235</td>\n",
       "      <td>0.079547</td>\n",
       "      <td>3343.249632</td>\n",
       "      <td>2808.158078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>54.341938</td>\n",
       "      <td>0.948447</td>\n",
       "      <td>177.836248</td>\n",
       "      <td>46.957553</td>\n",
       "      <td>0.070713</td>\n",
       "      <td>0.031186</td>\n",
       "      <td>55.098567</td>\n",
       "      <td>2894.000000</td>\n",
       "      <td>115.655339</td>\n",
       "      <td>134.607389</td>\n",
       "      <td>0.436619</td>\n",
       "      <td>3373.423772</td>\n",
       "      <td>2889.097982</td>\n",
       "      <td>0.652339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CTD          SI         LAB        MOHO          SV          PV       GEOID          DEM          FA          BG  EMAG2_CLASS        RHO_L        RHO_C  VOLC_DIST_W    REG   GLIM\n",
       "count   865.000000  865.000000  865.000000  865.000000  865.000000  865.000000  865.000000   865.000000  865.000000  865.000000   865.000000   865.000000   865.000000   865.000000  865.0  865.0\n",
       "unique         NaN         NaN         NaN         NaN         NaN         NaN         NaN          NaN         NaN         NaN          NaN          NaN          NaN          NaN    6.0   11.0\n",
       "top            NaN         NaN         NaN         NaN         NaN         NaN         NaN          NaN         NaN         NaN          NaN          NaN          NaN          NaN    1.0   15.0\n",
       "freq           NaN         NaN         NaN         NaN         NaN         NaN         NaN          NaN         NaN         NaN          NaN          NaN          NaN          NaN  432.0  497.0\n",
       "mean     28.876870    0.050441  131.296939   33.885225    0.020758    0.002219   11.474278   147.472832    4.423719  -14.717862     0.012016  3320.527087  2789.142359     0.005703    NaN    NaN\n",
       "std       5.801959    0.414449   39.478027    4.838664    0.030675    0.006868   12.034971   664.831749   23.726995   67.100616     0.137110    30.661087    36.412144     0.052387    NaN    NaN\n",
       "min      21.404036   -0.877965   63.616049   15.100915   -0.072599   -0.018389  -19.114012 -1221.000000  -32.209390 -185.910239    -1.000000  3258.836570  2719.499856     0.000000    NaN    NaN\n",
       "25%      25.225217   -0.321257   78.791160   31.256840   -0.006992   -0.003515    5.999313  -111.000000  -19.465192  -44.043296    -0.025830  3276.738674  2756.409230     0.000000    NaN    NaN\n",
       "50%      26.602118    0.097057  146.134097   34.059936    0.034554    0.004413   10.499104   -33.000000    2.922379    8.417811     0.033117  3339.351502  2785.573554     0.000000    NaN    NaN\n",
       "75%      30.642644    0.296373  165.748988   35.961792    0.044598    0.004668   18.429691   467.000000   23.171467   26.226235     0.079547  3343.249632  2808.158078     0.000000    NaN    NaN\n",
       "max      54.341938    0.948447  177.836248   46.957553    0.070713    0.031186   55.098567  2894.000000  115.655339  134.607389     0.436619  3373.423772  2889.097982     0.652339    NaN    NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "rating = 'ra'\n",
    "outlier = 'OD'\n",
    "\n",
    "\n",
    "file_label = f'{outlier}_{rating}'\n",
    "\n",
    "w_OD_ra_f =  DIR/'Dataset'/'Preprocessed'/f'W_OD_ra.csv'\n",
    "W_OD_ra = pd.read_csv(w_OD_ra_f, sep='\\t')\n",
    "\n",
    "#mask_afr = W_OD_ra['lon'].between(afr_lon_min, afr_lon_max)& W_OD_ra['lat'].between(afr_lat_min, afr_lat_max)\n",
    "#Afr_OD_ra = W_OD_ra[~mask_afr]\n",
    "\n",
    "\n",
    "\n",
    "Afr_OD_ra_hr_f =  DIR/'Dataset'/'Preprocessed'/f'Afr_OD_ra_hr.csv'\n",
    "Afr_OD_ra_hr = pd.read_csv(Afr_OD_ra_hr_f,  sep='\\t')\n",
    "\n",
    "\n",
    "Afr_NOD_ra_hr_f =  DIR/'Dataset'/'Preprocessed'/f'Afr_NOD_ra_hr.csv'\n",
    "Afr_NOD_ra_hr = pd.read_csv(Afr_NOD_ra_hr_f,sep='\\t')\n",
    "\n",
    "W_OD_ra['GLIM']  = W_OD_ra['GLIM'].astype('category')\n",
    "W_OD_ra['REG']  = W_OD_ra['REG'].astype('category')\n",
    "\n",
    "\n",
    "Afr_OD_ra_hr['GLIM']  = Afr_OD_ra_hr['GLIM'].astype('int').astype('category')\n",
    "Afr_OD_ra_hr['REG']  = Afr_OD_ra_hr['REG'].astype('int').astype('category')\n",
    "\n",
    "\n",
    "\n",
    "X_w = W_OD_ra[features]\n",
    "y_w = W_OD_ra[target].values.reshape(-1,1) \n",
    "\n",
    "X_afr_hr = Afr_OD_ra_hr[features]\n",
    "y_afr_hr = Afr_OD_ra_hr[target].values.reshape(-1,1) \n",
    "\n",
    "\n",
    "X_w.describe(include='all')\n",
    "\n",
    "\n",
    "\n",
    "X_afr_hr.describe(include='all')\n",
    "\n",
    "\n",
    "\n",
    "bs_rfr_hyp =  DIR/'Hyperparameters'/f'RFR_{file_label}.csv'\n",
    "\n",
    "\n",
    "\n",
    "bs_rfr_hyp_df = pd.read_csv(bs_rfr_hyp, sep='\\t')\n",
    "\n",
    "\n",
    "best_params = bs_rfr_hyp_df.to_dict('list')\n",
    "\n",
    "print(file_label)\n",
    "\n",
    "\n",
    "print(len(Afr_OD_ra_hr))\n",
    "print(len(W_OD_ra))\n",
    "\n",
    "X_afr_hr.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429523d6",
   "metadata": {},
   "source": [
    "# Pre-evalaution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 10 \n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "KPI_afr_hr = pd.DataFrame()\n",
    "results_W = pd.DataFrame()\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) * -1\n",
    "\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for best_features in range(8,16):  \n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "\n",
    "    rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe),   (\"regressor\", regressor)]\n",
    "\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "\n",
    "\n",
    "\n",
    "    model_pipeline.fit(X_afr_hr, y_afr_hr)\n",
    "\n",
    "    \n",
    "    y_predict = model_pipeline.predict(X_afr_hr)\n",
    "    \n",
    "\n",
    "    KPI_afr_hr.loc['NRMSE', f'RFE_{best_features}'] = nrmse(y_afr_hr, y_predict) *-1\n",
    "    KPI_afr_hr.loc['RMSE', f'RFE_{best_features}'] =mean_squared_error(y_afr_hr, y_predict, squared=False) \n",
    "    KPI_afr_hr.loc['MAE', f'RFE_{best_features}'] = mean_absolute_error(y_afr_hr, y_predict)  \n",
    "    KPI_afr_hr.loc['MAPE', f'RFE_{best_features}'] = mean_absolute_percentage_error(y_afr_hr, y_predict) \n",
    "    KPI_afr_hr.loc['CD', f'RFE_{best_features}'] = r2_score(y_afr_hr, y_predict)\n",
    "    KPI_afr_hr.loc['EV', f'RFE_{best_features}'] = explained_variance_score(y_afr_hr, y_predict)\n",
    "    KPI_afr_hr.loc['CCC', f'RFE_{best_features}'] = concordance_correlation_coefficient(y_afr_hr, y_predict)\n",
    "    KPI_afr_hr.loc['MAX', f'RFE_{best_features}'] = y_predict.max()\n",
    "    KPI_afr_hr.loc['MIN', f'RFE_{best_features}'] = y_predict.min()\n",
    "    \n",
    "    KPI_afr_hr.loc['MAX_E',  f'RFE_{best_features}'] = round( max_error(y_afr_hr, y_predict), 3)\n",
    "    KPI_afr_hr.loc['MedAE',  f'RFE_{best_features}'] = round( median_absolute_error(y_afr_hr, y_predict), 3) \n",
    "    KPI_afr_hr.loc['MPE',  f'RFE_{best_features}'] = round(np.mean((y_afr_hr -y_predict)/y_afr_hr) , 3)\n",
    "    KPI_afr_hr.loc['ACC',  f'RFE_{best_features}'] = round(100 - mean_absolute_percentage_error(y_afr_hr, y_predict) *100, 3)\n",
    "    KPI_afr_hr.loc['Mean',  f'RFE_{best_features}'] = round(np.mean(y_predict),3)\n",
    "    KPI_afr_hr.loc['Median',  f'RFE_{best_features}'] = round(np.median(y_predict),3)\n",
    "    KPI_afr_hr.loc['Stdev',  f'RFE_{best_features}'] = round(np.std(y_predict),3)\n",
    "    KPI_afr_hr.loc['RSD',  f'RFE_{best_features}'] = round(np.std(y_predict) / np.mean(y_predict) ,3)\n",
    "    \n",
    "       \n",
    "  \n",
    "\n",
    "    \n",
    "    results_W[f'RFE_{best_features}'] =y_predict.reshape(-1,)\n",
    "    # Print message to user\n",
    "    print('#'*60)\n",
    "\n",
    "\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "\n",
    "scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "numeric_transformer = scaler\n",
    "\n",
    "categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "   (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe), (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "# Initialize Pipeline object\n",
    "pipeline= Pipeline(steps = steps)\n",
    "\n",
    "model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "\n",
    "model_pipeline.fit(X_afr_hr, y_afr_hr)\n",
    "\n",
    "\n",
    "y_predict = model_pipeline.predict(X_afr_hr)\n",
    "\n",
    "\n",
    "KPI_afr_hr.loc['NRMSE', f'RFE_{best_features}'] = nrmse(y_afr_hr, y_predict) *-1\n",
    "KPI_afr_hr.loc['RMSE', f'RFE_{best_features}'] =mean_squared_error(y_afr_hr, y_predict, squared=False) \n",
    "KPI_afr_hr.loc['MAE', f'RFE_{best_features}'] = mean_absolute_error(y_afr_hr, y_predict)  \n",
    "KPI_afr_hr.loc['MAPE', f'RFE_{best_features}'] = mean_absolute_percentage_error(y_afr_hr, y_predict) \n",
    "KPI_afr_hr.loc['CD', f'RFE_{best_features}'] = r2_score(y_afr_hr, y_predict)\n",
    "KPI_afr_hr.loc['EV', f'RFE_{best_features}'] = explained_variance_score(y_afr_hr, y_predict)\n",
    "KPI_afr_hr.loc['CCC', f'RFE_{best_features}'] = concordance_correlation_coefficient(y_afr_hr, y_predict)\n",
    "KPI_afr_hr.loc['MAX', f'RFE_{best_features}'] = y_predict.max()\n",
    "KPI_afr_hr.loc['MIN', f'RFE_{best_features}'] = y_predict.min()\n",
    "\n",
    "KPI_afr_hr.loc['MAX_E',  f'RFE_{best_features}'] = round( max_error(y_afr_hr, y_predict), 3)\n",
    "KPI_afr_hr.loc['MedAE',  f'RFE_{best_features}'] = round( median_absolute_error(y_afr_hr, y_predict), 3) \n",
    "KPI_afr_hr.loc['MPE',  f'RFE_{best_features}'] = round(np.mean((y_afr_hr -y_predict)/y_afr_hr) , 3)\n",
    "KPI_afr_hr.loc['ACC',  f'RFE_{best_features}'] = round(100 - mean_absolute_percentage_error(y_afr_hr, y_predict) *100, 3)\n",
    "KPI_afr_hr.loc['Mean',  f'RFE_{best_features}'] = round(np.mean(y_predict),3)\n",
    "KPI_afr_hr.loc['Median',  f'RFE_{best_features}'] = round(np.median(y_predict),3)\n",
    "KPI_afr_hr.loc['Stdev',  f'RFE_{best_features}'] = round(np.std(y_predict),3)\n",
    "KPI_afr_hr.loc['RSD',  f'RFE_{best_features}'] = round(np.std(y_predict) / np.mean(y_predict) ,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_W[f'RFE_{best_features}'] =y_predict.reshape(-1,)\n",
    "# Print message to user\n",
    "print('#'*60)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbd077",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "\n",
    "# Set figure size and create barplot\n",
    "\n",
    "fig, axs = plt.subplots(8,2,figsize=(15, 40))\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 2)\n",
    "#fig.set_size_inches(30,30)\n",
    "\n",
    "#scores = ['RMSE', 'NRMSE','MAE', 'MAPE', 'CD','EV', 'MAX_E','MIN_E' ,'MedAE', 'MPE']\n",
    "\n",
    "scores = ['RMSE', 'MAE', 'NRMSE','MAPE', 'CD','EV', 'MAX_E', 'MAX', \n",
    "          'Stdev', 'RSD', 'Mean','Median','MedAE', 'MPE', 'ACC', 'CCC']\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 2)\n",
    "n_models = 30\n",
    "#subfile = 'HOD'\n",
    "#files_rg = [ x for x in files_rg if subfile in x ]\n",
    "for score, ax in zip(scores, axs.flatten()):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    cols  = KPI_afr_lr.loc[score,:].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "\n",
    "    if score in ['CD','EV' ,'MAX', 'MPE', 'ACC','CCC']:\n",
    "        \n",
    "        \n",
    "        x_data = KPI_afr_lr.loc[score,cols].sort_values(ascending=False).index\n",
    "        y_data = KPI_afr_lr.loc[score,cols].sort_values(ascending=False).round(2)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0])\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        x_data = KPI_afr_lr.loc[score,cols].sort_values().index\n",
    "        y_data = KPI_afr_lr.loc[score,cols].sort_values().round(2)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0], )\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e03c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ['RMSE', 'MAE', 'NRMSE','MAPE', 'CD','EV', 'MAX_E', 'MAX', 'Stdev', 'RSD', 'Mean','Median','MedAE', 'MPE', 'Acc']\n",
    "# False ['CD','EV' ,'MAX', 'MPE']\n",
    "\n",
    "#len(KPI_afr_lr)\n",
    "n_models = 10\n",
    "\n",
    "rfe_range = [col  for col in KPI_afr_lr.columns]\n",
    "\n",
    "score = 'NRMSE'\n",
    "columns_W = KPI_afr_lr.loc[score,rfe_range].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "results_W['y'] = y_afr_lr\n",
    "\n",
    "\n",
    "threshold = 20\n",
    "\n",
    "for column in columns_W[:n_models]:\n",
    "    mask = np.abs(results_W['y'] - results_W[column]) > threshold\n",
    "    y_predict = results_W[column]\n",
    "    \n",
    "    g0 =sns.jointplot( x=column, y='y', data=results_W, kind='reg', size=12,   ratio=4, \n",
    "                        marginal_kws={'lw':1, 'color':'blue'}, \n",
    "                  scatter_kws={\"color\": \"grey\", \"edgecolor\":\"w\"}, line_kws={\"color\": \"blue\"},\n",
    "    label=   \n",
    "    f'''\n",
    "    best fit\n",
    "    {column}\n",
    "    RMSE     = {round(KPI_afr_lr.loc['RMSE', column],2)}\n",
    "    NRMSE    = {round(KPI_afr_lr.loc['NRMSE', column],2)} %\n",
    "    MAE      = {round(KPI_afr_lr.loc['MAE', column],2)}\n",
    "    MAPE     = {round(KPI_afr_lr.loc['MAPE', column],2)} %\n",
    "    MAX       = {round(KPI_afr_lr.loc['MAX', column],2)}\n",
    "    RSD       = {round(KPI_afr_lr.loc['RSD', column],2)}\n",
    "    $R^2$    = {round(KPI_afr_lr.loc['CD', column],2)}\n",
    "    Total count    : {len(y_predict) - len(y_predict[mask])}   \n",
    "        ''' )\n",
    "\n",
    "    sns.regplot([results_W[column].min(), results_W[column].max()], [results_W['y'].min(), results_W['y'].max()], \\\n",
    "                ci=None, scatter=False, ax= g0.ax_joint, line_kws={\"color\": \"grey\", 'ls':'--'} , label = 'Identity')\n",
    "\n",
    "    sns.scatterplot(results_W[column][mask],results_W['y'][mask], color=\"#ce1414\",\\\n",
    "                    s=30,  ax= g0.ax_joint, edgecolor=\"white\",\n",
    "    label = \n",
    "    f'''Error > {threshold}    = {len(y_predict[mask])}\n",
    "    Realtive error       = {round(len(y_predict[mask]) / len(y_predict), 1)  *100} %\n",
    "\n",
    "    ''' )\n",
    "\n",
    "    g0.set_axis_labels( '$\\hat{y}$','$_y$', fontsize=30, fontweight='bold')\n",
    "    g0.fig.suptitle('PREDICTED vs ACTUAL',fontsize=20)\n",
    "\n",
    "    g0.ax_marg_y.grid('on') \n",
    "\n",
    "    #plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    #####\n",
    "    \n",
    "    g1 = sns.jointplot( x=column, y='y', data=results_W, kind=\"resid\", size=12, \n",
    "                         line_kws={\"color\": \"blue\", 'lowess':True, 'robust':True},     \n",
    "                         )\n",
    "\n",
    "\n",
    "    #plot.ax_joint.axvline(x=6)\n",
    "    g1.ax_joint.axhline(y=threshold )\n",
    "    g1.ax_joint.axhline(y=-threshold)\n",
    "\n",
    "\n",
    "    g1.set_axis_labels('$_y$', 'Residuals', fontsize=30, fontweight='bold')\n",
    "    g1.fig.suptitle(column,fontsize=20)\n",
    "\n",
    "    g1.ax_marg_y.grid('on') \n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    fig.set_size_inches(16,9)\n",
    "\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "    mg0 = SeabornFig2Grid(g0, fig, gs[0])\n",
    "    mg1 = SeabornFig2Grid(g1, fig, gs[1])\n",
    "\n",
    "    gs.tight_layout(fig)\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cf0b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "kfold = 5\n",
    "\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) \n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "ccc_score = make_scorer(concordance_correlation_coefficient , greater_is_better=True)\n",
    "\n",
    "scoring = {\n",
    "    'NRMSE':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    'CD':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'CCC': ccc_score,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "results ={}\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize RFECV object\n",
    "    feature_selector = RFECV(regressor, cv = cv, step = 1, #n_jobs=-1, \n",
    "                             scoring = score, verbose = 1)\n",
    "    \n",
    "\n",
    "    # Fit RFECV\n",
    "    feature_selector .fit(X_afr_lr, np.ravel(y_afr_lr))\n",
    "    results[key] = feature_selector\n",
    "\n",
    "    # Get selected features\n",
    "    #feature_names = X_corr.columns\n",
    "    #selected_features = feature_names[feature_selector.support_].tolist()\n",
    "\n",
    "    print(f'terminated {key} {score}\\n')\n",
    "    print('terminated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d05794",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for key, score in scoring.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X_afr_lr.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "    if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "        plt.plot(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1)*-1, label=key)\n",
    "        plt.scatter(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1)*-1, marker='x')\n",
    "\n",
    "    else:\n",
    "        plt.plot(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1), label=key)\n",
    "        plt.scatter(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1), marker='x')\n",
    "        \n",
    "    \n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score\")\n",
    "    plt.legend(loc=[.79,0.26])\n",
    "plt.axvline(results[key].n_features_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a878fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "# Set figure size and create barplot\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "regressor_label = 'RFR'\n",
    "\n",
    "# Load hyper parameter \n",
    "\n",
    "regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X_afr_lr, y_afr_lr).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X_afr_lr[selected_features],y_afr_lr)\n",
    "\n",
    "#obs.set_index('OBS_REF', inplace=True)\n",
    "selected_labels = obs.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"Feature\"])\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "\n",
    "sns.barplot(x = \"Relative Importance\", y = \"Feature\",\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 16)),  data = feature_importance)\n",
    "\n",
    "\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "#ax.set_title(f'{sub_figs[0]})', loc ='left', pad=20,   y=1.1)\n",
    "\n",
    "#obs.reset_index(inplace=True)\n",
    "\n",
    "# Save Figure\n",
    "#plt.savefig(\"feature_importance.png\", dpi = 1080)\n",
    "\n",
    " #['LAB', 'RHO_C', 'SV', 'PV', 'CTD', 'RHO_L', 'DEM', 'VOLC_DIST_W', 'A_MEDIAN_W', 'SI', 'GEOID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f68bc6",
   "metadata": {},
   "source": [
    "# High resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187d17c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 10 \n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "KPI_afr_hr = pd.DataFrame()\n",
    "results_W = pd.DataFrame()\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) * -1\n",
    "\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for best_features in range(8,16):  \n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "\n",
    "    rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe),   (\"regressor\", regressor)]\n",
    "\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "\n",
    "\n",
    "\n",
    "    model_pipeline.fit(X_afr_hr, y_afr_hr)\n",
    "\n",
    "    \n",
    "    y_predict = model_pipeline.predict(X_afr_hr)\n",
    "    \n",
    "\n",
    "    KPI_afr_hr.loc['NRMSE', f'RFE_{best_features}'] = nrmse(y_afr_hr, y_predict) *-1\n",
    "    KPI_afr_hr.loc['RMSE', f'RFE_{best_features}'] =mean_squared_error(y_afr_hr, y_predict, squared=False) \n",
    "    KPI_afr_hr.loc['MAE', f'RFE_{best_features}'] = mean_absolute_error(y_afr_hr, y_predict)  \n",
    "    KPI_afr_hr.loc['MAPE', f'RFE_{best_features}'] = mean_absolute_percentage_error(y_afr_hr, y_predict) \n",
    "    KPI_afr_hr.loc['CD', f'RFE_{best_features}'] = r2_score(y_afr_hr, y_predict)\n",
    "    KPI_afr_hr.loc['EV', f'RFE_{best_features}'] = explained_variance_score(y_afr_hr, y_predict)\n",
    "    KPI_afr_hr.loc['CCC', f'RFE_{best_features}'] = concordance_correlation_coefficient(y_afr_hr, y_predict)\n",
    "    KPI_afr_hr.loc['MAX', f'RFE_{best_features}'] = y_predict.max()\n",
    "    KPI_afr_hr.loc['MIN', f'RFE_{best_features}'] = y_predict.min()\n",
    "    \n",
    "    KPI_afr_hr.loc['MAX_E',  f'RFE_{best_features}'] = round( max_error(y_afr_hr, y_predict), 3)\n",
    "    KPI_afr_hr.loc['MedAE',  f'RFE_{best_features}'] = round( median_absolute_error(y_afr_hr, y_predict), 3) \n",
    "    KPI_afr_hr.loc['MPE',  f'RFE_{best_features}'] = round(np.mean((y_afr_hr -y_predict)/y_afr_hr) , 3)\n",
    "    KPI_afr_hr.loc['ACC',  f'RFE_{best_features}'] = round(100 - mean_absolute_percentage_error(y_afr_hr, y_predict) *100, 3)\n",
    "    KPI_afr_hr.loc['Mean',  f'RFE_{best_features}'] = round(np.mean(y_predict),3)\n",
    "    KPI_afr_hr.loc['Median',  f'RFE_{best_features}'] = round(np.median(y_predict),3)\n",
    "    KPI_afr_hr.loc['Stdev',  f'RFE_{best_features}'] = round(np.std(y_predict),3)\n",
    "    KPI_afr_hr.loc['RSD',  f'RFE_{best_features}'] = round(np.std(y_predict) / np.mean(y_predict) ,3)\n",
    "    \n",
    "       \n",
    "  \n",
    "\n",
    "    \n",
    "    results_W[f'RFE_{best_features}'] =y_predict.reshape(-1,)\n",
    "    # Print message to user\n",
    "    print('#'*60)\n",
    "\n",
    "\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "\n",
    "scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "numeric_transformer = scaler\n",
    "\n",
    "categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "   (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe), (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "# Initialize Pipeline object\n",
    "pipeline= Pipeline(steps = steps)\n",
    "\n",
    "model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "\n",
    "model_pipeline.fit(X_afr_hr, y_afr_hr)\n",
    "\n",
    "\n",
    "y_predict = model_pipeline.predict(X_afr_hr)\n",
    "\n",
    "\n",
    "KPI_afr_hr.loc['NRMSE', f'RFE_{best_features}'] = nrmse(y_afr_hr, y_predict) *-1\n",
    "KPI_afr_hr.loc['RMSE', f'RFE_{best_features}'] =mean_squared_error(y_afr_hr, y_predict, squared=False) \n",
    "KPI_afr_hr.loc['MAE', f'RFE_{best_features}'] = mean_absolute_error(y_afr_hr, y_predict)  \n",
    "KPI_afr_hr.loc['MAPE', f'RFE_{best_features}'] = mean_absolute_percentage_error(y_afr_hr, y_predict) \n",
    "KPI_afr_hr.loc['CD', f'RFE_{best_features}'] = r2_score(y_afr_hr, y_predict)\n",
    "KPI_afr_hr.loc['EV', f'RFE_{best_features}'] = explained_variance_score(y_afr_hr, y_predict)\n",
    "KPI_afr_hr.loc['CCC', f'RFE_{best_features}'] = concordance_correlation_coefficient(y_afr_hr, y_predict)\n",
    "KPI_afr_hr.loc['MAX', f'RFE_{best_features}'] = y_predict.max()\n",
    "KPI_afr_hr.loc['MIN', f'RFE_{best_features}'] = y_predict.min()\n",
    "\n",
    "KPI_afr_hr.loc['MAX_E',  f'RFE_{best_features}'] = round( max_error(y_afr_hr, y_predict), 3)\n",
    "KPI_afr_hr.loc['MedAE',  f'RFE_{best_features}'] = round( median_absolute_error(y_afr_hr, y_predict), 3) \n",
    "KPI_afr_hr.loc['MPE',  f'RFE_{best_features}'] = round(np.mean((y_afr_hr -y_predict)/y_afr_hr) , 3)\n",
    "KPI_afr_hr.loc['ACC',  f'RFE_{best_features}'] = round(100 - mean_absolute_percentage_error(y_afr_hr, y_predict) *100, 3)\n",
    "KPI_afr_hr.loc['Mean',  f'RFE_{best_features}'] = round(np.mean(y_predict),3)\n",
    "KPI_afr_hr.loc['Median',  f'RFE_{best_features}'] = round(np.median(y_predict),3)\n",
    "KPI_afr_hr.loc['Stdev',  f'RFE_{best_features}'] = round(np.std(y_predict),3)\n",
    "KPI_afr_hr.loc['RSD',  f'RFE_{best_features}'] = round(np.std(y_predict) / np.mean(y_predict) ,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_W[f'RFE_{best_features}'] =y_predict.reshape(-1,)\n",
    "# Print message to user\n",
    "print('#'*60)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a5cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "\n",
    "# Set figure size and create barplot\n",
    "\n",
    "fig, axs = plt.subplots(8,2,figsize=(15, 40))\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 2)\n",
    "#fig.set_size_inches(30,30)\n",
    "\n",
    "#scores = ['RMSE', 'NRMSE','MAE', 'MAPE', 'CD','EV', 'MAX_E','MIN_E' ,'MedAE', 'MPE']\n",
    "\n",
    "scores = ['RMSE', 'MAE', 'NRMSE','MAPE', 'CD','EV', 'MAX_E', 'MAX', \n",
    "          'Stdev', 'RSD', 'Mean','Median','MedAE', 'MPE', 'ACC', 'CCC']\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 2)\n",
    "n_models = 30\n",
    "#subfile = 'HOD'\n",
    "#files_rg = [ x for x in files_rg if subfile in x ]\n",
    "for score, ax in zip(scores, axs.flatten()):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    cols  = KPI_afr_hr.loc[score,:].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "\n",
    "    if score in ['CD','EV' ,'MAX', 'MPE', 'ACC','CCC']:\n",
    "        \n",
    "        \n",
    "        x_data = KPI_afr_hr.loc[score,cols].sort_values(ascending=False).index\n",
    "        y_data = KPI_afr_hr.loc[score,cols].sort_values(ascending=False).round(2)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0])\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        x_data = KPI_afr_hr.loc[score,cols].sort_values().index\n",
    "        y_data = KPI_afr_hr.loc[score,cols].sort_values().round(2)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0], )\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2ed44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ['RMSE', 'MAE', 'NRMSE','MAPE', 'CD','EV', 'MAX_E', 'MAX', 'Stdev', 'RSD', 'Mean','Median','MedAE', 'MPE', 'Acc']\n",
    "# False ['CD','EV' ,'MAX', 'MPE']\n",
    "\n",
    "#len(KPI_afr_hr)\n",
    "n_models = 10\n",
    "\n",
    "rfe_range = [col  for col in KPI_afr_hr.columns]\n",
    "\n",
    "score = 'NRMSE'\n",
    "columns_W = KPI_afr_hr.loc[score,rfe_range].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "results_W['y'] = y_afr_hr\n",
    "\n",
    "\n",
    "threshold = 20\n",
    "\n",
    "for column in columns_W[:n_models]:\n",
    "    mask = np.abs(results_W['y'] - results_W[column]) > threshold\n",
    "    y_predict = results_W[column]\n",
    "    \n",
    "    g0 =sns.jointplot( x=column, y='y', data=results_W, kind='reg', size=12,   ratio=4, \n",
    "                        marginal_kws={'lw':1, 'color':'blue'}, \n",
    "                  scatter_kws={\"color\": \"grey\", \"edgecolor\":\"w\"}, line_kws={\"color\": \"blue\"},\n",
    "    label=   \n",
    "    f'''\n",
    "    best fit\n",
    "    {column}\n",
    "    RMSE     = {round(KPI_afr_hr.loc['RMSE', column],2)}\n",
    "    NRMSE    = {round(KPI_afr_hr.loc['NRMSE', column],2)} %\n",
    "    MAE      = {round(KPI_afr_hr.loc['MAE', column],2)}\n",
    "    MAPE     = {round(KPI_afr_hr.loc['MAPE', column],2)} %\n",
    "    MAX       = {round(KPI_afr_hr.loc['MAX', column],2)}\n",
    "    RSD       = {round(KPI_afr_hr.loc['RSD', column],2)}\n",
    "    $R^2$    = {round(KPI_afr_hr.loc['CD', column],2)}\n",
    "    Total count    : {len(y_predict) - len(y_predict[mask])}   \n",
    "        ''' )\n",
    "\n",
    "    sns.regplot([results_W[column].min(), results_W[column].max()], [results_W['y'].min(), results_W['y'].max()], \\\n",
    "                ci=None, scatter=False, ax= g0.ax_joint, line_kws={\"color\": \"grey\", 'ls':'--'} , label = 'Identity')\n",
    "\n",
    "    sns.scatterplot(results_W[column][mask],results_W['y'][mask], color=\"#ce1414\",\\\n",
    "                    s=30,  ax= g0.ax_joint, edgecolor=\"white\",\n",
    "    label = \n",
    "    f'''Error > {threshold}    = {len(y_predict[mask])}\n",
    "    Realtive error       = {round(len(y_predict[mask]) / len(y_predict), 1)  *100} %\n",
    "\n",
    "    ''' )\n",
    "\n",
    "    g0.set_axis_labels( '$\\hat{y}$','$_y$', fontsize=30, fontweight='bold')\n",
    "    g0.fig.suptitle('PREDICTED vs ACTUAL',fontsize=20)\n",
    "\n",
    "    g0.ax_marg_y.grid('on') \n",
    "\n",
    "    #plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    #####\n",
    "    \n",
    "    g1 = sns.jointplot( x=column, y='y', data=results_W, kind=\"resid\", size=12, \n",
    "                         line_kws={\"color\": \"blue\", 'lowess':True, 'robust':True},     \n",
    "                         )\n",
    "\n",
    "\n",
    "    #plot.ax_joint.axvline(x=6)\n",
    "    g1.ax_joint.axhline(y=threshold )\n",
    "    g1.ax_joint.axhline(y=-threshold)\n",
    "\n",
    "\n",
    "    g1.set_axis_labels('$_y$', 'Residuals', fontsize=30, fontweight='bold')\n",
    "    g1.fig.suptitle(column,fontsize=20)\n",
    "\n",
    "    g1.ax_marg_y.grid('on') \n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    fig.set_size_inches(16,9)\n",
    "\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "    mg0 = SeabornFig2Grid(g0, fig, gs[0])\n",
    "    mg1 = SeabornFig2Grid(g1, fig, gs[1])\n",
    "\n",
    "    gs.tight_layout(fig)\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b015aaf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "kfold = 5\n",
    "\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) \n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "ccc_score = make_scorer(concordance_correlation_coefficient , greater_is_better=True)\n",
    "\n",
    "scoring = {\n",
    "    'NRMSE':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    'CD':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'CCC': ccc_score,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "results ={}\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize RFECV object\n",
    "    feature_selector = RFECV(regressor, cv = cv, step = 1, #n_jobs=-1, \n",
    "                             scoring = score, verbose = 1)\n",
    "    \n",
    "\n",
    "    # Fit RFECV\n",
    "    feature_selector .fit(X_afr_hr, np.ravel(y_afr_hr))\n",
    "    results[key] = feature_selector\n",
    "\n",
    "    # Get selected features\n",
    "    #feature_names = X_corr.columns\n",
    "    #selected_features = feature_names[feature_selector.support_].tolist()\n",
    "\n",
    "    print(f'terminated {key} {score}\\n')\n",
    "    print('terminated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ae593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for key, score in scoring.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X_afr_hr.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "    if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "        plt.plot(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1)*-1, label=key)\n",
    "        plt.scatter(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1)*-1, marker='x')\n",
    "\n",
    "    else:\n",
    "        plt.plot(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1), label=key)\n",
    "        plt.scatter(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1), marker='x')\n",
    "        \n",
    "    \n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score\")\n",
    "    plt.legend(loc=[.79,0.26])\n",
    "plt.axvline(results[key].n_features_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce70818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "# Set figure size and create barplot\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "regressor_label = 'RFR'\n",
    "\n",
    "# Load hyper parameter \n",
    "\n",
    "regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X_afr_hr, y_afr_hr).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X_afr_hr[selected_features],y_afr_hr)\n",
    "\n",
    "#obs.set_index('OBS_REF', inplace=True)\n",
    "selected_labels = obs.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"Feature\"])\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "\n",
    "sns.barplot(x = \"Relative Importance\", y = \"Feature\",\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 16)),  data = feature_importance)\n",
    "\n",
    "\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "#ax.set_title(f'{sub_figs[0]})', loc ='left', pad=20,   y=1.1)\n",
    "\n",
    "#obs.reset_index(inplace=True)\n",
    "\n",
    "# Save Figure\n",
    "#plt.savefig(\"feature_importance.png\", dpi = 1080)\n",
    "\n",
    " #['LAB', 'RHO_C', 'SV', 'PV', 'CTD', 'RHO_L', 'DEM', 'VOLC_DIST_W', 'A_MEDIAN_W', 'SI', 'GEOID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0edaafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6431a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ebd8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sorted_features = obs.reset_index(drop=False).set_index('LABELS')\n",
    "\n",
    "\n",
    "\n",
    "selected_features = []\n",
    "\n",
    "for best_feature in range(15,2, -1):\n",
    "    selected_features.extend([sorted_features.loc[feature_importance['Feature'].values, 'OBS_REF'].values[0 :best_feature]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3af2f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline_dict = {}\n",
    "grids_dict = {}\n",
    "selected_features_dict = {}\n",
    "\n",
    "\n",
    "best_features = ['16', '15','14', '13','12', '11','10',\n",
    "                 '09','08', '07','06','05','04'\n",
    "                 ]\n",
    "\n",
    "\n",
    "scoring = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "\n",
    "kfold =10\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "\n",
    "label = 'AFR' \n",
    "\n",
    "for best_feature, selected_feature in zip(best_features ,selected_features) :\n",
    "\n",
    "    y_Afr = Afr_OD_ra_lr[target]\n",
    "    x_Afr = Afr_OD_ra_lr[selected_feature]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "    \n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[ (\"preprocessor\", preprocessor),  (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "    \n",
    "    trained_model = model_pipeline.fit(x_Afr, y_Afr )\n",
    "    \n",
    "   \n",
    "\n",
    "    ######### save\n",
    "\n",
    "   \n",
    "    pipeline_dict[f'RFE_{best_feature}'] = trained_model\n",
    "    \n",
    "    #grids_dict[f'RFE_{best_feature}'] =  ds_afr[selected_feature].to_array().values\n",
    "    \n",
    "    selected_features_dict[f'RFE_{best_feature}']   = selected_feature\n",
    "\n",
    "    print(f'RFE_{best_feature} fitting is terminated' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31573a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "grids_dict = {}\n",
    "\n",
    "n_features = ['16','15', '14', '13', '12', '11', '10', '09', '08', '07', '06', '05', '04']\n",
    "for selected_feature, n_feature in tqdm_notebook(zip(selected_features, n_features), total = len(n_features),\n",
    "                                      desc= f'{selected_feature}: ' ):\n",
    "    df = pd.DataFrame({'X': ds_afr_lr.XV.values.ravel(), 'Y': ds_afr_lr.YV.values.ravel()})\n",
    "\n",
    "    for feature in tqdm_notebook(selected_feature , \n",
    "                                            desc=f'Processing: ', leave=False ):\n",
    "        sleep(0.01)\n",
    "        df[feature] = ds_afr_lr[feature].values.ravel()\n",
    "    grids_dict[f'RFE_{n_feature}'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = {}\n",
    "xs = range(len(ds_afr_lr.X))\n",
    "ys = range(len(ds_afr_lr.Y))\n",
    "nn = (len(ds_afr_lr.Y), len( ds_afr_lr.X))\n",
    "\n",
    "\n",
    "hq_gt = Afr_OD_ra_lr[[grid_index_afr, target]].set_index(grid_index_afr)\n",
    "hq_gt.index.names = ['index']\n",
    "\n",
    "for key, pipeline  in tqdm_notebook(pipeline_dict.items() , \n",
    "                                            desc=f'Modelling: '):\n",
    "    print(key)\n",
    "    pipeline = pipeline_dict[key]\n",
    "    AFR_Q_RFR = np.zeros(nn) # predicted HF value\n",
    "    AFR_grid = grids_dict[key][selected_features_dict[key]]\n",
    "    predictions_df[key] = pd.DataFrame({'X': ds_afr_lr.XV.values.ravel(), 'Y': ds_afr_lr.YV.values.ravel()})\n",
    "\n",
    "    if 'GLIM' in selected_features_dict[key]:\n",
    "        AFR_grid['GLIM']  = AFR_grid['GLIM'].astype('int').astype('category')\n",
    "    if 'REG' in selected_features_dict[key]:\n",
    "        AFR_grid['REG']  = AFR_grid['REG'].astype('int').astype('category')\n",
    "    predictions_df[key]['Prediction'] = pipeline.predict(AFR_grid).reshape(-1,1)\n",
    "    predictions_df[key].index.names = ['index']\n",
    "    final_df = pd.merge(predictions_df[key], hq_gt,  how=\"left\", on=\"index\")\n",
    "    final_df.to_csv(DIR/'Grids'/'Outputs'/f'{key}_ra.csv' , index=False, header=True, sep='\\t')\n",
    "    ds_afr_lr[key] = (('Y', 'X'), predictions_df[key]['Prediction'].values.reshape(nn) )\n",
    "    \n",
    "ds_afr_lr.to_netcdf(DIR/'Grids'/'Outputs'/\"ds_afr_lr_rfr_ra.nc\", mode='w', \n",
    "                    engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72065084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
