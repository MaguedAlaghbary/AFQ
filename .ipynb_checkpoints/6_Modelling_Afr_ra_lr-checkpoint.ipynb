{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edac9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311f870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os, sys, pickle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "\n",
    "from scipy import stats, interpolate, spatial, io\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Arc \n",
    "\n",
    "\n",
    "import pyproj as proj\n",
    "import rasterio\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numba as nb\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# helper function for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer , r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#import gstools as gst\n",
    "#from pykrige.rk import RegressionKriging\n",
    "#from pykrige.rk import Krige\n",
    "#from skgstat import Variogram\n",
    "\n",
    "\n",
    "import operator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder , PowerTransformer\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor ,  ColumnTransformer\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from time import sleep\n",
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8a8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constanst\n",
    "crs_to='epsg:4326'\n",
    "crs_from='epsg:4326'\n",
    "projection = 'M5.4i'\n",
    "#parent directory\n",
    "\n",
    "DIR = Path().resolve() \n",
    "\n",
    "\n",
    "# We can exclude Arctic ocean and Antarctica, as there are no HF measurements to use\n",
    "world_lon_min, world_lon_max, world_lat_min, world_lat_max  = -180, 180, -60, 80\n",
    "\n",
    "# map extents of Africa and Australia\n",
    "afr_lon_min, afr_lon_max, afr_lat_min, afr_lat_max =  -20, 52, -37 , 38  \n",
    "\n",
    "\n",
    "# create grid for each region\n",
    "# crs Coordinate reference system\n",
    "\n",
    "#EPSG is projection\n",
    "# 0.2 degrees equal roughly 20 km\n",
    "\n",
    "region_afr = [afr_lon_min, afr_lon_max, afr_lat_min, afr_lat_max]\n",
    "region_world = [world_lon_min, world_lon_max, world_lat_min, world_lat_max]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215924c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SeabornFig2Grid():\n",
    "\n",
    "    def __init__(self, seaborngrid, fig,  subplot_spec):\n",
    "        self.fig = fig\n",
    "        self.sg = seaborngrid\n",
    "        self.subplot = subplot_spec\n",
    "        if isinstance(self.sg, sns.axisgrid.FacetGrid) or \\\n",
    "            isinstance(self.sg, sns.axisgrid.PairGrid):\n",
    "            self._movegrid()\n",
    "        elif isinstance(self.sg, sns.axisgrid.JointGrid):\n",
    "            self._movejointgrid()\n",
    "        self._finalize()\n",
    "\n",
    "    def _movegrid(self):\n",
    "        \"\"\" Move PairGrid or Facetgrid \"\"\"\n",
    "        self._resize()\n",
    "        n = self.sg.axes.shape[0]\n",
    "        m = self.sg.axes.shape[1]\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(n,m, subplot_spec=self.subplot)\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                self._moveaxes(self.sg.axes[i,j], self.subgrid[i,j])\n",
    "\n",
    "    def _movejointgrid(self):\n",
    "        \"\"\" Move Jointgrid \"\"\"\n",
    "        h= self.sg.ax_joint.get_position().height\n",
    "        h2= self.sg.ax_marg_x.get_position().height\n",
    "        r = int(np.round(h/h2))\n",
    "        self._resize()\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(r+1,r+1, subplot_spec=self.subplot)\n",
    "\n",
    "        self._moveaxes(self.sg.ax_joint, self.subgrid[1:, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_x, self.subgrid[0, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_y, self.subgrid[1:, -1])\n",
    "\n",
    "    def _moveaxes(self, ax, gs):\n",
    "        #https://stackoverflow.com/a/46906599/4124317\n",
    "        ax.remove()\n",
    "        ax.figure=self.fig\n",
    "        self.fig.axes.append(ax)\n",
    "        self.fig.add_axes(ax)\n",
    "        ax._subplotspec = gs\n",
    "        ax.set_position(gs.get_position(self.fig))\n",
    "        ax.set_subplotspec(gs)\n",
    "\n",
    "    def _finalize(self):\n",
    "        plt.close(self.sg.fig)\n",
    "        self.fig.canvas.mpl_connect(\"resize_event\", self._resize)\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def _resize(self, evt=None):\n",
    "        self.sg.fig.set_size_inches(self.fig.get_size_inches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "330f7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance_correlation_coefficient(y_true, y_pred):\n",
    "    \"\"\"Concordance correlation coefficient.\"\"\"\n",
    "    \n",
    "    y_true = y_true.ravel().reshape(-1,)\n",
    "    y_pred = y_pred.ravel().reshape(-1,)\n",
    "    # Remove NaNs\n",
    "    df = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "    df = df.dropna()\n",
    "    y_true = df['y_true']\n",
    "    y_pred = df['y_pred']\n",
    "    # Pearson product-moment correlation coefficients\n",
    "    cor = np.corrcoef(y_true, y_pred)[0][1]\n",
    "    # Mean\n",
    "    mean_true = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    # Variance\n",
    "    var_true = np.var(y_true)\n",
    "    var_pred = np.var(y_pred)\n",
    "    # Standard deviation\n",
    "    sd_true = np.std(y_true)\n",
    "    sd_pred = np.std(y_pred)\n",
    "    # Calculate CCC\n",
    "    numerator = 2 * cor * sd_true * sd_pred\n",
    "    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1569405b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBS_AFR</th>\n",
       "      <th>LABELS_gmt</th>\n",
       "      <th>LABELS</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>UNITS_gmt</th>\n",
       "      <th>V_RANGE</th>\n",
       "      <th>V_RANGE_AFR</th>\n",
       "      <th>CMAPS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBS_REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CTD</th>\n",
       "      <td>CTD</td>\n",
       "      <td>CTD</td>\n",
       "      <td>CTD</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>SI</td>\n",
       "      <td>Shape index</td>\n",
       "      <td>Shape index</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAB</th>\n",
       "      <td>LAB</td>\n",
       "      <td>LAB</td>\n",
       "      <td>LAB</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(0, 300)</td>\n",
       "      <td>(50, 250)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOHO</th>\n",
       "      <td>MOHO</td>\n",
       "      <td>Moho</td>\n",
       "      <td>Moho</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(15, 60)</td>\n",
       "      <td>(20, 50)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SV</th>\n",
       "      <td>SV_SPEED</td>\n",
       "      <td>S@_v@ 150km</td>\n",
       "      <td>$S_v$ @150km</td>\n",
       "      <td>$\\delta$$S_v$ %</td>\n",
       "      <td>km/s</td>\n",
       "      <td>(-0.075, 0.075)</td>\n",
       "      <td>(-0.075, 0.075)</td>\n",
       "      <td>SCM/roma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV</th>\n",
       "      <td>PV_SPEED</td>\n",
       "      <td>P@_v@ 150km</td>\n",
       "      <td>$P_v$ @150km</td>\n",
       "      <td>$\\delta$$P_v$ %</td>\n",
       "      <td>km/s</td>\n",
       "      <td>(-0.02, 0.02)</td>\n",
       "      <td>(-0.02, 0.02)</td>\n",
       "      <td>SCM/roma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <td>GEOID</td>\n",
       "      <td>Geoid</td>\n",
       "      <td>Geoid</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>(-45, 45)</td>\n",
       "      <td>(-45, 45)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEM</th>\n",
       "      <td>DEM</td>\n",
       "      <td>DEM</td>\n",
       "      <td>DEM</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>(-2200, 2200)</td>\n",
       "      <td>(-2200, 2200)</td>\n",
       "      <td>SCM/oleron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FA</th>\n",
       "      <td>FA</td>\n",
       "      <td>Free air</td>\n",
       "      <td>Free air</td>\n",
       "      <td>mGal</td>\n",
       "      <td>mGal</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>BG</td>\n",
       "      <td>Bouguer</td>\n",
       "      <td>Bouguer</td>\n",
       "      <td>mGal</td>\n",
       "      <td>mGal</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMAG2_CLASS</th>\n",
       "      <td>EMAG2</td>\n",
       "      <td>Mag.</td>\n",
       "      <td>Mag.</td>\n",
       "      <td>f(nT)</td>\n",
       "      <td>f(nT)</td>\n",
       "      <td>(-0.4, 0.4)</td>\n",
       "      <td>(-200, 200)</td>\n",
       "      <td>SCM/bilbao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RHO_L</th>\n",
       "      <td>RHO_L</td>\n",
       "      <td>Lith. rho</td>\n",
       "      <td>Lith. ρ</td>\n",
       "      <td>kg/m$^3$</td>\n",
       "      <td>kg/m@+3@+</td>\n",
       "      <td>(3260, 3360)</td>\n",
       "      <td>(3260, 3360)</td>\n",
       "      <td>SCM/batlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RHO_C</th>\n",
       "      <td>RHO_C</td>\n",
       "      <td>Crust rho</td>\n",
       "      <td>Crust ρ</td>\n",
       "      <td>kg/m$^3$</td>\n",
       "      <td>kg/m@+3@+</td>\n",
       "      <td>(2650, 2950)</td>\n",
       "      <td>(2650, 2950)</td>\n",
       "      <td>SCM/batlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOLC_DIST_W</th>\n",
       "      <td>VOLC_DIST</td>\n",
       "      <td>Volcano</td>\n",
       "      <td>Volcano</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(0, 100)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REG</th>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>class</td>\n",
       "      <td>class</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>gmt/categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLIM</th>\n",
       "      <td>GLIM</td>\n",
       "      <td>GliM</td>\n",
       "      <td>GliM</td>\n",
       "      <td>class</td>\n",
       "      <td>class</td>\n",
       "      <td>(1, 16)</td>\n",
       "      <td>(1, 15)</td>\n",
       "      <td>gmt/categorical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               OBS_AFR   LABELS_gmt        LABELS            UNITS  UNITS_gmt          V_RANGE      V_RANGE_AFR            CMAPS\n",
       "OBS_REF                                                                                                                         \n",
       "CTD                CTD          CTD           CTD               km         km          (0, 50)          (0, 50)       SCM/bamako\n",
       "SI                  SI  Shape index   Shape index               si         si          (-1, 1)          (-1, 1)         SCM/broc\n",
       "LAB                LAB          LAB           LAB               km         km         (0, 300)        (50, 250)       SCM/bamako\n",
       "MOHO              MOHO         Moho          Moho               km         km         (15, 60)         (20, 50)       SCM/bamako\n",
       "SV            SV_SPEED  S@_v@ 150km  $S_v$ @150km  $\\delta$$S_v$ %       km/s  (-0.075, 0.075)  (-0.075, 0.075)         SCM/roma\n",
       "PV            PV_SPEED  P@_v@ 150km  $P_v$ @150km  $\\delta$$P_v$ %       km/s    (-0.02, 0.02)    (-0.02, 0.02)         SCM/roma\n",
       "GEOID            GEOID        Geoid         Geoid                m          m        (-45, 45)        (-45, 45)       SCM/bamako\n",
       "DEM                DEM          DEM           DEM                m          m    (-2200, 2200)    (-2200, 2200)       SCM/oleron\n",
       "FA                  FA     Free air      Free air             mGal       mGal      (-100, 100)      (-100, 100)         SCM/broc\n",
       "BG                  BG      Bouguer       Bouguer             mGal       mGal      (-100, 100)      (-100, 100)         SCM/broc\n",
       "EMAG2_CLASS      EMAG2         Mag.          Mag.            f(nT)      f(nT)      (-0.4, 0.4)      (-200, 200)       SCM/bilbao\n",
       "RHO_L            RHO_L    Lith. rho       Lith. ρ         kg/m$^3$  kg/m@+3@+     (3260, 3360)     (3260, 3360)       SCM/batlow\n",
       "RHO_C            RHO_C    Crust rho       Crust ρ         kg/m$^3$  kg/m@+3@+     (2650, 2950)     (2650, 2950)       SCM/batlow\n",
       "VOLC_DIST_W  VOLC_DIST      Volcano       Volcano               km         km           (0, 1)         (0, 100)         SCM/broc\n",
       "REG                REG          REG           REG            class      class           (1, 6)           (1, 6)  gmt/categorical\n",
       "GLIM              GLIM         GliM          GliM            class      class          (1, 16)          (1, 15)  gmt/categorical"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = pd.DataFrame()\n",
    "\n",
    "\n",
    "obs[\"OBS_REF\"] = [\"CTD\" ,  \"SI\",\"LAB\", \"MOHO\",\n",
    "            \"SV\",\"PV\", \n",
    "            \"GEOID\",\"FA\",\"DEM\",\"BG\", \"EMAG2_CLASS\",\n",
    "                   \"RHO_L\", \"RHO_C\", \n",
    "                  \"VOLC_DIST_W\", \"REG\", \"GLIM\"]\n",
    "\n",
    "obs[\"OBS_AFR\"] = [\"CTD\" ,  \"SI\",\"LAB\", \"MOHO\",\n",
    "            \"SV_SPEED\",\"PV_SPEED\", \n",
    "            \"GEOID\",\"FA\",\"DEM\",\"BG\", \"EMAG2\",\n",
    "                   \"RHO_L\", \"RHO_C\", \n",
    "                  \"VOLC_DIST\", \"REG\", \"GLIM\"]\n",
    "  \n",
    "     \n",
    "# Labels for plots etc\n",
    "\n",
    "\n",
    "# Labels for plots etc\n",
    "obs[\"LABELS_gmt\"] = [\"CTD\",  \"Shape index\", \"LAB\", \"Moho\", \n",
    "                \"S@_v@ 150km\", \"P@_v@ 150km\", \n",
    "                \"Geoid\", \"Free air\", \"DEM\", \"Bouguer\", \"Mag.\", \n",
    "                \"Lith. rho\", \"Crust rho\",  \n",
    "                 \"Volcano\", \"REG\", \"GliM\", ]  \n",
    "\n",
    "\n",
    "obs[\"LABELS\"] = [\"CTD\",  \"Shape index\", \"LAB\", \"Moho\", \n",
    "                \"$S_v$ @150km\", \"$P_v$ @150km\", \n",
    "                \"Geoid\", \"Free air\", \"DEM\", \"Bouguer\", \"Mag.\", \n",
    "                \"Lith. ρ\", \"Crust ρ\",  \n",
    "                 \"Volcano\", \"REG\", \"GliM\", ]\n",
    "    \n",
    "# \"vp/vs\"\n",
    "# Units to display in plots etc\n",
    "obs[\"UNITS\"] = [\"km\",  \"si\", \"km\", \"km\",\n",
    "             \"$\\delta$$S_v$ %\",\"$\\delta$$P_v$ %\", \n",
    "             \"m\", \"mGal\", \"m\", \"mGal\",  \"f(nT)\", \n",
    "                 \"kg/m$^3$\", \"kg/m$^3$\",\n",
    "                \"km\",  \"class\", \"class\"]\n",
    "\n",
    "\n",
    "\n",
    "obs[\"UNITS_gmt\"] = [\"km\",  \"si\", \"km\", \"km\",\n",
    "             \"km/s\",\"km/s\", \n",
    "             \"m\", \"mGal\", \"m\", \"mGal\",  \"f(nT)\", \n",
    "                 \"kg/m@+3@+\", \"kg/m@+3@+\",\n",
    "                \"km\",  \"class\", \"class\"]\n",
    "        \n",
    "# Range of colormap for plots. Similar data are placed in same ranges for consistancy\n",
    "obs[\"V_RANGE\"] = [(0,50), (-1,1),(0,300),(15,60),\n",
    "              (-0.075,0.075), (-0.02,0.02), \n",
    "              (-45,45), (-100,100) , (-2200, 2200),(-100,100),  (-0.4, 0.4), \n",
    "                   (3260, 3360), (2650, 2950),\n",
    "                  (0,1), (1,6),(1,16),]\n",
    "\n",
    "\n",
    "    \n",
    "obs[\"V_RANGE_AFR\"] = [(0,50), (-1,1),(50,250),(20,50),\n",
    "          (-0.075,0.075), (-0.02,0.02), \n",
    "          (-45,45), (-100,100) , (-2200, 2200),(-100,100),  (-200, 200), \n",
    "               (3260, 3360), (2650, 2950),\n",
    "              (0,100), (1,6),(1,15),]\n",
    "\n",
    "\n",
    "obs[\"CMAPS\"] = [\"batlow\",  \"broc\", \"bamako\", \"batlow\", \n",
    "             \"roma\",\"roma\", \n",
    "             \"bamako\", \"broc\", \"bukavu\", \"broc\", \"batlow\",            \n",
    "                \"batlow\", \"batlow\",\n",
    "               \"bamako\",  \"batlowS\",\"categorical\", ]\n",
    "\n",
    "obs[\"CMAPS\"] = [\"SCM/bamako\",  \"SCM/broc\", \"SCM/bamako\", \"SCM/bamako\", \n",
    "             \"SCM/roma\",\"SCM/roma\", \n",
    "             \"SCM/bamako\", \"SCM/broc\", \"SCM/oleron\", \"SCM/broc\", \"SCM/bilbao\",            \n",
    "                \"SCM/batlow\", \"SCM/batlow\",\n",
    "               \"SCM/broc\",  \"gmt/categorical\",\"gmt/categorical\", ]\n",
    "\n",
    "new_index = [0,1,2,3,4,5,6,8,7,9,10,11,12,13,14,15]\n",
    "\n",
    "#new_index = [4,3,15,6,7,0, 14, 10,16, 8, 9,2, 13, 12, 8, 11, ]\n",
    "\n",
    "obs = obs.reindex(new_index)\n",
    "\n",
    "#obs.index = np.arange(0,len(obs))\n",
    "\n",
    "pd.options.display.width = 370\n",
    "pd.options.display.max_colwidth = 16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "obs_dict = obs.to_dict(orient='records')\n",
    "\n",
    "obs.set_index(['OBS_REF'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52e68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_afr_lr = xr.load_dataset(DIR/'Grids'/'inputs'/\"ds_afr_lr.nc\")\n",
    "#ds_afr_hr = xr.load_dataset(DIR/'Grids'/'inputs'/\"ds_afr_hr.nc\")\n",
    "#ds_world = xr.load_dataset(dir_p/'Grids'/'inputs'/\"ds_world.nc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d31693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CTD',\n",
       " 'SI',\n",
       " 'LAB',\n",
       " 'MOHO',\n",
       " 'SV',\n",
       " 'PV',\n",
       " 'GEOID',\n",
       " 'DEM',\n",
       " 'FA',\n",
       " 'BG',\n",
       " 'EMAG2_CLASS',\n",
       " 'RHO_L',\n",
       " 'RHO_C',\n",
       " 'VOLC_DIST_W',\n",
       " 'REG',\n",
       " 'GLIM',\n",
       " 'lon',\n",
       " 'lat',\n",
       " 'grid_index_world',\n",
       " 'grid_index_afr',\n",
       " 'GHF']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "target = 'GHF'\n",
    "coord = ['lon', 'lat']\n",
    "grid_index_world = 'grid_index_world'\n",
    "grid_index_afr ='grid_index_afr'\n",
    "\n",
    "#######\n",
    "\n",
    "features_ex = []\n",
    "features_ghf = []\n",
    "\n",
    "\n",
    "\n",
    "features = obs.index.to_list()\n",
    "\n",
    "\n",
    "\n",
    "in_features = set(features)\n",
    "\n",
    "features_ex = copy.deepcopy(features)\n",
    "features_ex.extend(coord)\n",
    "features_ex.append(grid_index_world)\n",
    "features_ex.append(grid_index_afr)\n",
    "\n",
    "features_ex.append(target)\n",
    "\n",
    "features_ghf = copy.deepcopy(features)\n",
    "features_ghf.append(target)\n",
    "\n",
    "\n",
    "features_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e3ded5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OD_ra\n",
      "799\n",
      "5509\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTD</th>\n",
       "      <th>SI</th>\n",
       "      <th>LAB</th>\n",
       "      <th>MOHO</th>\n",
       "      <th>SV</th>\n",
       "      <th>PV</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>DEM</th>\n",
       "      <th>FA</th>\n",
       "      <th>BG</th>\n",
       "      <th>EMAG2_CLASS</th>\n",
       "      <th>RHO_L</th>\n",
       "      <th>RHO_C</th>\n",
       "      <th>VOLC_DIST_W</th>\n",
       "      <th>REG</th>\n",
       "      <th>GLIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.000000</td>\n",
       "      <td>799.0</td>\n",
       "      <td>799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>411.0</td>\n",
       "      <td>457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.017066</td>\n",
       "      <td>0.030498</td>\n",
       "      <td>136.025183</td>\n",
       "      <td>34.442175</td>\n",
       "      <td>0.023422</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>11.520035</td>\n",
       "      <td>235.173967</td>\n",
       "      <td>4.616344</td>\n",
       "      <td>-16.312394</td>\n",
       "      <td>0.015309</td>\n",
       "      <td>3324.199985</td>\n",
       "      <td>2792.000906</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.140022</td>\n",
       "      <td>0.421621</td>\n",
       "      <td>37.543080</td>\n",
       "      <td>4.709578</td>\n",
       "      <td>0.030488</td>\n",
       "      <td>0.006705</td>\n",
       "      <td>12.331826</td>\n",
       "      <td>661.092576</td>\n",
       "      <td>25.053288</td>\n",
       "      <td>69.224221</td>\n",
       "      <td>0.115164</td>\n",
       "      <td>28.816931</td>\n",
       "      <td>36.720293</td>\n",
       "      <td>0.064216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.465931</td>\n",
       "      <td>-0.838243</td>\n",
       "      <td>64.424635</td>\n",
       "      <td>14.861654</td>\n",
       "      <td>-0.064826</td>\n",
       "      <td>-0.016766</td>\n",
       "      <td>-19.335741</td>\n",
       "      <td>-2548.000000</td>\n",
       "      <td>-33.854423</td>\n",
       "      <td>-175.794751</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3260.876553</td>\n",
       "      <td>2705.605972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.717975</td>\n",
       "      <td>-0.320227</td>\n",
       "      <td>96.247014</td>\n",
       "      <td>31.498866</td>\n",
       "      <td>-0.001366</td>\n",
       "      <td>-0.000530</td>\n",
       "      <td>5.965246</td>\n",
       "      <td>-48.000000</td>\n",
       "      <td>-21.852249</td>\n",
       "      <td>-49.585525</td>\n",
       "      <td>-0.034223</td>\n",
       "      <td>3311.783852</td>\n",
       "      <td>2767.350431</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.583212</td>\n",
       "      <td>0.034901</td>\n",
       "      <td>155.569360</td>\n",
       "      <td>34.002274</td>\n",
       "      <td>0.037129</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>8.570286</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>1.837202</td>\n",
       "      <td>5.990976</td>\n",
       "      <td>0.042244</td>\n",
       "      <td>3339.757499</td>\n",
       "      <td>2793.378738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.969939</td>\n",
       "      <td>0.258787</td>\n",
       "      <td>165.820080</td>\n",
       "      <td>36.405059</td>\n",
       "      <td>0.044109</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>18.541397</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>22.423387</td>\n",
       "      <td>30.180507</td>\n",
       "      <td>0.065555</td>\n",
       "      <td>3343.708290</td>\n",
       "      <td>2810.677714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.587565</td>\n",
       "      <td>0.958196</td>\n",
       "      <td>221.425165</td>\n",
       "      <td>48.227529</td>\n",
       "      <td>0.077389</td>\n",
       "      <td>0.029473</td>\n",
       "      <td>54.581686</td>\n",
       "      <td>2489.000000</td>\n",
       "      <td>109.765254</td>\n",
       "      <td>135.872088</td>\n",
       "      <td>0.438907</td>\n",
       "      <td>3371.878973</td>\n",
       "      <td>2888.931047</td>\n",
       "      <td>0.964264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CTD          SI         LAB        MOHO          SV          PV       GEOID          DEM          FA          BG  EMAG2_CLASS        RHO_L        RHO_C  VOLC_DIST_W    REG   GLIM\n",
       "count   799.000000  799.000000  799.000000  799.000000  799.000000  799.000000  799.000000   799.000000  799.000000  799.000000   799.000000   799.000000   799.000000   799.000000  799.0  799.0\n",
       "unique         NaN         NaN         NaN         NaN         NaN         NaN         NaN          NaN         NaN         NaN          NaN          NaN          NaN          NaN    5.0   11.0\n",
       "top            NaN         NaN         NaN         NaN         NaN         NaN         NaN          NaN         NaN         NaN          NaN          NaN          NaN          NaN    1.0   15.0\n",
       "freq           NaN         NaN         NaN         NaN         NaN         NaN         NaN          NaN         NaN         NaN          NaN          NaN          NaN          NaN  411.0  457.0\n",
       "mean     29.017066    0.030498  136.025183   34.442175    0.023422    0.002800   11.520035   235.173967    4.616344  -16.312394     0.015309  3324.199985  2792.000906     0.007204    NaN    NaN\n",
       "std       6.140022    0.421621   37.543080    4.709578    0.030488    0.006705   12.331826   661.092576   25.053288   69.224221     0.115164    28.816931    36.720293     0.064216    NaN    NaN\n",
       "min      21.465931   -0.838243   64.424635   14.861654   -0.064826   -0.016766  -19.335741 -2548.000000  -33.854423 -175.794751    -1.000000  3260.876553  2705.605972     0.000000    NaN    NaN\n",
       "25%      24.717975   -0.320227   96.247014   31.498866   -0.001366   -0.000530    5.965246   -48.000000  -21.852249  -49.585525    -0.034223  3311.783852  2767.350431     0.000000    NaN    NaN\n",
       "50%      26.583212    0.034901  155.569360   34.002274    0.037129    0.004450    8.570286   -12.000000    1.837202    5.990976     0.042244  3339.757499  2793.378738     0.000000    NaN    NaN\n",
       "75%      30.969939    0.258787  165.820080   36.405059    0.044109    0.004784   18.541397   520.000000   22.423387   30.180507     0.065555  3343.708290  2810.677714     0.000000    NaN    NaN\n",
       "max      56.587565    0.958196  221.425165   48.227529    0.077389    0.029473   54.581686  2489.000000  109.765254  135.872088     0.438907  3371.878973  2888.931047     0.964264    NaN    NaN"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "rating = 'ra'\n",
    "outlier = 'OD'\n",
    "\n",
    "\n",
    "file_label = f'{outlier}_{rating}'\n",
    "\n",
    "w_OD_ra_f =  DIR/'Dataset'/'Preprocessed'/f'W_OD_ra.csv'\n",
    "W_OD_ra = pd.read_csv(w_OD_ra_f, sep='\\t')\n",
    "\n",
    "#mask_afr = W_OD_ra['lon'].between(afr_lon_min, afr_lon_max)& W_OD_ra['lat'].between(afr_lat_min, afr_lat_max)\n",
    "#Afr_OD_ra = W_OD_ra[~mask_afr]\n",
    "\n",
    "\n",
    "Afr_OD_ra_lr_f =  DIR/'Dataset'/'Preprocessed'/f'Afr_OD_ra_lr.csv'\n",
    "Afr_OD_ra_lr = pd.read_csv(Afr_OD_ra_lr_f,  sep='\\t')\n",
    "\n",
    "\n",
    "Afr_NOD_ra_lr_f =  DIR/'Dataset'/'Preprocessed'/f'Afr_NOD_ra_lr.csv'\n",
    "Afr_NOD_ra_lr = pd.read_csv(Afr_NOD_ra_lr_f,sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "W_OD_ra['GLIM']  = W_OD_ra['GLIM'].astype('category')\n",
    "W_OD_ra['REG']  = W_OD_ra['REG'].astype('category')\n",
    "\n",
    "Afr_OD_ra_lr['GLIM']  = Afr_OD_ra_lr['GLIM'].astype('int').astype('category')\n",
    "Afr_OD_ra_lr['REG']  = Afr_OD_ra_lr['REG'].astype('int').astype('category')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_w = W_OD_ra[features]\n",
    "y_w = W_OD_ra[target].values.reshape(-1,1) \n",
    "\n",
    "X_afr_lr = Afr_OD_ra_lr[features]\n",
    "y_afr_lr = Afr_OD_ra_lr[target].values.reshape(-1,1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X_w.describe(include='all')\n",
    "\n",
    "X_afr_lr.describe(include='all')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bs_rfr_hyp =  DIR/'Hyperparameters'/f'RFR_{file_label}.csv'\n",
    "\n",
    "\n",
    "\n",
    "bs_rfr_hyp_df = pd.read_csv(bs_rfr_hyp, sep='\\t')\n",
    "\n",
    "\n",
    "best_params = bs_rfr_hyp_df.to_dict('list')\n",
    "\n",
    "print(file_label)\n",
    "\n",
    "print(len(Afr_OD_ra_lr))\n",
    "\n",
    "print(len(W_OD_ra))\n",
    "\n",
    "X_afr_lr.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f0c0a",
   "metadata": {},
   "source": [
    "# Pre-evalaution world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37bb9e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized\n",
      "terminated OD_ra\n",
      "optimized\n",
      "terminated NOD_ra\n",
      "terminated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "files = [\n",
    "         'OD_ra',\n",
    "         'NOD_ra',\n",
    "        ]\n",
    "\n",
    "observables = [ \n",
    "            features, \n",
    "            features, \n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "for file_label, observable in zip(files, observables):\n",
    "    \n",
    "     \n",
    "    KPI_W = pd.DataFrame()\n",
    "    \n",
    "    #### training\n",
    "    w_f =  DIR/ 'Dataset'/'Preprocessed'/f'W_{file_label}.csv'\n",
    "\n",
    "    W = pd.read_csv(w_f, sep='\\t')\n",
    "\n",
    "    \n",
    "    X = W[observable] \n",
    "    y = W[target]\n",
    "    X['GLIM']  = X['GLIM'].astype('int').astype('category')\n",
    "    X['REG']  = X['REG'].astype('int').astype('category')\n",
    "\n",
    "    X['GLIM']  = X['GLIM'].astype('int').astype('category')\n",
    "    X['REG']  = X['REG'].astype('int').astype('category')\n",
    "    \n",
    "    X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # hyperparameter\n",
    "    bs_rfr_hyp =  DIR/'Hyperparameters'/f'RFR_{file_label}.csv'\n",
    "\n",
    "\n",
    "    bs_rfr_hyp_df = pd.read_csv(bs_rfr_hyp, sep='\\t')\n",
    "\n",
    "\n",
    "    best_params = bs_rfr_hyp_df.to_dict('list')\n",
    "\n",
    "\n",
    "    # Load hyper parameter \n",
    "\n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "\n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"regressor\", regressor)]\n",
    "\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "\n",
    "\n",
    "\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_predict = model_pipeline.predict(X_test)\n",
    "\n",
    "    print('optimized')\n",
    "\n",
    "    errors      = abs(y_test - y_predict)\n",
    "    mape        = round( mean_absolute_percentage_error(y_test, y_predict), 2)  \n",
    "    accuracy    = round(100 - mape*100, 2)\n",
    "    mae         = round(mean_absolute_error(y_test, y_predict ), 2)\n",
    "    rmse        = round(mean_squared_error(y_test, y_predict , squared=False), 2)\n",
    "    nrmse       = round( rmse/(y_test.mean()) , 2)\n",
    "    r2          = round(r2_score(y_test, y_predict ), 2)\n",
    "    ev          = round( explained_variance_score(y_test, y_predict), 2)\n",
    "    max_e       = round( max_error(y_test, y_predict), 2)\n",
    "    min_e       = round( errors.min(), 2)\n",
    "    mnae        = round( median_absolute_error(y_test, y_predict), 2) \n",
    "    #mpd         = round( mean_poisson_deviance(y_test, y_predict), 2) \n",
    "    #mgd         = round( mean_gamma_deviance(y_test, y_predict), 2) \n",
    "    # # Mean Absolute Error (MAE)\n",
    "    mpe         =  round(np.mean((y_test -y_predict)/y_test) , 2)\n",
    "    ccc         =   round( concordance_correlation_coefficient(y_test, y_predict), 2) \n",
    "\n",
    "\n",
    "\n",
    "    KPI_W.loc['NRMSE', f'{file_label}'] = nrmse\n",
    "    KPI_W.loc['RMSE', f'{file_label}'] = rmse\n",
    "    KPI_W.loc['MAE', f'{file_label}'] = mae\n",
    "    KPI_W.loc['MAPE', f'{file_label}'] = mape\n",
    "    KPI_W.loc['$R^2$', f'{file_label}'] = r2\n",
    "    KPI_W.loc['EV', f'{file_label}'] = ev\n",
    "    KPI_W.loc['MAX_E', f'{file_label}'] = max_e\n",
    "    KPI_W.loc['MIN_E', f'{file_label}'] = min_e\n",
    "    KPI_W.loc['MedAE', f'{file_label}'] = mnae\n",
    "    KPI_W.loc['MPE', f'{file_label}'] = mpe\n",
    "    KPI_W.loc['MAX', f'{file_label}'] = round(y_predict.max(),1)\n",
    "    KPI_W.loc['MIN', f'{file_label}'] = y_predict.min()\n",
    "    KPI_W.loc['ACC', f'{file_label}'] = accuracy\n",
    "    KPI_W.loc['Mean', f'{file_label}'] = round(np.mean(y_predict),2)\n",
    "    KPI_W.loc['Median', f'{file_label}'] = round(np.median(y_predict),2)\n",
    "    KPI_W.loc['Stdev', f'{file_label}'] = round(np.std(y_predict),2)\n",
    "    KPI_W.loc['RSD', f'{file_label}'] = round(np.std(y_predict) / np.mean(y_predict) ,2)\n",
    "    KPI_W.loc['CCC', f'{file_label}'] = ccc\n",
    "    #save results\n",
    "    kpi_f =  DIR/'KPI'/f'KPI_{file_label}.csv'\n",
    "\n",
    "    KPI_W.to_csv(kpi_f , sep='\\t')\n",
    "    \n",
    "    \n",
    "    print(f'terminated {file_label}')\n",
    "\n",
    "print('terminated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d94cb2c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 4 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29296\\910790695.py\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mKPI_W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtmp_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKPI_W\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mKPI_W\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Without Anomalies IDW'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'With Anomalies IDW'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Initialize auc_score dictionary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AFQ2\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5586\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5587\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5588\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5589\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5590\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AFQ2\\lib\\site-packages\\pandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AFQ2\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 769\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    770\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AFQ2\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\AFQ2\\lib\\site-packages\\pandas\\core\\internals\\base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     70\u001b[0m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 4 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "KPI_W = pd.DataFrame()\n",
    "files = [filename for filename in os.listdir(DIR/'KPI')  if 'ra' in filename]\n",
    "for file in zip(files):\n",
    "    path = DIR/'KPI'/f'{file[0]}'\n",
    "    tmp_df = pd.read_csv(path, index_col=0, sep='\\t')\n",
    "    KPI_W = pd.concat([tmp_df, KPI_W], axis=1)\n",
    "    \n",
    "KPI_W.columns = ['Without Anomalies IDW', 'With Anomalies IDW']\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "\n",
    "# Set figure size and create barplot\n",
    "\n",
    "fig, axs = plt.subplots(2,2,figsize=(35, 20))\n",
    "\n",
    "sns.set(font_scale = 4)\n",
    "\n",
    "#fig.set_size_inches(30,30)\n",
    "\n",
    "#scores = ['RMSE', 'NRMSE','MAE', 'MAPE', 'CD','EV', 'MAX_E','MIN_E' ,'MedAE', 'MPE']\n",
    "scores = ['RMSE', 'MAE', 'NRMSE','MAPE', 'CD','EV', 'MAX_E', 'MAX', 'Stdev', \n",
    "          'RSD', 'Mean','Median','MedAE', 'MPE', 'ACC', 'CCC']\n",
    "\n",
    "scores = ['NRMSE','$R^2$','MAX_E', 'MAX']\n",
    "#subfile = 'HOD'\n",
    "#files_rg = [ x for x in files_rg if subfile in x ]\n",
    "for score, ax in zip(scores, axs.flatten()):\n",
    "\n",
    "\n",
    "\n",
    "    if score in ['$R^2$','EV' ,'Max', 'MPE', 'ACC','CCC']:\n",
    "        x_data = KPI_W.loc[score, :].sort_values(ascending=False).index\n",
    "        y_data = KPI_W.loc[score,:].sort_values(ascending=False)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0])\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        x_data = KPI_W.loc[score,:].sort_values().index\n",
    "        y_data = KPI_W.loc[score,:].sort_values()\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0], )\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "#  fig.savefig(DIR/'fig'/\"fig_s4.jpeg\", bbox_inches='tight', dpi=300 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429523d6",
   "metadata": {},
   "source": [
    "# Pre-evalaution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 10 \n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "KPI_afr_lr = pd.DataFrame()\n",
    "results_W = pd.DataFrame()\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) * -1\n",
    "\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for best_features in range(8,16):  \n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "\n",
    "    rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe),   (\"regressor\", regressor)]\n",
    "\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "\n",
    "\n",
    "\n",
    "    model_pipeline.fit(X_afr_lr, y_afr_lr)\n",
    "\n",
    "    \n",
    "    y_predict = model_pipeline.predict(X_afr_lr)\n",
    "    \n",
    "\n",
    "    KPI_afr_lr.loc['NRMSE', f'RFE_{best_features}'] = nrmse(y_afr_lr, y_predict) *-1\n",
    "    KPI_afr_lr.loc['RMSE', f'RFE_{best_features}'] =mean_squared_error(y_afr_lr, y_predict, squared=False) \n",
    "    KPI_afr_lr.loc['MAE', f'RFE_{best_features}'] = mean_absolute_error(y_afr_lr, y_predict)  \n",
    "    KPI_afr_lr.loc['MAPE', f'RFE_{best_features}'] = mean_absolute_percentage_error(y_afr_lr, y_predict) \n",
    "    KPI_afr_lr.loc['CD', f'RFE_{best_features}'] = r2_score(y_afr_lr, y_predict)\n",
    "    KPI_afr_lr.loc['EV', f'RFE_{best_features}'] = explained_variance_score(y_afr_lr, y_predict)\n",
    "    KPI_afr_lr.loc['CCC', f'RFE_{best_features}'] = concordance_correlation_coefficient(y_afr_lr, y_predict)\n",
    "    KPI_afr_lr.loc['MAX', f'RFE_{best_features}'] = y_predict.max()\n",
    "    KPI_afr_lr.loc['MIN', f'RFE_{best_features}'] = y_predict.min()\n",
    "    \n",
    "    KPI_afr_lr.loc['MAX_E',  f'RFE_{best_features}'] = round( max_error(y_afr_lr, y_predict), 3)\n",
    "    KPI_afr_lr.loc['MedAE',  f'RFE_{best_features}'] = round( median_absolute_error(y_afr_lr, y_predict), 3) \n",
    "    KPI_afr_lr.loc['MPE',  f'RFE_{best_features}'] = round(np.mean((y_afr_lr -y_predict)/y_afr_lr) , 3)\n",
    "    KPI_afr_lr.loc['ACC',  f'RFE_{best_features}'] = round(100 - mean_absolute_percentage_error(y_afr_lr, y_predict) *100, 3)\n",
    "    KPI_afr_lr.loc['Mean',  f'RFE_{best_features}'] = round(np.mean(y_predict),3)\n",
    "    KPI_afr_lr.loc['Median',  f'RFE_{best_features}'] = round(np.median(y_predict),3)\n",
    "    KPI_afr_lr.loc['Stdev',  f'RFE_{best_features}'] = round(np.std(y_predict),3)\n",
    "    KPI_afr_lr.loc['RSD',  f'RFE_{best_features}'] = round(np.std(y_predict) / np.mean(y_predict) ,3)\n",
    "    \n",
    "       \n",
    "  \n",
    "\n",
    "    \n",
    "    results_W[f'RFE_{best_features}'] =y_predict.reshape(-1,)\n",
    "    # Print message to user\n",
    "    print('#'*60)\n",
    "\n",
    "\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "\n",
    "scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "numeric_transformer = scaler\n",
    "\n",
    "categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "   (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe), (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "# Initialize Pipeline object\n",
    "pipeline= Pipeline(steps = steps)\n",
    "\n",
    "model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "\n",
    "model_pipeline.fit(X_afr_lr, y_afr_lr)\n",
    "\n",
    "\n",
    "y_predict = model_pipeline.predict(X_afr_lr)\n",
    "\n",
    "\n",
    "KPI_afr_lr.loc['NRMSE', f'RFE_{best_features}'] = nrmse(y_afr_lr, y_predict) *-1\n",
    "KPI_afr_lr.loc['RMSE', f'RFE_{best_features}'] =mean_squared_error(y_afr_lr, y_predict, squared=False) \n",
    "KPI_afr_lr.loc['MAE', f'RFE_{best_features}'] = mean_absolute_error(y_afr_lr, y_predict)  \n",
    "KPI_afr_lr.loc['MAPE', f'RFE_{best_features}'] = mean_absolute_percentage_error(y_afr_lr, y_predict) \n",
    "KPI_afr_lr.loc['CD', f'RFE_{best_features}'] = r2_score(y_afr_lr, y_predict)\n",
    "KPI_afr_lr.loc['EV', f'RFE_{best_features}'] = explained_variance_score(y_afr_lr, y_predict)\n",
    "KPI_afr_lr.loc['CCC', f'RFE_{best_features}'] = concordance_correlation_coefficient(y_afr_lr, y_predict)\n",
    "KPI_afr_lr.loc['MAX', f'RFE_{best_features}'] = y_predict.max()\n",
    "KPI_afr_lr.loc['MIN', f'RFE_{best_features}'] = y_predict.min()\n",
    "\n",
    "KPI_afr_lr.loc['MAX_E',  f'RFE_{best_features}'] = round( max_error(y_afr_lr, y_predict), 3)\n",
    "KPI_afr_lr.loc['MedAE',  f'RFE_{best_features}'] = round( median_absolute_error(y_afr_lr, y_predict), 3) \n",
    "KPI_afr_lr.loc['MPE',  f'RFE_{best_features}'] = round(np.mean((y_afr_lr -y_predict)/y_afr_lr) , 3)\n",
    "KPI_afr_lr.loc['ACC',  f'RFE_{best_features}'] = round(100 - mean_absolute_percentage_error(y_afr_lr, y_predict) *100, 3)\n",
    "KPI_afr_lr.loc['Mean',  f'RFE_{best_features}'] = round(np.mean(y_predict),3)\n",
    "KPI_afr_lr.loc['Median',  f'RFE_{best_features}'] = round(np.median(y_predict),3)\n",
    "KPI_afr_lr.loc['Stdev',  f'RFE_{best_features}'] = round(np.std(y_predict),3)\n",
    "KPI_afr_lr.loc['RSD',  f'RFE_{best_features}'] = round(np.std(y_predict) / np.mean(y_predict) ,3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "results_W[f'RFE_{best_features}'] =y_predict.reshape(-1,)\n",
    "# Print message to user\n",
    "print('#'*60)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbd077",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "\n",
    "# Set figure size and create barplot\n",
    "\n",
    "fig, axs = plt.subplots(8,2,figsize=(15, 40))\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 2)\n",
    "#fig.set_size_inches(30,30)\n",
    "\n",
    "#scores = ['RMSE', 'NRMSE','MAE', 'MAPE', 'CD','EV', 'MAX_E','MIN_E' ,'MedAE', 'MPE']\n",
    "\n",
    "scores = ['RMSE', 'MAE', 'NRMSE','MAPE', 'CD','EV', 'MAX_E', 'MAX', \n",
    "          'Stdev', 'RSD', 'Mean','Median','MedAE', 'MPE', 'ACC', 'CCC']\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 2)\n",
    "n_models = 30\n",
    "#subfile = 'HOD'\n",
    "#files_rg = [ x for x in files_rg if subfile in x ]\n",
    "for score, ax in zip(scores, axs.flatten()):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    cols  = KPI_afr_lr.loc[score,:].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "\n",
    "    if score in ['CD','EV' ,'MAX', 'MPE', 'ACC','CCC']:\n",
    "        \n",
    "        \n",
    "        x_data = KPI_afr_lr.loc[score,cols].sort_values(ascending=False).index\n",
    "        y_data = KPI_afr_lr.loc[score,cols].sort_values(ascending=False).round(2)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0])\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        x_data = KPI_afr_lr.loc[score,cols].sort_values().index\n",
    "        y_data = KPI_afr_lr.loc[score,cols].sort_values().round(2)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0], )\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e03c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ['RMSE', 'MAE', 'NRMSE','MAPE', 'CD','EV', 'MAX_E', 'MAX', 'Stdev', 'RSD', 'Mean','Median','MedAE', 'MPE', 'Acc']\n",
    "# False ['CD','EV' ,'MAX', 'MPE']\n",
    "\n",
    "#len(KPI_afr_lr)\n",
    "n_models = 10\n",
    "\n",
    "rfe_range = [col  for col in KPI_afr_lr.columns]\n",
    "\n",
    "score = 'NRMSE'\n",
    "columns_W = KPI_afr_lr.loc[score,rfe_range].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "results_W['y'] = y_afr_lr\n",
    "\n",
    "\n",
    "threshold = 20\n",
    "\n",
    "for column in columns_W[:n_models]:\n",
    "    mask = np.abs(results_W['y'] - results_W[column]) > threshold\n",
    "    y_predict = results_W[column]\n",
    "    \n",
    "    g0 =sns.jointplot( x=column, y='y', data=results_W, kind='reg', size=12,   ratio=4, \n",
    "                        marginal_kws={'lw':1, 'color':'blue'}, \n",
    "                  scatter_kws={\"color\": \"grey\", \"edgecolor\":\"w\"}, line_kws={\"color\": \"blue\"},\n",
    "    label=   \n",
    "    f'''\n",
    "    best fit\n",
    "    {column}\n",
    "    RMSE     = {round(KPI_afr_lr.loc['RMSE', column],2)}\n",
    "    NRMSE    = {round(KPI_afr_lr.loc['NRMSE', column],2)} %\n",
    "    MAE      = {round(KPI_afr_lr.loc['MAE', column],2)}\n",
    "    MAPE     = {round(KPI_afr_lr.loc['MAPE', column],2)} %\n",
    "    MAX       = {round(KPI_afr_lr.loc['MAX', column],2)}\n",
    "    RSD       = {round(KPI_afr_lr.loc['RSD', column],2)}\n",
    "    $R^2$    = {round(KPI_afr_lr.loc['CD', column],2)}\n",
    "    Total count    : {len(y_predict) - len(y_predict[mask])}   \n",
    "        ''' )\n",
    "\n",
    "    sns.regplot([results_W[column].min(), results_W[column].max()], [results_W['y'].min(), results_W['y'].max()], \\\n",
    "                ci=None, scatter=False, ax= g0.ax_joint, line_kws={\"color\": \"grey\", 'ls':'--'} , label = 'Identity')\n",
    "\n",
    "    sns.scatterplot(results_W[column][mask],results_W['y'][mask], color=\"#ce1414\",\\\n",
    "                    s=30,  ax= g0.ax_joint, edgecolor=\"white\",\n",
    "    label = \n",
    "    f'''Error > {threshold}    = {len(y_predict[mask])}\n",
    "    Realtive error       = {round(len(y_predict[mask]) / len(y_predict), 1)  *100} %\n",
    "\n",
    "    ''' )\n",
    "\n",
    "    g0.set_axis_labels( '$\\hat{y}$','$_y$', fontsize=30, fontweight='bold')\n",
    "    g0.fig.suptitle('PREDICTED vs ACTUAL',fontsize=20)\n",
    "\n",
    "    g0.ax_marg_y.grid('on') \n",
    "\n",
    "    #plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    #####\n",
    "    \n",
    "    g1 = sns.jointplot( x=column, y='y', data=results_W, kind=\"resid\", size=12, \n",
    "                         line_kws={\"color\": \"blue\", 'lowess':True, 'robust':True},     \n",
    "                         )\n",
    "\n",
    "\n",
    "    #plot.ax_joint.axvline(x=6)\n",
    "    g1.ax_joint.axhline(y=threshold )\n",
    "    g1.ax_joint.axhline(y=-threshold)\n",
    "\n",
    "\n",
    "    g1.set_axis_labels('$_y$', 'Residuals', fontsize=30, fontweight='bold')\n",
    "    g1.fig.suptitle(column,fontsize=20)\n",
    "\n",
    "    g1.ax_marg_y.grid('on') \n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(16,9))\n",
    "    fig.set_size_inches(16,9)\n",
    "\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 2)\n",
    "\n",
    "    mg0 = SeabornFig2Grid(g0, fig, gs[0])\n",
    "    mg1 = SeabornFig2Grid(g1, fig, gs[1])\n",
    "\n",
    "    gs.tight_layout(fig)\n",
    "\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cf0b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    " \n",
    "kfold = 5\n",
    "\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) \n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "ccc_score = make_scorer(concordance_correlation_coefficient , greater_is_better=True)\n",
    "\n",
    "scoring = {\n",
    "    'NRMSE':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    'CD':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'CCC': ccc_score,\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "results ={}\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize RFECV object\n",
    "    feature_selector = RFECV(regressor, cv = cv, step = 1, #n_jobs=-1, \n",
    "                             scoring = score, verbose = 1)\n",
    "    \n",
    "\n",
    "    # Fit RFECV\n",
    "    feature_selector .fit(X_afr_lr, np.ravel(y_afr_lr))\n",
    "    results[key] = feature_selector\n",
    "\n",
    "    # Get selected features\n",
    "    #feature_names = X_corr.columns\n",
    "    #selected_features = feature_names[feature_selector.support_].tolist()\n",
    "\n",
    "    print(f'terminated {key} {score}\\n')\n",
    "    print('terminated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d05794",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for key, score in scoring.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X_afr_lr.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "    if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "        plt.plot(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1)*-1, label=key)\n",
    "        plt.scatter(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1)*-1, marker='x')\n",
    "\n",
    "    else:\n",
    "        plt.plot(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1), label=key)\n",
    "        plt.scatter(range(1, len(results[key].grid_scores_) + 1), results[key].grid_scores_.mean(axis=1), marker='x')\n",
    "        \n",
    "    \n",
    "    plt.xlabel(\"Number of features selected\")\n",
    "    plt.ylabel(\"Cross validation score\")\n",
    "    plt.legend(loc=[.79,0.26])\n",
    "plt.axvline(results[key].n_features_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a878fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "# Set figure size and create barplot\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "regressor_label = 'RFR'\n",
    "\n",
    "# Load hyper parameter \n",
    "\n",
    "regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X_afr_lr, y_afr_lr).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X_afr_lr[selected_features],y_afr_lr)\n",
    "\n",
    "#obs.set_index('OBS_REF', inplace=True)\n",
    "selected_labels = obs.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"observable\"])\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "feature_importance[\"LABELS\"]= obs.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "feature_importance.set_index('observable', inplace=True)\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "\n",
    "sns.barplot(x = feature_importance[\"Relative Importance\"], \n",
    "            y = feature_importance[\"LABELS\"],\n",
    "            palette = reversed(sns.color_palette('YlOrRd', best_features)))\n",
    "\n",
    "\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "#ax.set_title(f'{sub_figs[0]})', loc ='left', pad=20,   y=1.1)\n",
    "\n",
    "#obs.reset_index(inplace=True)\n",
    "\n",
    "# Save Figure\n",
    "#plt.savefig(\"feature_importance.png\", dpi = 1080)\n",
    "\n",
    " #['LAB', 'RHO_C', 'SV', 'PV', 'CTD', 'RHO_L', 'DEM', 'VOLC_DIST_W', 'A_MEDIAN_W', 'SI', 'GEOID']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6431a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ebd8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sorted_features = obs.reset_index(drop=False).set_index('LABELS')\n",
    "\n",
    "\n",
    "\n",
    "selected_features = []\n",
    "\n",
    "for best_feature in range(16,3, -1):\n",
    "    selected_features.extend([sorted_features.loc[feature_importance.index, 'OBS_REF'].values[0 :best_feature]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3af2f8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline_dict = {}\n",
    "grids_dict = {}\n",
    "selected_features_dict = {}\n",
    "\n",
    "\n",
    "best_features = ['16', '15','14', '13','12', '11','10',\n",
    "                 '09','08', '07','06','05','04'\n",
    "                 ]\n",
    "\n",
    "\n",
    "scoring = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "\n",
    "kfold =10\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "\n",
    "label = 'AFR' \n",
    "\n",
    "for best_feature, selected_feature in zip(best_features ,selected_features) :\n",
    "\n",
    "    y_Afr = Afr_OD_ra_lr[target]\n",
    "    x_Afr = Afr_OD_ra_lr[selected_feature]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "    \n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[ (\"preprocessor\", preprocessor),  (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "    \n",
    "    trained_model = model_pipeline.fit(x_Afr, y_Afr )\n",
    "    \n",
    "   \n",
    "\n",
    "    ######### save\n",
    "\n",
    "   \n",
    "    pipeline_dict[f'RFE_{best_feature}'] = trained_model\n",
    "    \n",
    "    #grids_dict[f'RFE_{best_feature}'] =  ds_afr[selected_feature].to_array().values\n",
    "    \n",
    "    selected_features_dict[f'RFE_{best_feature}']   = selected_feature\n",
    "\n",
    "    print(f'RFE_{best_feature} fitting is terminated' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31573a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "grids_dict = {}\n",
    "\n",
    "n_features = ['16','15', '14', '13', '12', '11', '10', '09', '08', '07', '06', '05', '04']\n",
    "for selected_feature, n_feature in tqdm_notebook(zip(selected_features, n_features), total = len(n_features),\n",
    "                                      desc= f'{selected_feature}: ' ):\n",
    "    df = pd.DataFrame({'X': ds_afr_lr.XV.values.ravel(), 'Y': ds_afr_lr.YV.values.ravel()})\n",
    "\n",
    "    for feature in tqdm_notebook(selected_feature , \n",
    "                                            desc=f'Processing: ', leave=False ):\n",
    "        sleep(0.01)\n",
    "        df[feature] = ds_afr_lr[feature].values.ravel()\n",
    "    grids_dict[f'RFE_{n_feature}'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0a5c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = {}\n",
    "xs = range(len(ds_afr_lr.X))\n",
    "ys = range(len(ds_afr_lr.Y))\n",
    "nn = (len(ds_afr_lr.Y), len( ds_afr_lr.X))\n",
    "\n",
    "\n",
    "hq_gt = Afr_OD_ra_lr[[grid_index_afr, target]].set_index(grid_index_afr)\n",
    "hq_gt.index.names = ['index']\n",
    "\n",
    "for key, pipeline  in tqdm_notebook(pipeline_dict.items() , \n",
    "                                            desc=f'Modelling: '):\n",
    "    print(key)\n",
    "    pipeline = pipeline_dict[key]\n",
    "    AFR_Q_RFR = np.zeros(nn) # predicted HF value\n",
    "    AFR_grid = grids_dict[key][selected_features_dict[key]]\n",
    "    predictions_df[key] = pd.DataFrame({'X': ds_afr_lr.XV.values.ravel(), 'Y': ds_afr_lr.YV.values.ravel()})\n",
    "\n",
    "    if 'GLIM' in selected_features_dict[key]:\n",
    "        AFR_grid['GLIM']  = AFR_grid['GLIM'].astype('int').astype('category')\n",
    "    if 'REG' in selected_features_dict[key]:\n",
    "        AFR_grid['REG']  = AFR_grid['REG'].astype('int').astype('category')\n",
    "    predictions_df[key]['Prediction'] = pipeline.predict(AFR_grid).reshape(-1,1)\n",
    "    predictions_df[key].index.names = ['index']\n",
    "    final_df = pd.merge(predictions_df[key], hq_gt,  how=\"left\", on=\"index\")\n",
    "    final_df.to_csv(DIR/'Grids'/'Outputs'/f'{key}_ra.csv' , index=False, header=True, sep='\\t')\n",
    "    ds_afr_lr[key] = (('Y', 'X'), predictions_df[key]['Prediction'].values.reshape(nn) )\n",
    "    \n",
    "ds_afr_lr.to_netcdf(DIR/'Grids'/'Outputs'/\"ds_afr_rfr_ra_lr.nc\", mode='w', \n",
    "                    engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72065084",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
