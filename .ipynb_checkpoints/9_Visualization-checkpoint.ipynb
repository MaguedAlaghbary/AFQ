{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agrid.grid import Grid\n",
    "from pathlib import Path\n",
    "import os, sys, pickle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "\n",
    "from scipy import stats, interpolate, spatial, io\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Arc \n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import pyproj as proj\n",
    "import rasterio\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numba as nb\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# helper function for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer , r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import gstools as gst\n",
    "from pykrige.rk import RegressionKriging\n",
    "import operator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "import pygmt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder , PowerTransformer\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor ,  ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b30f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parent directory\n",
    "\n",
    "#parent directory\n",
    "\n",
    "dir_p = Path().resolve() \n",
    "\n",
    "src_crs=4326\n",
    "src_crs_aus = 3577\n",
    "    \n",
    "#constants\n",
    "km = 1000\n",
    "milli = 0.001\n",
    "micro = 0.000001\n",
    "\n",
    "# fig size for presentation\n",
    "fig_pres_small = (4,3)\n",
    "\n",
    "fig_pres_small_cbar = (4,2)\n",
    "#aspect ratio\n",
    "fig_pres_large = (16,9)\n",
    "\n",
    "\n",
    "\n",
    "# We can exclude Arctic ocean and Antarctica, as there are no HF measurements to use\n",
    "world_lon_min, world_lon_max, world_lat_min, world_lat_max  = -180, 180, -60, 80\n",
    "\n",
    "# map extents of Africa and Australia\n",
    "afr_lon_min, afr_lon_max, afr_lat_min, afr_lat_max =  -20, 52, -37 , 38  \n",
    "aus_lon_min, aus_lon_max, aus_lat_min, aus_lat_max =  108,  156 , -45, -10\n",
    "\n",
    "\n",
    "# create grid for each region\n",
    "# crs Coordinate reference system\n",
    "\n",
    "#EPSG is projection\n",
    "# 0.2 degrees equal roughly 20 km\n",
    "\n",
    "World = Grid(res=[0.2, 0.2], up=world_lat_max, down=world_lat_min)\n",
    "\n",
    "# africa grid\n",
    "\n",
    "Africa =    Grid(res=[0.2, 0.2],  left = afr_lon_min, right= afr_lon_max, up=afr_lat_max , down=afr_lat_min)\n",
    "\n",
    "# africa grid low resolution 50 x 50 km\n",
    "\n",
    "Africa_50 =    Grid(res=[0.5, 0.5],  left = afr_lon_min, right= afr_lon_max, up=afr_lat_max , down=afr_lat_min)\n",
    "\n",
    "\n",
    "# to be added as verification set\n",
    "Aus = Grid(crs=3577, res = [20*km, 20*km], extent=[-2000*km, 2200*km, -5000*km, -1200*km])\n",
    "\n",
    "\n",
    "#dictionary of all grids\n",
    "\n",
    "grids = {}\n",
    "\n",
    "grids['Afr'] = Africa\n",
    "grids['Afr_50'] = Africa_50\n",
    "grids['Aus'] = Aus\n",
    "grids['World'] = World\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SeabornFig2Grid():\n",
    "\n",
    "    def __init__(self, seaborngrid, fig,  subplot_spec):\n",
    "        self.fig = fig\n",
    "        self.sg = seaborngrid\n",
    "        self.subplot = subplot_spec\n",
    "        if isinstance(self.sg, sns.axisgrid.FacetGrid) or \\\n",
    "            isinstance(self.sg, sns.axisgrid.PairGrid):\n",
    "            self._movegrid()\n",
    "        elif isinstance(self.sg, sns.axisgrid.JointGrid):\n",
    "            self._movejointgrid()\n",
    "        self._finalize()\n",
    "\n",
    "    def _movegrid(self):\n",
    "        \"\"\" Move PairGrid or Facetgrid \"\"\"\n",
    "        self._resize()\n",
    "        n = self.sg.axes.shape[0]\n",
    "        m = self.sg.axes.shape[1]\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(n,m, subplot_spec=self.subplot)\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                self._moveaxes(self.sg.axes[i,j], self.subgrid[i,j])\n",
    "\n",
    "    def _movejointgrid(self):\n",
    "        \"\"\" Move Jointgrid \"\"\"\n",
    "        h= self.sg.ax_joint.get_position().height\n",
    "        h2= self.sg.ax_marg_x.get_position().height\n",
    "        r = int(np.round(h/h2))\n",
    "        self._resize()\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(r+1,r+1, subplot_spec=self.subplot)\n",
    "\n",
    "        self._moveaxes(self.sg.ax_joint, self.subgrid[1:, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_x, self.subgrid[0, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_y, self.subgrid[1:, -1])\n",
    "\n",
    "    def _moveaxes(self, ax, gs):\n",
    "        #https://stackoverflow.com/a/46906599/4124317\n",
    "        ax.remove()\n",
    "        ax.figure=self.fig\n",
    "        self.fig.axes.append(ax)\n",
    "        self.fig.add_axes(ax)\n",
    "        ax._subplotspec = gs\n",
    "        ax.set_position(gs.get_position(self.fig))\n",
    "        ax.set_subplotspec(gs)\n",
    "\n",
    "    def _finalize(self):\n",
    "        plt.close(self.sg.fig)\n",
    "        self.fig.canvas.mpl_connect(\"resize_event\", self._resize)\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def _resize(self, evt=None):\n",
    "        self.sg.fig.set_size_inches(self.fig.get_size_inches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance_correlation_coefficient(y_true, y_pred):\n",
    "    \"\"\"Concordance correlation coefficient.\"\"\"\n",
    "    # Remove NaNs\n",
    "    df = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "    df = df.dropna()\n",
    "    y_true = df['y_true']\n",
    "    y_pred = df['y_pred']\n",
    "    # Pearson product-moment correlation coefficients\n",
    "    cor = np.corrcoef(y_true, y_pred)[0][1]\n",
    "    # Mean\n",
    "    mean_true = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    # Variance\n",
    "    var_true = np.var(y_true)\n",
    "    var_pred = np.var(y_pred)\n",
    "    # Standard deviation\n",
    "    sd_true = np.std(y_true)\n",
    "    sd_pred = np.std(y_pred)\n",
    "    # Calculate CCC\n",
    "    numerator = 2 * cor * sd_true * sd_pred\n",
    "    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ease looping with dictionaries\n",
    "\n",
    "regions_a_a5 = [ 'Afr','Afr_50' ]\n",
    "\n",
    "regions_w_a = [ 'World' ,'Afr',]\n",
    "\n",
    "\n",
    "regions_w_a_a5 = [ 'World' ,'Afr', 'Afr_50']\n",
    "\n",
    "\n",
    "regions_Total = ['World' ,'Afr', 'Afr_50',]\n",
    "\n",
    "# raster exenets to adjust map\n",
    "raster_extent_Afr = [grids['Afr'].extent[0], grids['Afr'].extent[1], grids['Afr'].extent[3], grids['Afr'].extent[2]]\n",
    "raster_extent_Afr_50 = [grids['Afr_50'].extent[0], grids['Afr_50'].extent[1], grids['Afr_50'].extent[3], grids['Afr_50'].extent[2]]\n",
    "raster_extent_World = [grids['World'].extent[0], grids['World'].extent[1], grids['World'].extent[3], grids['World'].extent[2]]\n",
    "\n",
    "# to correct plot maps\n",
    "raster_extents = {}\n",
    "\n",
    "raster_extents['Afr'] = raster_extent_Afr\n",
    "raster_extents['Afr_50'] = raster_extent_Afr_50\n",
    "raster_extents['World'] = raster_extent_World\n",
    "\n",
    "\n",
    "# list of latitudes and longitudes\n",
    "lon_dict = {}\n",
    "lat_dict = {}\n",
    "\n",
    "lon_dict['Afr'] = [afr_lon_min, afr_lon_max]\n",
    "lon_dict['Afr_50'] = [afr_lon_min, afr_lon_max]\n",
    "lon_dict['World'] = [world_lon_min, world_lon_max]\n",
    "\n",
    "lat_dict['Afr'] = [afr_lat_min, afr_lat_max]\n",
    "lat_dict['Afr_50'] = [afr_lat_min, afr_lat_max]\n",
    "lat_dict['World'] = [world_lat_min, world_lat_max]\n",
    "\n",
    "\n",
    "print('terminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fcb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/nvkelso/natural-earth-vector\n",
    "# natural earth 10 m land shape\n",
    "ne_10m_land = dir_p / 'data'/ 'Shapefiles'/'NE'/ 'ne_10m_land.shp'\n",
    "continents = dir_p /'data'/ 'Shapefiles'/'continents'/ 'continent.shp'\n",
    "\n",
    "# LAND is water vs land\n",
    "#Continet describes each continent\n",
    "\n",
    "#assign_shape Rasterize vector polygons to grid \n",
    "\n",
    "for region in regions_a_a5:\n",
    "    # Use continental plates instead\n",
    "    grids[region].ds['LAND'] = (('Y', 'X'), grids[region].assign_shape(ne_10m_land, \n",
    "                                               'scalerank', map_to_int = False, burn_val = 1))\n",
    "\n",
    "\n",
    "    grids[region].ds['CONTINENT'] = (('Y', 'X'), grids[region].assign_shape(continents, \n",
    "                                               'CONTINENT', map_to_int = True))\n",
    "\n",
    "\n",
    "\n",
    "    grids[region].map_grid('CONTINENT', raster_extent= raster_extents[region], \n",
    "                          cmap='jet', figsize=(10,10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de9a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pd.DataFrame()\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "obs[\"REF_n\"] = [ \"MOHO\",\"LAB\", \"RHO_C\", \"SV\", \"PV\", \"CTD\",\n",
    "             \"RHO_L\", \"DEM\", \n",
    "                \"VOLC_DIST_W\", \"A_MEDIAN_W\", \"FA\", \"SI\",\"LITH_MANTLE\", \n",
    "                \"EMAG2_CLASS\", \"GEOID\", \"BG\",\n",
    "              \"GLIM\"]\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "obs[\"OBS_REF_IDW\"] = [\"CTD_IDW\" ,  \"SI_IDW\",\"LAB_IDW\", \"MOHO_IDW\",\n",
    "            \"SV_IDW\",\"PV_IDW\", \n",
    "            \"GEOID_IDW\",\"FA_IDW\",\"DEM\",\"BG_IDW\", \"EMAG2_CLASS\",\n",
    "                   \"RHO_L_IDW\", \"RHO_C_IDW\", \n",
    "                  \"VOLC_DIST_W\", \"REG\", \"GLIM\"]\n",
    "\n",
    "\n",
    "\n",
    "obs[\"OBS_REF_LN\"] = [\"CTD_LN\" ,  \"SI_LN\",\"LAB_LN\", \"MOHO_LN\",\n",
    "            \"SV_LN\",\"PV_LN\", \n",
    "            \"GEOID_LN\",\"FA_LN\",\"DEM\",\"BG_LN\", \"EMAG2_CLASS\",\n",
    "                  \"RHO_L_LN\", \"RHO_C_LN\", \n",
    "                      \"VOLC_DIST_W\",\"REG\", \"GLIM\"]\n",
    "\n",
    "obs[\"OBS_AFR_IDW\"] = [\"CTD_IDW\" ,  \"SI_IDW\",\"LAB_IDW\", \"MOHO_IDW\",\n",
    "            \"SV_SPEED_IDW\",\"PV_SPEED_IDW\", \n",
    "            \"GEOID_IDW\",\"FA_IDW\",\"DEM\",\"BG_IDW\", \"EMAG2\",\n",
    "                   \"RHO_L_IDW\", \"RHO_C_IDW\", \n",
    "                  \"VOLC_DIST\", \"REG\", \"GLIM\"]\n",
    "  \n",
    "     \n",
    "# Labels for plots etc\n",
    "obs[\"LABELS\"] = [\"CTD\",  \"Shape index\", \"LAB\", \"Moho\", \n",
    "                \"S@_v@ 150km\", \"P@_v@ 150km\", \n",
    "                \"Geoid\", \"Free air\", \"DEM\", \"Bouguer\", \"Mag.\", \n",
    "                \"Lith. rho\", \"Crust rho\",  \n",
    "                 \"Volcano\", \"REG\", \"GliM\", ]  \n",
    "\n",
    "\n",
    "obs[\"LABELS\"] = [\"CTD\",  \"Shape index\", \"LAB\", \"Moho\", \n",
    "                \"$S_v$ @150km\", \"$P_v$ @150km\", \n",
    "                \"Geoid\", \"Free air\", \"DEM\", \"Bouguer\", \"Mag.\", \n",
    "                \"Lith. ρ\", \"Crust ρ\",  \n",
    "                 \"Volcano\", \"REG\", \"GliM\", ]\n",
    "    \n",
    "# \"vp/vs\"\n",
    "# Units to display in plots etc\n",
    "obs[\"UNITS\"] = [\"km\",  \"si\", \"km\", \"km\",\n",
    "             \"$\\delta$ v_s %\",\"$\\delta$ v_p %\", \n",
    "             \"m\", \"mGal\", \"m\", \"mGal\",  \"f(nT)\", \n",
    "                 \"kg/m$^3$\", \"kg/m$^3$\",\n",
    "                \"km\",  \"class\", \"class\"]\n",
    "\n",
    "\n",
    "\n",
    "obs[\"UNITS\"] = [\"km\",  \"si\", \"km\", \"km\",\n",
    "             \"km/s\",\"km/s\", \n",
    "             \"m\", \"mGal\", \"m\", \"mGal\",  \"nT\", \n",
    "                 \"kg/m@+3@+\", \"kg/m@+3@+\",\n",
    "                \"km\",  \"class\", \"class\"]\n",
    "        \n",
    "# Range of colormap for plots. Similar data are placed in same ranges for consistancy\n",
    "obs[\"V_RANGE\"] = [(0,50), (-1,1),(0,300),(15,60),\n",
    "              (-0.075,0.075), (-0.02,0.02), \n",
    "              (-45,45), (-100,100) , (-2200, 2200),(-100,100),  (-0.4, 0.4), \n",
    "                   (3260, 3360), (2650, 2950),\n",
    "                  (0,1), (1,6),(1,16),]\n",
    "\n",
    "\n",
    "    \n",
    "obs[\"V_RANGE_AFR\"] = [(0,50), (-1,1),(50,250),(20,50),\n",
    "          (-0.075,0.075), (-0.02,0.02), \n",
    "          (-45,45), (-100,100) , (-2200, 2200),(-100,100),  (-200, 200), \n",
    "               (3260, 3360), (2650, 2950),\n",
    "              (0,100), (1,6),(1,15),]\n",
    "\n",
    "\n",
    "obs[\"CMAPS\"] = [\"batlow\",  \"broc\", \"bamako\", \"batlow\", \n",
    "             \"roma\",\"roma\", \n",
    "             \"bamako\", \"broc\", \"bukavu\", \"broc\", \"batlow\",            \n",
    "                \"batlow\", \"batlow\",\n",
    "               \"bamako\",  \"batlowS\",\"topo\", ]\n",
    "\n",
    "\n",
    "#new_index = [4,3,15,6,7,0,14,10,16,17,9, 2,1,5,13,12, 8,11,]\n",
    "\n",
    "#new_index = [4,3,15,6,7,0, 14, 10,16, 8, 9,2, 13, 12, 8, 11, ]\n",
    "\n",
    "#obs = obs.reindex(new_index)\n",
    "\n",
    "obs.index = np.arange(0,len(obs))\n",
    "\n",
    "pd.options.display.width = 370\n",
    "pd.options.display.max_colwidth = 12\n",
    "print(obs)\n",
    "\n",
    "n_obs = len(obs)\n",
    "\n",
    "obs_dict = obs.to_dict(orient=\"records\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969658c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'heat-flow (mW/m2)'\n",
    "coord = ['lon', 'lat']\n",
    "\n",
    "\n",
    "\n",
    "#features_ex_idw = []\n",
    "#features_ex_ln = []\n",
    "\n",
    "\n",
    "features_idw = obs['OBS_REF_IDW'].tolist()\n",
    "features_ln = obs['OBS_REF_LN'].tolist()\n",
    "\n",
    "\n",
    "#in_features_idw = set(features_idw)\n",
    "#in_features_ln = set(features_ln)\n",
    "\n",
    "#in_features_ln_but_not_in_features_idw = in_features_ln - in_features_idw\n",
    "\n",
    "#features_all = features_idw + list(in_features_ln_but_not_in_features_idw)\n",
    "\n",
    "\n",
    "features_ex_idw = copy.deepcopy(features_idw)\n",
    "features_ex_idw.extend(coord)\n",
    "features_ex_idw.append(target)\n",
    "\n",
    "\n",
    "features_ex_ln = copy.deepcopy(features_ln)\n",
    "features_ex_ln.extend(coord)\n",
    "features_ex_ln.append(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a87d3",
   "metadata": {},
   "source": [
    "# ABC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8e6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rating = 'rabc'\n",
    "outlier = 'NOD'\n",
    "\n",
    "file_label = f'{outlier}_{rating}'\n",
    "\n",
    "\n",
    "train_Afr_50_f =  dir_p/'data'/'dataset'/'Preprocessed'/f'Training_Afr_50_{file_label}.csv'\n",
    "train_Afr_50 = pd.read_csv(train_Afr_50_f)\n",
    "\n",
    "\n",
    "train_Afr_50['GLIM']  = train_Afr_50['GLIM'].astype('int').astype('category')\n",
    "train_Afr_50['REG']  = train_Afr_50['REG'].astype('int').astype('category')\n",
    "\n",
    "\n",
    "\n",
    "X_train_afr = train_Afr_50[features_idw]\n",
    "y_train_afr = train_Afr_50[target].values.reshape(-1,1) \n",
    "\n",
    "\n",
    "\n",
    "X_train_afr.describe(include='all')\n",
    "\n",
    "\n",
    "bs_rfr_hyp =  dir_p/'RF_Hyperparameters'/f'RFR_{outlier}_IDW_rab.csv'\n",
    "\n",
    "\n",
    "\n",
    "bs_rfr_hyp_df = pd.read_csv(bs_rfr_hyp, sep='\\t')\n",
    "\n",
    "\n",
    "best_params = bs_rfr_hyp_df.to_dict('list')\n",
    "\n",
    "print(file_label)\n",
    "\n",
    "X_train_afr.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "training_Afr_50_rabc_f =  dir_p/'data'/'dataset'/'Preprocessed'/'Training_Afr_50_NOD_rabc.csv'\n",
    "training_Afr_50_rabc = pd.read_csv(training_Afr_50_rabc_f)\n",
    "\n",
    "#######\n",
    "\n",
    "\n",
    "\n",
    "training_Afr_50_rabc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85330e39",
   "metadata": {},
   "source": [
    "# Visualiazation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed9ce22",
   "metadata": {},
   "source": [
    "# AFR 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7cc48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'Afr_50'\n",
    "path_grd_RK_rabc_lr = dir_p/'Grids'/'outputs'/'AFR_50'/f'RK_gaussian_6_RFE_11_rabc.nc'\n",
    "path_grd_RF_rabc_lr = dir_p/'Grids'/'outputs'/'AFR_50'/f'RF_gaussian_6_RFE_11_rabc.nc'\n",
    "\n",
    "grids[region].ds[f'RK_11_rabc'] = (('Y', 'X'), grids[region].read_raster(\n",
    "    path_grd_RK_rabc_lr , src_crs=src_crs))\n",
    "grids[region].ds[f'RF_11_rabc'] = (('Y', 'X'), grids[region].read_raster(\n",
    "    path_grd_RF_rabc_lr , src_crs=src_crs))\n",
    "\n",
    "\n",
    "Afr_50_Q_RK_rabc_lr = pd.DataFrame(grids[region].ds[f'RK_11_rabc'].T.values.reshape(-1,1))\n",
    "Afr_50_Q_RF_rabc_lr = pd.DataFrame(grids[region].ds[f'RF_11_rabc'].T.values.reshape(-1,1))\n",
    "\n",
    "lon = pd.DataFrame(grids[region].lon.T.reshape(-1,1))\n",
    "lat = pd.DataFrame(grids[region].lat.T.reshape(-1,1))\n",
    "\n",
    "df_Afr_50_rabc_lr = pd.concat([lon, lat, Afr_50_Q_RK_rabc_lr, Afr_50_Q_RF_rabc_lr,\n",
    "                          ] , axis=1).dropna()\n",
    "\n",
    "df_Afr_50_rabc_lr.columns = ['lon', 'lat','Q_RK', 'Q_RF']\n",
    "\n",
    "\n",
    "df_Afr_50_RK_rabc_lr = df_Afr_50_rabc_lr[['lon', 'lat','Q_RK']]\n",
    "data_RK_rabc_lr = df_Afr_50_RK_rabc_lr.values\n",
    "\n",
    "df_Afr_50_RF_rabc_lr = df_Afr_50_rabc_lr[['lon', 'lat','Q_RF']]\n",
    "data_RF_rabc_lr = df_Afr_50_RF_rabc_lr.values\n",
    "\n",
    "\n",
    "\n",
    "df_Afr_50_OK_rabc_lr = df_Afr_50_rabc_lr[['lon', 'lat']]\n",
    "df_Afr_50_OK_rabc_lr['Q_OK'] = df_Afr_50_rabc_lr['Q_RK'] - df_Afr_50_rabc_lr['Q_RF']\n",
    "data_OK_rabc_lr =  df_Afr_50_OK_rabc_lr.values \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_test_rabc_lr =  training_Afr_50_rabc[target]\n",
    "\n",
    "y_pred_RK_rabc_lr =  grids[region].ds[f'RK_11_rabc'].values.ravel()[training_Afr_50_rabc['grid_index']]\n",
    "y_pred_RF_rabc_lr =  grids[region].ds[f'RF_11_rabc'].values.ravel()[training_Afr_50_rabc['grid_index']]\n",
    "\n",
    "len(y_pred_RF_rabc_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'Afr_50'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "\n",
    "file_rfe = '11'\n",
    "\n",
    "\n",
    "label_ra_lr = [ label for label in labels_RK_ra_lr if file_rfe in label]\n",
    "\n",
    "\n",
    "label_rab_lr = [ label for label in labels_RK_rab_lr if file_rfe in label]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Afr_50_Q_RK_rab_lr = pd.DataFrame(grids[region].ds[f'RK_{label_rab_lr[0][-6:]}'].T.values.reshape(-1,1))\n",
    "Afr_50_Q_RF_rab_lr = pd.DataFrame(grids[region].ds[f'RF_{label_rab_lr[0][-6:]}'].T.values.reshape(-1,1))\n",
    "\n",
    "Afr_50_Q_RK_ra_lr = pd.DataFrame(grids[region].ds[f'RK_{label_ra_lr[0][-5:]}'].T.values.reshape(-1,1))\n",
    "Afr_50_Q_RF_ra_lr = pd.DataFrame(grids[region].ds[f'RF_{label_ra_lr[0][-5:]}'].T.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "print(f'max b {Afr_50_Q_RK_ra_lr.max()[0]} min {Afr_50_Q_RK_ra_lr.min()[0]}')\n",
    "print(f'max g {Afr_50_Q_RK_rab_lr.max()[0]} min {Afr_50_Q_RK_rab_lr.min()[0]}')\n",
    "\n",
    "lon = pd.DataFrame(grids[region].lon.T.reshape(-1,1))\n",
    "lat = pd.DataFrame(grids[region].lat.T.reshape(-1,1))\n",
    "'''\n",
    "df_Afr_50_rab_lr = pd.concat([lon, lat, Afr_50_Q_RK_rab_lr, Afr_50_Q_RF_rab_lr,\n",
    "                             (predictions_max_min_rab_lr['max'] - predictions_max_min_rab_lr['min'])/2,\n",
    "                          ] , axis=1).dropna()'''\n",
    "\n",
    "df_Afr_50_rab_lr = pd.concat([lon, lat, Afr_50_Q_RK_rab_lr, Afr_50_Q_RF_rab_lr,\n",
    "                             (predictions_max_min_rab_lr['max'] - predictions_max_min_rab_lr['min'])/2,\n",
    "                          ] , axis=1).dropna()\n",
    "\n",
    "df_Afr_50_rab_lr.columns = ['lon', 'lat','Q_RK', 'Q_RF' ,'UNC',]\n",
    "\n",
    "'''df_Afr_50_ra_lr = pd.concat([lon, lat, Afr_50_Q_RK_ra_lr, Afr_50_Q_RF_ra_lr,\n",
    "                         (predictions_max_min_ra_lr['max'] - predictions_max_min_ra_lr['min'])/2,\n",
    "                          ] , axis=1).dropna()'''\n",
    "\n",
    "df_Afr_50_ra_lr = pd.concat([lon, lat, Afr_50_Q_RK_ra_lr, Afr_50_Q_RF_ra_lr,\n",
    "                         (predictions_max_min_rab_lr['max'] - predictions_max_min_rab_lr['min'])/2,\n",
    "                          ] , axis=1).dropna()\n",
    "\n",
    "df_Afr_50_ra_lr.columns = ['lon', 'lat','Q_RK', 'Q_RF', 'UNC',]\n",
    "\n",
    "\n",
    "df_Afr_50_RK_rab_lr = df_Afr_50_rab_lr[['lon', 'lat','Q_RK']]\n",
    "data_RK_rab_lr = df_Afr_50_RK_rab_lr.values\n",
    "\n",
    "df_Afr_50_RK_ra_lr = df_Afr_50_ra_lr[['lon', 'lat','Q_RK']]\n",
    "data_RK_ra_lr = df_Afr_50_RK_ra_lr.values\n",
    "\n",
    "df_Afr_50_RF_rab_lr = df_Afr_50_rab_lr[['lon', 'lat','Q_RF']]\n",
    "data_RF_rab_lr = df_Afr_50_RF_rab_lr.values\n",
    "\n",
    "df_Afr_50_RF_ra_lr = df_Afr_50_ra_lr[['lon', 'lat','Q_RF']]\n",
    "data_RF_ra_lr = df_Afr_50_RF_ra_lr.values\n",
    "\n",
    "df_Afr_50_UNC_rab_lr = df_Afr_50_rab_lr[['lon', 'lat','UNC']]\n",
    "data_UNC_rab_lr = df_Afr_50_UNC_rab_lr.values\n",
    "\n",
    "df_Afr_50_UNC_ra_lr = df_Afr_50_ra_lr[['lon', 'lat','UNC']]\n",
    "data_UNC_ra_lr = df_Afr_50_UNC_ra_lr.values\n",
    "\n",
    "\n",
    "df_Afr_50_Diff_rab_lr = df_Afr_50_rab_lr[['lon', 'lat']]\n",
    "df_Afr_50_Diff_rab_lr['Q_Diff'] = df_Afr_50_rab_lr['Q_RK'] - df_Afr_50_ra_lr['Q_RK']\n",
    "data_Diff_rab_lr =  df_Afr_50_Diff_rab_lr.values \n",
    "\n",
    "df_Afr_50_Diff_ra_lr = df_Afr_50_ra_lr[['lon', 'lat']]\n",
    "df_Afr_50_Diff_ra_lr['Q_Diff'] = df_Afr_50_ra_lr['Q_RK'] - df_Afr_50_rab_lr['Q_RK']\n",
    "data_Diff_ra_lr =  df_Afr_50_Diff_ra_lr.values \n",
    "\n",
    "df_Afr_50_OK_rab_lr = df_Afr_50_rab_lr[['lon', 'lat']]\n",
    "df_Afr_50_OK_rab_lr['Q_OK'] = df_Afr_50_rab_lr['Q_RK'] - df_Afr_50_rab_lr['Q_RF']\n",
    "data_OK_rab_lr =  df_Afr_50_OK_rab_lr.values \n",
    "\n",
    "df_Afr_50_OK_ra_lr = df_Afr_50_ra_lr[['lon', 'lat']]\n",
    "df_Afr_50_OK_ra_lr['Q_OK'] = df_Afr_50_ra_lr['Q_RK'] - df_Afr_50_ra_lr['Q_RF']\n",
    "data_OK_ra_lr =  df_Afr_50_OK_ra_lr.values \n",
    "\n",
    "mu_rab_lr = df_Afr_50_rab_lr['Q_RK'].mean()\n",
    "mu_ra_lr = df_Afr_50_ra_lr['Q_RK'].mean()\n",
    "\n",
    "df_Afr_50_RSD_rab_lr = df_Afr_50_rab_lr[['lon', 'lat']]\n",
    "df_Afr_50_RSD_rab_lr['Q_RSD'] = (np.sqrt((df_Afr_50_rab_lr['Q_RK'] - mu_rab_lr)**2)/ mu_rab_lr)  *100\n",
    "data_RSD_rab_lr =  df_Afr_50_RSD_rab_lr.values \n",
    "\n",
    "df_Afr_50_RSD_ra_lr = df_Afr_50_ra_lr[['lon', 'lat']]\n",
    "df_Afr_50_RSD_ra_lr['Q_RSD'] = (np.sqrt((df_Afr_50_ra_lr['Q_RK'] - mu_ra_lr)**2)/ mu_ra_lr) *100\n",
    "data_RSD_ra_lr =  df_Afr_50_RSD_ra_lr.values \n",
    "\n",
    "\n",
    "prediction_df_ra_lr = pd.DataFrame()\n",
    "\n",
    "prediction_df_ra_lr['y'] = training_Afr_50_ra[target]\n",
    "prediction_df_ra_lr['lat'] = training_Afr_50_ra['lat']\n",
    "prediction_df_ra_lr['lon'] =  training_Afr_50_ra['lon']\n",
    "prediction_df_ra_lr['y_hat_RK'] = grids[region].ds[f'RK_{label_ra_lr[0][-5:]}'].values.ravel()[training_Afr_50_ra['grid_index']]\n",
    "prediction_df_ra_lr['y_hat_RF'] = grids[region].ds[f'RF_{label_ra_lr[0][-5:]}'].values.ravel()[training_Afr_50_ra['grid_index']]\n",
    "\n",
    "\n",
    "prediction_df_ra_lr.dropna(inplace=True)\n",
    "\n",
    "gt_Afr_50_ra_lr_lat = prediction_df_ra_lr['lat'].values\n",
    "gt_Afr_50_ra_lr_lon =  prediction_df_ra_lr['lon'].values\n",
    "y_test_ra_lr = prediction_df_ra_lr['y'].values\n",
    "y_pred_RK_ra_lr = prediction_df_ra_lr['y_hat_RK'].values\n",
    "y_pred_RF_ra_lr = prediction_df_ra_lr['y_hat_RF'].values\n",
    "\n",
    "prediction_df_rab_lr = pd.DataFrame()\n",
    "\n",
    "prediction_df_rab_lr['y'] = training_Afr_50_rab[target]\n",
    "prediction_df_rab_lr['lat'] = training_Afr_50_rab['lat']\n",
    "prediction_df_rab_lr['lon'] =  training_Afr_50_rab['lon']\n",
    "prediction_df_rab_lr['y_hat_RK'] = grids[region].ds[f'RK_{label_rab_lr[0][-6:]}'].values.ravel()[training_Afr_50_rab['grid_index']]\n",
    "prediction_df_rab_lr['y_hat_RF'] = grids[region].ds[f'RF_{label_rab_lr[0][-6:]}'].values.ravel()[training_Afr_50_rab['grid_index']]\n",
    "\n",
    "\n",
    "prediction_df_rab_lr.dropna(inplace=True)\n",
    "\n",
    "gt_Afr_50_rab_lr_lat = prediction_df_rab_lr['lat'].values\n",
    "gt_Afr_50_rab_lr_lon =  prediction_df_rab_lr['lon'].values\n",
    "y_test_rab_lr = prediction_df_rab_lr['y'].values\n",
    "y_pred_RK_rab_lr = prediction_df_rab_lr['y_hat_RK'].values\n",
    "y_pred_RF_rab_lr = prediction_df_rab_lr['y_hat_RF'].values\n",
    "\n",
    "prediction_df_rb_lr = pd.concat([prediction_df_rab_lr, prediction_df_ra_lr])\n",
    "\n",
    "prediction_df_rb_lr.drop_duplicates(['y' , 'lat', 'lon'], keep=False, inplace = True)\n",
    "\n",
    "\n",
    "gt_Afr_50_rb_lr_lat = prediction_df_rb_lr['lat'].values\n",
    "gt_Afr_50_rb_lr_lon =  prediction_df_rb_lr['lon'].values\n",
    "y_test_rb_lr = prediction_df_rb_lr['y'].values\n",
    "y_pred_RK_rb_lr = prediction_df_rb_lr['y_hat_RK'].values\n",
    "y_pred_RF_rb_lr = prediction_df_rb_lr['y_hat_RF'].values\n",
    "\n",
    "resid_rb_lr = (prediction_df_rb_lr['y'] - prediction_df_rb_lr['y_hat_RK'] ).values\n",
    "\n",
    "resid_rab_lr = (prediction_df_rab_lr['y'] - prediction_df_rab_lr['y_hat_RK'] ).values\n",
    " \n",
    "resid_ra_lr = (prediction_df_ra_lr['y']  - prediction_df_ra_lr['y_hat_RK'] ).values\n",
    "\n",
    "\n",
    "print(len(prediction_df_ra_lr))\n",
    "print(len(prediction_df_rb_lr))\n",
    "print(len(prediction_df_rab_lr))\n",
    "\n",
    "print(len(prediction_df_rab_lr[prediction_df_rab_lr['y'] > 125])/len(prediction_df_rab_lr))\n",
    "print(len(prediction_df_rab_lr[prediction_df_rab_lr['y'] < 50])/len(prediction_df_rab_lr))\n",
    "\n",
    "\n",
    "#len(training_Afr_50_rab[target])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "#create two datsets for A ratibng and b ratings\n",
    "HGHF_file = dir_p / 'data' / 'dataset'/ 'Reference'/'q_Heat_flow'/'NGHF.csv'\n",
    "\n",
    "\n",
    "hf = pd.read_csv(HGHF_file)\n",
    "# change heat flow to mili\n",
    "\n",
    "elev_cut = -1000\n",
    "\n",
    "\n",
    "\n",
    "record_total = pd.read_csv(HGHF_file)\n",
    "\n",
    "print(len(record_total))\n",
    "hf_clean = record_total.dropna(subset = ['longitude', 'latitude', 'heat-flow (mW/m2)'])\n",
    "\n",
    "\n",
    "hf_no_pole = hf_clean[hf_clean['latitude'].between(world_lat_min, world_lat_max, inclusive='both')]\n",
    "hf_deep = hf_no_pole[(hf_no_pole['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "hf_final_a = hf_no_pole[(hf_no_pole ['code6']=='A') & (hf_no_pole ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "hf_final_b = hf_no_pole[(hf_no_pole ['code6']=='B') & (hf_no_pole ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "hf_final_c = hf_no_pole[(hf_no_pole ['code6']=='C') & (hf_no_pole ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "hf_final_d = hf_no_pole[(hf_no_pole ['code6']=='D') & (hf_no_pole ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "\n",
    "######A rating\n",
    "\n",
    "hf_final_a.columns = ['lon', 'lat', 'heat-flow (mW/m2)']\n",
    "\n",
    "\n",
    "hf_final_a = hf_final_a.round(3)\n",
    "\n",
    "print(len(hf_final_a))\n",
    "hf_final_a.replace(' ', np.nan, inplace=True)\n",
    "hf_final_a.sort_values(by=['lon', 'lat'], ascending=True, inplace=True)\n",
    "hf_final_a.reset_index( inplace=True,drop=True)\n",
    "\n",
    "assert hf_final_a['lon'].max() <= 180, f\" max lon {hf_final_a['lon'].max()}\"\n",
    "assert hf_final_a['lon'].min() >= -180, f\" min lon {hf_final_a['lon'].min()}\"\n",
    "assert hf_final_a['lat'].max() <= 90, f\" max lat {hf_final_a['lat'].max()}\"\n",
    "assert hf_final_a['lat'].min() >= -90, f\" min lat {hf_final_a['lon'].min()}\"\n",
    "\n",
    "\n",
    "###### A+ B rating\n",
    "\n",
    "hf_final_b.columns = ['lon', 'lat', 'heat-flow (mW/m2)']\n",
    "\n",
    "\n",
    "hf_final_b = hf_final_b.round(3)\n",
    "\n",
    "hf_final_b.replace(' ', np.nan, inplace=True)\n",
    "hf_final_b.sort_values(by=['lon', 'lat'], ascending=True, inplace=True)\n",
    "hf_final_b.reset_index( inplace=True,drop=True)\n",
    "\n",
    "\n",
    "assert hf_final_b['lon'].max() <= 180, f\" max lon {hf_final_b['lon'].max()}\"\n",
    "assert hf_final_b['lon'].min() >= -180, f\" min lon {hf_final_b['lon'].min()}\"\n",
    "assert hf_final_b['lat'].max() <= 90, f\" max lat {hf_final_b['lat'].max()}\"\n",
    "assert hf_final_b['lat'].min() >= -90, f\" min lat {hf_final_b['lon'].min()}\"\n",
    "\n",
    "\n",
    "\n",
    "###### A+ B + C rating\n",
    "\n",
    "hf_final_c.columns = ['lon', 'lat', 'heat-flow (mW/m2)']\n",
    "\n",
    "\n",
    "hf_final_c = hf_final_c.round(3)\n",
    "\n",
    "hf_final_c.replace(' ', np.nan, inplace=True)\n",
    "hf_final_c.sort_values(by=['lon', 'lat'], ascending=True, inplace=True)\n",
    "hf_final_c.reset_index( inplace=True,drop=True)\n",
    "print(len(hf_final_c))\n",
    "\n",
    "assert hf_final_c['lon'].max() <= 180, f\" max lon {hf_final_c['lon'].max()}\"\n",
    "assert hf_final_c['lon'].min() >= -180, f\" min lon {hf_final_c['lon'].min()}\"\n",
    "assert hf_final_c['lat'].max() <= 90, f\" max lat {hf_final_c['lat'].max()}\"\n",
    "assert hf_final_c['lat'].min() >= -90, f\" min lat {hf_final_c['lon'].min()}\"\n",
    "\n",
    "\n",
    "###### A+ B + C rating and elevation\n",
    "\n",
    "hf_final_d.columns = ['lon', 'lat', 'heat-flow (mW/m2)']\n",
    "\n",
    "\n",
    "hf_final_d = hf_final_d.round(3)\n",
    "\n",
    "hf_final_d.replace(' ', np.nan, inplace=True)\n",
    "hf_final_d.sort_values(by=['lon', 'lat'], ascending=True, inplace=True)\n",
    "hf_final_d.reset_index( inplace=True,drop=True)\n",
    "\n",
    "\n",
    "assert hf_final_d['lon'].max() <= 180, f\" max lon {hf_final_d['lon'].max()}\"\n",
    "assert hf_final_d['lon'].min() >= -180, f\" min lon {hf_final_d['lon'].min()}\"\n",
    "assert hf_final_d['lat'].max() <= 90, f\" max lat {hf_final_d['lat'].max()}\"\n",
    "assert hf_final_d['lat'].min() >= -90, f\" min lat {hf_final_d['lon'].min()}\"\n",
    "\n",
    "\n",
    "print(len(hf_final_a))\n",
    "print(len(hf_final_b))\n",
    "\n",
    "print(len(hf_final_c))\n",
    "print(len(hf_final_d))\n",
    "\n",
    "\n",
    "print('terminated')\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(20, 12))\n",
    "print(plt.style.available)\n",
    "plt.style.use('_classic_test_patch')\n",
    "\n",
    "sns.set(style='white', font_scale = 2.6)\n",
    "\n",
    "record_total[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                          label = f'All records (n={len(record_total):,})')\n",
    "                          \n",
    "hf_clean[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                      label = f'Excluded incomplete records (n={len(hf_clean):,})')\n",
    "hf_no_pole[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                         label = f'Excluded high latitudes (n={len(hf_no_pole):,})')\n",
    "hf_deep[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                         label = f'Excluded deeper than {abs(elev_cut)} m (n={len(hf_deep):,})')\n",
    "\n",
    "pd.concat([hf_final_a[target], hf_final_b[target], hf_final_c[target], \n",
    "           hf_final_d[target]]).hist(\n",
    "    bins=100, range = (0, 200), ax=ax,\n",
    "label = f'Rating $A$-$D$ (n={len(hf_final_a) + len(hf_final_b)+ len(hf_final_c) + len(hf_final_d):,})')\n",
    "pd.concat([hf_final_a[target], hf_final_b[target], hf_final_c[target]]).hist(\n",
    "    bins=100,  range = (0, 200),ax=ax,\n",
    "label = f'Rating $A$-$C$ (n={len(hf_final_a) + len(hf_final_b) + len(hf_final_c):,})')\n",
    "pd.concat([hf_final_a[target], hf_final_b[target]]).hist(\n",
    "    bins=100,  range = (0, 200),ax=ax,\n",
    "                        label = f'Rating $A$-$B$ (n={len(hf_final_a) + len(hf_final_b ):,})')\n",
    "hf_final_a[target].hist(bins=100,  range = (0, 200),ax=ax,\n",
    "                        label = f'Rating $A$ (n={len(hf_final_a):,})')\n",
    "\n",
    "\n",
    "ax.set_title(f'{sub_figs[2]})', loc ='left', pad=20, )\n",
    "ax.legend()\n",
    "ax.set_ylabel(f'$n$')\n",
    "\n",
    "ax.set_xlabel('GHF [mW/m2]')\n",
    "    \n",
    "\n",
    "#ax.set_title('Distribution of different global GHF values', pad=40,)\n",
    "\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_s1b.jpeg\", bbox_inches='tight', dpi=300 , pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f37370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create two datsets for A ratibng and b ratings\n",
    "HGHF_file = dir_p / 'data' / 'dataset'/ 'Reference'/ 'q_Heat_flow'/'NGHF.csv'\n",
    "\n",
    "\n",
    "hf = pd.read_csv(HGHF_file)\n",
    "# change heat flow to mili\n",
    "\n",
    "elev_cut = -1000\n",
    "\n",
    "\n",
    "\n",
    "record_total_int = pd.read_csv(HGHF_file)\n",
    "\n",
    "hf_afr_lat = record_total_int[record_total_int['latitude'].between(afr_lat_min, afr_lat_max, inclusive='both')]\n",
    "record_total_afr = hf_afr_lat[hf_afr_lat['longitude'].between(afr_lon_min, afr_lon_max, inclusive='both')]\n",
    "\n",
    "\n",
    "\n",
    "hf_no_pole_afr = record_total_afr.dropna(subset = ['longitude', 'latitude', 'heat-flow (mW/m2)'])\n",
    "\n",
    "\n",
    "\n",
    "#hf_no_pole_afr = hf_clean[hf_clean['latitude'].between(world_lat_min, world_lat_max, inclusive='both')]\n",
    "hf_deep_afr = hf_no_pole_afr[(hf_no_pole_afr['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "hf_final_a_afr = hf_no_pole_afr[(hf_no_pole_afr ['code6']=='A') & (hf_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "hf_final_b_afr= hf_no_pole_afr[(hf_no_pole_afr ['code6']=='B') & (hf_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "hf_final_c_afr = hf_no_pole_afr[(hf_no_pole_afr ['code6']=='C') & (hf_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "hf_final_d_afr = hf_no_pole_afr[(hf_no_pole_afr ['code6']=='D') & (hf_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "hf_final_z_afr = hf_no_pole_afr[(hf_no_pole_afr ['code6']=='Z') & (hf_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "\n",
    "hf_extreme_a = hf_final_a_afr[hf_final_a_afr[target] >=200]\n",
    "lon_hf_extreme_a = hf_extreme_a['longitude']\n",
    "lat_hf_extreme_a = hf_extreme_a['latitude']\n",
    "\n",
    "hf_extreme_b = hf_final_b_afr[hf_final_b_afr[target] >=200]\n",
    "lon_hf_extreme_b = hf_extreme_b['longitude']\n",
    "lat_hf_extreme_b = hf_extreme_b['latitude']\n",
    "\n",
    "hf_extreme = hf_no_pole_afr[hf_no_pole_afr[target] >=200]\n",
    "lon_hf_extreme = hf_extreme['longitude']\n",
    "lat_hf_extreme = hf_extreme['latitude']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(20, 12))\n",
    "print(plt.style.available)\n",
    "plt.style.use('_classic_test_patch')\n",
    "\n",
    "sns.set(style='whitegrid', font_scale = 2.6)\n",
    "\n",
    "\n",
    "record_total_afr[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                          label = f'All records (n={len(record_total_afr):,})')\n",
    "                          \n",
    "#hf_clean[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "#                      label = f'Excluded incomplete records (n={len(hf_clean):,})')\n",
    "hf_no_pole_afr[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                         label = f'Excluded incomplete records (n={len(hf_no_pole_afr):,})')\n",
    "hf_deep_afr[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                         label = f'Excluded deeper than {abs(elev_cut)} m (n={len(hf_deep_afr):,})')\n",
    "\n",
    "pd.concat([hf_final_a_afr[target], hf_final_b_afr[target], hf_final_c_afr[target], hf_final_d_afr[target]]).hist(\n",
    "    bins=100, range = (0, 200), ax=ax,\n",
    "                        label = f'Rating $A$-$D$ (n={len(hf_final_a_afr) + len(hf_final_b_afr) + len(hf_final_c_afr) + len(hf_final_d_afr):,})')\n",
    "pd.concat([hf_final_a_afr[target], hf_final_b_afr[target], hf_final_c_afr[target]]).hist(\n",
    "    bins=100,  range = (0, 200),ax=ax,\n",
    "                        label = f'Rating $A$-$C$ (n={len(hf_final_a_afr) + len(hf_final_b_afr) + len(hf_final_c_afr):,})')\n",
    "pd.concat([hf_final_a_afr[target], hf_final_b_afr[target]]).hist(\n",
    "    bins=100,  range = (0, 200),ax=ax,\n",
    "                        label = f'Rating $A$-$B$ (n={len(hf_final_a_afr) + len(hf_final_b_afr ):,})')\n",
    "hf_final_a_afr[target].hist(bins=100,  range = (0, 200),ax=ax,\n",
    "                        label = f'Rating $A$ (n={len(hf_final_a_afr):,})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.set_title(f'{sub_figs[2]})', loc ='left', pad=20, )\n",
    "ax.legend()\n",
    "ax.set_ylabel(f'$n$')\n",
    "\n",
    "ax.set_xlabel('GHF [mW/m2]')\n",
    "    \n",
    "\n",
    "#ax.set_title('Distribution of different global GHF values', pad=40,)\n",
    "\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_1b.jpeg\", bbox_inches='tight', dpi=300 , pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68014b48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=2,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['A)+o0.3/-1.2'],\n",
    "    margins=[\"0.18c\", \"0.6c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    cmap= pygmt.makecpt(\n",
    "          cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "    \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RF\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj,  frame='wNse', panel=[0, 0])\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RF_rabc_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            )\n",
    "\n",
    "\n",
    "        #fig.colorbar(frame=[\"af\", \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "          #       position=f\"g{str(afr_lon_max +2)}/{str(afr_lat_min+1)}+w14.5c/0.5c+v+e\")\n",
    "\n",
    "\n",
    "\n",
    "    #####Kriging\n",
    "    with fig.set_panel(panel=[0, 1]):\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='vik', #temp 19lev\n",
    "            series=f\"-15/15/1\",\n",
    "            continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='NsEw', panel=[0, 1])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_OK_rabc_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "        #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        #fig.colorbar(frame=[\"af\",  \"y+l[mW/m@+2@+]\"], \n",
    "                 #    position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w11c/0.5c+h+e\")\n",
    "        fig.colorbar(frame=[\"af\", 'x+lKriging\\tof\\tGHFs\\tResidual\\t[mW/m@+2@+\\]'],\n",
    "                   position=f\"g{str(afr_lon_max +14)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    ###\n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_5aa.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85282eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "\n",
    "    \n",
    "tectonics_shp_main = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "labels_main = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "              if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "\n",
    "tectonics_shp_sub = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "                    and 'gmt' in filename]\n",
    "labels_sub = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics') \n",
    "             if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "             and 'gmt' in filename]\n",
    "\n",
    "volc_erup = pd.read_csv(dir_p/'GMT'/'tectonics'/'volcanic_eruptions.dat', sep='\\s')\n",
    "# congo co KA kalhari\n",
    "\n",
    "\n",
    "#pygmt.config(FONT_ANNOT = '180p')\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=2,\n",
    "    ncols=3,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['C)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"0.6c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey='r',  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "    \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame='ESnw', panel=[0, 0])\n",
    "        \n",
    "        '''\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"GHF\"',\n",
    "                      pen=\"0.5p\", style=\"c0.2c\")'''\n",
    "      \n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rabc_lr, region=region_gmt, spacing=spacing)\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region_gmt,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "              #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "        \n",
    "        '''\n",
    "                    \n",
    "        for shape, label in zip(tectonics_shp_sub, labels_sub):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1,white,--')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "            #fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, font='15' ,text=label, justify=\"ML\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        for shape, label in zip(tectonics_shp_main, labels_main):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1.5,white')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "                \n",
    "            if label == 'RTA':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()-10, y=shape_xy.iloc[:,1].median()+0.5, \n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            elif label == 'AAO':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()+2, y=shape_xy.iloc[:,1].median()+2,\n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            elif label == 'BB':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()-3, y=shape_xy.iloc[:,1].median(),\n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "\n",
    "            else:\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, \n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            \n",
    "\n",
    "        fig.plot(x=volc_erup.Lon, y=volc_erup.Lat,  projection=proj,\n",
    "             color='white', label=f'\"Eruptions\"',\n",
    "                      pen=\"0.5p\", style=\"a0.25c\")'''\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "        fig.plot(x=hf_final_a.lon, y=hf_final_a.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_a[target], transparency =50,\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        fig.plot(x=hf_final_b.lon, y=hf_final_b.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_b[target],transparency =50,\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_c.lon, y=hf_final_c.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_c[target], transparency =50,\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        fig.plot(x=hf_final_z_afr.longitude, y=hf_final_z_afr.latitude,  cmap=True, projection=proj,\n",
    "             color=hf_final_z_afr[target], transparency =50,\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        '''\n",
    "        fig.text(text=\"_\", x=-19, y=-4, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Major Cratons\", x=-8, y=-4, font=\"13p,Helvetica,black\")\n",
    "        fig.text(text=\"KA : Kalhari Cr.\", x=-11, y=-7, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"CC : Congo Cr.\", x=-11, y=-10, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"RTA :\", x=-11, y=-13, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"BB :\", x=-8, y=-16, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"WAC : W. African Cr.\", x=-7, y=-19, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"SMC : Sah. Metacr.\", x=-8, y=-22, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"AAO :\", x=-8, y=-25, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"--\", x=-19, y=-28, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Minor Cratons\", x=-8, y=-28, font=\"14p,Helvetica,black\")'''\n",
    "\n",
    "        fig.colorbar(frame=[\"af\", \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_max +14)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "        \n",
    "    \n",
    "        fig.legend(position=\"g-23/-3\", box=False)\n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "#fig.savefig(dir_p/'fig'/\"fig_5bb.jpg\", dpi=300 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14c5ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_identity(axes, *line_args, **line_kwargs):\n",
    "    identity, = axes.plot([], [], *line_args, **line_kwargs)\n",
    "    def callback(axes):\n",
    "        low_x, high_x = axes.get_xlim()\n",
    "        low_y, high_y = axes.get_ylim()\n",
    "        low = max(low_x, low_y)\n",
    "        high = min(high_x, high_y)\n",
    "        identity.set_data([low, high], [low, high])\n",
    "    callback(axes)\n",
    "    axes.callbacks.connect('xlim_changed', callback)\n",
    "    axes.callbacks.connect('ylim_changed', callback)\n",
    "    return axes\n",
    "\n",
    "KPI_df = pd.DataFrame()\n",
    "\n",
    "#define plotting region (2 rows, 2 columns)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(32,30), dpi=300)\n",
    "\n",
    "# Seaborn setting                                                                                                                                              \n",
    "#sns.set(style='white',  font_scale = 3)\n",
    "\n",
    "sns.set(style='white',  font_scale = 3.5)\n",
    "#parameters = {'axes.labelsize': 35,\n",
    "#          'axes.titlesize': 35}\n",
    "#plt.rcParams.update(parameters)\n",
    "font_size = 30\n",
    "\n",
    "point_size = 150\n",
    "\n",
    "#####\n",
    "errors      = abs(y_test_rabc_lr - y_pred_RK_rabc_lr)\n",
    "errors_lr     = abs(y_test_rabc_lr - y_pred_RF_rabc_lr)\n",
    "mape        = round( mean_absolute_percentage_error(y_test_rabc_lr, y_pred_RK_rabc_lr), 2) \n",
    "accuracy    = round(100 - mape *100, 3)\n",
    "mae         = round(mean_absolute_error(y_test_rabc_lr, y_pred_RK_rabc_lr ), 1)\n",
    "rmse        = round(mean_squared_error(y_test_rabc_lr, y_pred_RK_rabc_lr , squared=False), 1)\n",
    "nrmse       = round( rmse/(y_test_rabc_lr.mean()) , 2) \n",
    "r2          = round(r2_score(y_test_rabc_lr, y_pred_RK_rabc_lr ), 2)\n",
    "ev          = round( explained_variance_score(y_test_rabc_lr, y_pred_RK_rabc_lr), 3)\n",
    "mnae        = round( median_absolute_error(y_test_rabc_lr, y_pred_RK_rabc_lr), 3) \n",
    "mpe         =  round(np.mean((y_test_rabc_lr -y_pred_RK_rabc_lr)/y_test_rabc_lr) , 3)\n",
    "ccc         = round(concordance_correlation_coefficient(y_test_rabc_lr, y_pred_RK_rabc_lr),2)\n",
    "bias        = round(y_pred_RK_rabc_lr.mean() - y_test_rabc_lr.mean(), 2)\n",
    "max_e_rk       = round( max_error(y_test_rabc_lr, y_pred_RK_rabc_lr), 0)\n",
    "min_e_rk       = round( errors.min(), 3)\n",
    "Max_rk         = round(y_pred_RK_rabc_lr.max(), 0)\n",
    "Min_rk         = round(y_pred_RK_rabc_lr.min(), 0)\n",
    "\n",
    "rsd         = round(np.std(y_pred_RK_rabc_lr) / np.mean(y_pred_RK_rabc_lr) ,3)\n",
    "\n",
    "rmse_rf        = round(mean_squared_error(y_test_rabc_lr, y_pred_RF_rabc_lr , squared=False), 1)\n",
    "max_e_rf      = round( max_error(y_test_rabc_lr, y_pred_RF_rabc_lr), 0)\n",
    "min_e_rf      = round( errors_lr.min(), 3)\n",
    "Max_rf        = round(y_pred_RF_rabc_lr.max(), 0)\n",
    "Min_rf        = round(y_pred_RF_rabc_lr.min(), 0)\n",
    "\n",
    "KPI_df.loc['NRMSE', f'RK_11_rabc'] = nrmse\n",
    "KPI_df.loc['RMSE', f'RK_11_rabc'] = rmse\n",
    "KPI_df.loc['MAE', f'RK_11_rabc'] = mae\n",
    "KPI_df.loc['MAPE', f'RK_11_rabc'] = mape\n",
    "KPI_df.loc['CD', f'RK_11_rabc'] = r2\n",
    "KPI_df.loc['EV', f'RK_11_rabc'] = ev\n",
    "KPI_df.loc['MAX_E', f'RK_11_rabc'] = max_e_rk\n",
    "KPI_df.loc['MIN_E', f'RK_11_rabc'] = min_e_rk\n",
    "KPI_df.loc['MedAE', f'RK_11_rabc'] = mnae\n",
    "KPI_df.loc['MPE', f'RK_11_rabc'] = mpe\n",
    "KPI_df.loc['ACC', f'RK_11_rabc'] = accuracy\n",
    "KPI_df.loc['MAX', f'RK_11_rabc'] = Max_rk    \n",
    "KPI_df.loc['RSD', f'RK_11_rabc'] = rsd\n",
    "KPI_df.loc['CCC', f'RK_11_rabc'] = ccc\n",
    "KPI_df.loc['BIAS', f'RK_11_rabc'] = bias\n",
    "\n",
    "KPI_df.loc['RI', f'RK_11_rabc'] = (rmse_rf - rmse)/rmse_rf * 100\n",
    "\n",
    "\n",
    "\n",
    "sns.regplot(x=y_pred_RK_rabc_lr, y=y_test_rabc_lr,    ax= axes[0,0], \n",
    "            line_kws={\"color\": \"k\"} , scatter_kws={ \"edgecolor\":\"w\", 's':point_size, },\n",
    "            \n",
    "             \n",
    "     label=  \n",
    "     f\"\"\"     \n",
    "     $NRMSe$ :   {nrmse} \n",
    "     $R^2$         :   {r2}\n",
    "     $MPe$      :  {mpe}\n",
    "     \"\"\")\n",
    "#$R_i$          :  {round((rmse_rf - rmse)/rmse_rf,3)}\n",
    "add_identity(axes[0,0], color='grey', ls='--')\n",
    "#mn = min(plt.gca().axis()) and mx = max(plt.gca().axis())\n",
    "\n",
    "'''sns.scatterplot(x=y_pred_RK_rabc_lr[mask],y=y_test_rabc_lr[mask], color=\"red\", \n",
    "                s=point_size,  ax= axes[0,0], edgecolor=\"white\", \n",
    "               #label= \"Mae > 15\"  \n",
    "               )'''\n",
    "axes[0,0].set(xlabel='$\\hat{z}_{KED}$ [$mW/m^{2}$]',ylabel='$z$ [$mW/m^{2}$]')\n",
    "axes[0,0].set_title(f\"{sub_figs[0]})   Observed vs predictions (KED)\", loc ='left', pad=20,   y=1.1)\n",
    "axes[0,0].set_xlim([0, 200])\n",
    "axes[0,0].set_ylim([0, 200])\n",
    "axes[0,0].set_xticks([0, 25, 50, 75, 100, 125, 150, 175, 200])\n",
    "\n",
    "#bbox_to_anchor=(2, 0), \n",
    "axes[0,0].legend( frameon=False,loc=\"lower right\")\n",
    "for lh in axes[0,0].get_legend().legendHandles: \n",
    "    lh._sizes = [0] \n",
    "\n",
    "\n",
    "####\n",
    "mean_lr= \"$\\overline{\\hat{z}}_{RF}$\"\n",
    "median_lr= \"$\\widetilde{\\hat{z}}_{RF}$\"\n",
    "std_lr= \"$s_{\\hat{z}_{RF}}$\"\n",
    "\n",
    "sns.kdeplot(y_pred_RF_rabc_lr,  ax =axes[0,1],fill=True, \n",
    "            color=\"orange\", label=f'''\n",
    "{mean_lr} : {round(y_pred_RF_rabc_lr.mean(),1)}\n",
    "{median_lr} : {round(np.median(y_pred_RF_rabc_lr),1)}\n",
    "{std_lr} : {round(y_pred_RF_rabc_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_pred_RF_rabc_lr.mean() , c='b')\n",
    "\n",
    "\n",
    "mean_ked = \"$\\overline{\\hat{z}}_{KED}$\"\n",
    "median_ked = \"$\\widetilde{\\hat{z}}_{KED}$\"\n",
    "std_ked = \"$s_{\\hat{z}_{KED}}$\"\n",
    "\n",
    "sns.kdeplot(y_pred_RK_rabc_lr,  ax =axes[0,1],fill=True, \n",
    "            color=\"r\", label=f'''\n",
    "{mean_ked} : {round(y_pred_RK_rabc_lr.mean(),1)}\n",
    "{median_ked} : {round(np.median(y_pred_RK_rabc_lr),1)}\n",
    "{std_ked} : {round(y_pred_RK_rabc_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_pred_RK_rabc_lr.mean() , c='g')\n",
    "\n",
    "mean_t = \"$\\overline{z}$\"\n",
    "median_t = \"$\\widetilde{z}$\"\n",
    "std_t = \"$s_{z}$\"\n",
    "\n",
    "sns.kdeplot(y_test_rabc_lr,  ax =axes[0,1],fill=True, \n",
    "            color=\"b\", label=f'''\n",
    "{mean_t}  : {round(y_test_rabc_lr.mean(),1)}\n",
    "{median_t}  : {round(np.median(y_test_rabc_lr),1)}\n",
    "{std_t} : {round(y_test_rabc_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_test_rabc_lr.mean() , c='r')\n",
    "\n",
    "axes[0,1].legend( frameon=False, bbox_to_anchor=(1.15, 1.08))\n",
    "axes[0,1].set_yticks([]) \n",
    "\n",
    "axes[0,1].set(xlabel='GHF [$mW/m^{2}$]',ylabel='PDF' )\n",
    "\n",
    "axes[0,1].set_title(f'{sub_figs[2]})   Density Plots', loc ='left', pad=20,   y=1.1)\n",
    "axes[0,1].set_xticks([0, 25, 50, 75, 100, 125, 150, 175, 200])\n",
    "###\n",
    "     \n",
    "     \n",
    "sns.residplot(  x=y_pred_RF_rabc_lr, y=y_test_rabc_lr, ax =axes[1,0], \n",
    "              scatter_kws={ \"edgecolor\":\"w\", 's':point_size, },\n",
    "     label=  \n",
    "     f\"\"\"     \n",
    "     $Max$ e : {int(max_e_rf)} \n",
    "     $Max$    : {int(Max_rf)}\n",
    "     $Min$     : {int(Min_rf)}\n",
    "     \"\"\")\n",
    "\n",
    "\n",
    "#plot.ax_joint.axvline(x=6)\n",
    "#axes[1,0].axhline(y=threshold , c='red')\n",
    "#axes[1,0].axhline(y=-threshold , c='red')\n",
    "axes[1,0].legend(frameon=False, loc=\"upper right\")\n",
    "for lh in axes[1,0].get_legend().legendHandles: \n",
    "    lh._sizes = [0] \n",
    "\n",
    "axes[1,0].set(xlabel='$\\hat{z}_{RF}$ [$mW/m^{2}$]',ylabel='Residuals' )\n",
    "axes[1,0].set_title(f'{sub_figs[1]})   Residuals vs predictions (RF)', loc ='left', pad=20,   y=1.1)\n",
    "axes[1,0].set_xticks([0, 25, 50, 75, 100, 125, 150, 175, 200])\n",
    "     \n",
    "sns.residplot(  x=y_pred_RK_rabc_lr, y=y_test_rabc_lr, ax =axes[1,1], \n",
    "              scatter_kws={ \"edgecolor\":\"w\", 's':point_size, },\n",
    "                  label=  \n",
    "     f\"\"\"     \n",
    "     $Max$ e : {int(max_e_rk)} \n",
    "     $Max$    : {int(Max_rk)}\n",
    "     $Min$     : {int(Min_rk)}\n",
    "     \"\"\")\n",
    "\n",
    "\n",
    "#plot.ax_joint.axvline(x=6)\n",
    "#axes[1,1].axhline(y=threshold , c='red')\n",
    "#axes[1,1].axhline(y=-threshold , c='red')\n",
    "\n",
    "\n",
    "axes[1,1].legend(frameon=False, loc=\"upper right\")\n",
    "for lh in axes[1,1].get_legend().legendHandles: \n",
    "    lh._sizes = [0] \n",
    "    \n",
    "axes[1,1].set(xlabel='$\\hat{z}_{KED}$ [$mW/m^{2}$]',ylabel='Residuals' )\n",
    "axes[1,1].set_title(f'{sub_figs[1]})   Residuals vs predictions (KED)', loc ='left', pad=20,   y=1.1)\n",
    "axes[1,1].set_xticks([0, 25, 50, 75, 100, 125, 150, 175, 200])\n",
    "\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_6rabc.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
