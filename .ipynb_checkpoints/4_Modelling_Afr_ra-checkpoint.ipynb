{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edac9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311f870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import os, sys, pickle, copy, pygmt, operator\n",
    "\n",
    "from pathlib import Path\n",
    "from time import sleep\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "#from joblib import Parallel, delayed\n",
    "#import multiprocessing\n",
    "#import numba as nb\n",
    "#from numba import jit\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, cross_val_score\n",
    "\n",
    "from sklearn.metrics import make_scorer ,explained_variance_score, mean_absolute_error, mean_squared_error, \\\n",
    "r2_score, max_error, median_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder , PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.compose import make_column_selector as selector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc8a8944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constanst\n",
    "crs_to='epsg:4326'\n",
    "crs_from='epsg:4326'\n",
    "projection = 'M5.4i'\n",
    "#parent directory\n",
    "\n",
    "DIR = Path().resolve() \n",
    "\n",
    "plt_params = {\n",
    "    'figure.titlesize' : 28,\n",
    "    \"axes.titlesize\" : 25, # main\n",
    "    \"axes.labelsize\" : 25,  # labels\n",
    "    \"axes.edgecolor\" : \"black\", \n",
    "    \"axes.linewidth\" : 1, \n",
    "    'xtick.labelsize': 20, # ticks\n",
    "    'ytick.labelsize': 20,\n",
    "    'legend.title_fontsize':17,\n",
    "    'legend.fontsize': 17,\n",
    "    'font.size': 20,\n",
    "}\n",
    "\n",
    "\n",
    "# We can exclude Arctic ocean and Antarctica, as there are no HF measurements to use\n",
    "world_lon_min, world_lon_max, world_lat_min, world_lat_max  = -180, 180, -60, 80\n",
    "\n",
    "# map extents of Africa and Australia\n",
    "afr_lon_min, afr_lon_max, afr_lat_min, afr_lat_max =  -20, 52, -37 , 38  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "215924c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SeabornFig2Grid():\n",
    "\n",
    "    def __init__(self, seaborngrid, fig,  subplot_spec):\n",
    "        self.fig = fig\n",
    "        self.sg = seaborngrid\n",
    "        self.subplot = subplot_spec\n",
    "        if isinstance(self.sg, sns.axisgrid.FacetGrid) or \\\n",
    "            isinstance(self.sg, sns.axisgrid.PairGrid):\n",
    "            self._movegrid()\n",
    "        elif isinstance(self.sg, sns.axisgrid.JointGrid):\n",
    "            self._movejointgrid()\n",
    "        self._finalize()\n",
    "\n",
    "    def _movegrid(self):\n",
    "        \"\"\" Move PairGrid or Facetgrid \"\"\"\n",
    "        self._resize()\n",
    "        n = self.sg.axes.shape[0]\n",
    "        m = self.sg.axes.shape[1]\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(n,m, subplot_spec=self.subplot)\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                self._moveaxes(self.sg.axes[i,j], self.subgrid[i,j])\n",
    "\n",
    "    def _movejointgrid(self):\n",
    "        \"\"\" Move Jointgrid \"\"\"\n",
    "        h= self.sg.ax_joint.get_position().height\n",
    "        h2= self.sg.ax_marg_x.get_position().height\n",
    "        r = int(np.round(h/h2))\n",
    "        self._resize()\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(r+1,r+1, subplot_spec=self.subplot)\n",
    "\n",
    "        self._moveaxes(self.sg.ax_joint, self.subgrid[1:, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_x, self.subgrid[0, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_y, self.subgrid[1:, -1])\n",
    "\n",
    "    def _moveaxes(self, ax, gs):\n",
    "        #https://stackoverflow.com/a/46906599/4124317\n",
    "        ax.remove()\n",
    "        ax.figure=self.fig\n",
    "        self.fig.axes.append(ax)\n",
    "        self.fig.add_axes(ax)\n",
    "        ax._subplotspec = gs\n",
    "        ax.set_position(gs.get_position(self.fig))\n",
    "        ax.set_subplotspec(gs)\n",
    "\n",
    "    def _finalize(self):\n",
    "        plt.close(self.sg.fig)\n",
    "        self.fig.canvas.mpl_connect(\"resize_event\", self._resize)\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def _resize(self, evt=None):\n",
    "        self.sg.fig.set_size_inches(self.fig.get_size_inches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330f7aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance_correlation_coefficient(y_true, y_pred):\n",
    "    \"\"\"Concordance correlation coefficient.\"\"\"\n",
    "    \n",
    "    y_true = y_true.ravel().reshape(-1,)\n",
    "    y_pred = y_pred.ravel().reshape(-1,)\n",
    "    # Remove NaNs\n",
    "    df = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "    df = df.dropna()\n",
    "    y_true = df['y_true']\n",
    "    y_pred = df['y_pred']\n",
    "    # Pearson product-moment correlation coefficients\n",
    "    cor = np.corrcoef(y_true, y_pred)[0][1]\n",
    "    # Mean\n",
    "    mean_true = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    # Variance\n",
    "    var_true = np.var(y_true)\n",
    "    var_pred = np.var(y_pred)\n",
    "    # Standard deviation\n",
    "    sd_true = np.std(y_true)\n",
    "    sd_pred = np.std(y_pred)\n",
    "    # Calculate CCC\n",
    "    numerator = 2 * cor * sd_true * sd_pred\n",
    "    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1569405b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBS_AFR</th>\n",
       "      <th>LABELS_gmt</th>\n",
       "      <th>LABELS</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>UNITS_gmt</th>\n",
       "      <th>V_RANGE</th>\n",
       "      <th>V_RANGE_AFR</th>\n",
       "      <th>CMAPS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OBS_REF</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CTD</th>\n",
       "      <td>CTD</td>\n",
       "      <td>CTD</td>\n",
       "      <td>CTD</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>(0, 50)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SI</th>\n",
       "      <td>SI</td>\n",
       "      <td>Shape index</td>\n",
       "      <td>Shape index</td>\n",
       "      <td>si</td>\n",
       "      <td>si</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>(-1, 1)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAB</th>\n",
       "      <td>LAB</td>\n",
       "      <td>LAB</td>\n",
       "      <td>LAB</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(0, 300)</td>\n",
       "      <td>(50, 250)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MOHO</th>\n",
       "      <td>MOHO</td>\n",
       "      <td>Moho</td>\n",
       "      <td>Moho</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(15, 60)</td>\n",
       "      <td>(20, 50)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SV</th>\n",
       "      <td>SV_Velocity</td>\n",
       "      <td>S@_v@ 150km</td>\n",
       "      <td>$S_v$ @150km</td>\n",
       "      <td>$\\delta$$S_v$ %</td>\n",
       "      <td>km/s</td>\n",
       "      <td>(-0.075, 0.075)</td>\n",
       "      <td>(-0.075, 0.075)</td>\n",
       "      <td>SCM/roma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PV</th>\n",
       "      <td>PV_Velocity</td>\n",
       "      <td>P@_v@ 150km</td>\n",
       "      <td>$P_v$ @150km</td>\n",
       "      <td>$\\delta$$P_v$ %</td>\n",
       "      <td>km/s</td>\n",
       "      <td>(-0.02, 0.02)</td>\n",
       "      <td>(-0.02, 0.02)</td>\n",
       "      <td>SCM/roma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <td>GEOID</td>\n",
       "      <td>Geoid</td>\n",
       "      <td>Geoid</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>(-45, 45)</td>\n",
       "      <td>(-45, 45)</td>\n",
       "      <td>SCM/bamako</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEM</th>\n",
       "      <td>DEM</td>\n",
       "      <td>DEM</td>\n",
       "      <td>DEM</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>(-2200, 2200)</td>\n",
       "      <td>(-2200, 2200)</td>\n",
       "      <td>SCM/oleron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FA</th>\n",
       "      <td>FA</td>\n",
       "      <td>Free air</td>\n",
       "      <td>Free air</td>\n",
       "      <td>mGal</td>\n",
       "      <td>mGal</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BG</th>\n",
       "      <td>BG</td>\n",
       "      <td>Bouguer</td>\n",
       "      <td>Bouguer</td>\n",
       "      <td>mGal</td>\n",
       "      <td>mGal</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>(-100, 100)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMAG2_CLASS</th>\n",
       "      <td>EMAG2</td>\n",
       "      <td>Mag.</td>\n",
       "      <td>Mag.</td>\n",
       "      <td>f(nT)</td>\n",
       "      <td>f(nT)</td>\n",
       "      <td>(-0.4, 0.4)</td>\n",
       "      <td>(-200, 200)</td>\n",
       "      <td>SCM/bilbao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RHO_L</th>\n",
       "      <td>RHO_L</td>\n",
       "      <td>Lith. rho</td>\n",
       "      <td>Lith. ρ</td>\n",
       "      <td>kg/m$^3$</td>\n",
       "      <td>kg/m@+3@+</td>\n",
       "      <td>(3260, 3360)</td>\n",
       "      <td>(3260, 3360)</td>\n",
       "      <td>SCM/batlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RHO_C</th>\n",
       "      <td>RHO_C</td>\n",
       "      <td>Crust rho</td>\n",
       "      <td>Crust ρ</td>\n",
       "      <td>kg/m$^3$</td>\n",
       "      <td>kg/m@+3@+</td>\n",
       "      <td>(2650, 2950)</td>\n",
       "      <td>(2650, 2950)</td>\n",
       "      <td>SCM/batlow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VOLC_DIST_W</th>\n",
       "      <td>VOLC_DIST</td>\n",
       "      <td>Volcano</td>\n",
       "      <td>Volcano</td>\n",
       "      <td>km</td>\n",
       "      <td>km</td>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(0, 100)</td>\n",
       "      <td>SCM/broc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REG</th>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>REG</td>\n",
       "      <td>class</td>\n",
       "      <td>class</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>(1, 6)</td>\n",
       "      <td>gmt/categorical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLIM</th>\n",
       "      <td>GLIM</td>\n",
       "      <td>GliM</td>\n",
       "      <td>GliM</td>\n",
       "      <td>class</td>\n",
       "      <td>class</td>\n",
       "      <td>(1, 16)</td>\n",
       "      <td>(1, 15)</td>\n",
       "      <td>gmt/categorical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 OBS_AFR   LABELS_gmt        LABELS            UNITS  UNITS_gmt          V_RANGE      V_RANGE_AFR            CMAPS\n",
       "OBS_REF                                                                                                                           \n",
       "CTD                  CTD          CTD           CTD               km         km          (0, 50)          (0, 50)       SCM/bamako\n",
       "SI                    SI  Shape index   Shape index               si         si          (-1, 1)          (-1, 1)         SCM/broc\n",
       "LAB                  LAB          LAB           LAB               km         km         (0, 300)        (50, 250)       SCM/bamako\n",
       "MOHO                MOHO         Moho          Moho               km         km         (15, 60)         (20, 50)       SCM/bamako\n",
       "SV           SV_Velocity  S@_v@ 150km  $S_v$ @150km  $\\delta$$S_v$ %       km/s  (-0.075, 0.075)  (-0.075, 0.075)         SCM/roma\n",
       "PV           PV_Velocity  P@_v@ 150km  $P_v$ @150km  $\\delta$$P_v$ %       km/s    (-0.02, 0.02)    (-0.02, 0.02)         SCM/roma\n",
       "GEOID              GEOID        Geoid         Geoid                m          m        (-45, 45)        (-45, 45)       SCM/bamako\n",
       "DEM                  DEM          DEM           DEM                m          m    (-2200, 2200)    (-2200, 2200)       SCM/oleron\n",
       "FA                    FA     Free air      Free air             mGal       mGal      (-100, 100)      (-100, 100)         SCM/broc\n",
       "BG                    BG      Bouguer       Bouguer             mGal       mGal      (-100, 100)      (-100, 100)         SCM/broc\n",
       "EMAG2_CLASS        EMAG2         Mag.          Mag.            f(nT)      f(nT)      (-0.4, 0.4)      (-200, 200)       SCM/bilbao\n",
       "RHO_L              RHO_L    Lith. rho       Lith. ρ         kg/m$^3$  kg/m@+3@+     (3260, 3360)     (3260, 3360)       SCM/batlow\n",
       "RHO_C              RHO_C    Crust rho       Crust ρ         kg/m$^3$  kg/m@+3@+     (2650, 2950)     (2650, 2950)       SCM/batlow\n",
       "VOLC_DIST_W    VOLC_DIST      Volcano       Volcano               km         km           (0, 1)         (0, 100)         SCM/broc\n",
       "REG                  REG          REG           REG            class      class           (1, 6)           (1, 6)  gmt/categorical\n",
       "GLIM                GLIM         GliM          GliM            class      class          (1, 16)          (1, 15)  gmt/categorical"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = pd.DataFrame()\n",
    "\n",
    "\n",
    "obs[\"OBS_REF\"] = [\"CTD\" ,  \"SI\",\"LAB\", \"MOHO\",\n",
    "            \"SV\",\"PV\", \n",
    "            \"GEOID\",\"FA\",\"DEM\",\"BG\", \"EMAG2_CLASS\",\n",
    "                   \"RHO_L\", \"RHO_C\", \n",
    "                  \"VOLC_DIST_W\", \"REG\", \"GLIM\"]\n",
    "\n",
    "obs[\"OBS_AFR\"] = [\"CTD\" ,  \"SI\",\"LAB\", \"MOHO\",\n",
    "            \"SV_Velocity\",\"PV_Velocity\", \n",
    "            \"GEOID\",\"FA\",\"DEM\",\"BG\", \"EMAG2\",\n",
    "                   \"RHO_L\", \"RHO_C\", \n",
    "                  \"VOLC_DIST\", \"REG\", \"GLIM\"]\n",
    "  \n",
    "     \n",
    "# Labels for plots etc\n",
    "\n",
    "\n",
    "# Labels for plots etc\n",
    "obs[\"LABELS_gmt\"] = [\"CTD\",  \"Shape index\", \"LAB\", \"Moho\", \n",
    "                \"S@_v@ 150km\", \"P@_v@ 150km\", \n",
    "                \"Geoid\", \"Free air\", \"DEM\", \"Bouguer\", \"Mag.\", \n",
    "                \"Lith. rho\", \"Crust rho\",  \n",
    "                 \"Volcano\", \"REG\", \"GliM\", ]  \n",
    "\n",
    "\n",
    "obs[\"LABELS\"] = [\"CTD\",  \"Shape index\", \"LAB\", \"Moho\", \n",
    "                \"$S_v$ @150km\", \"$P_v$ @150km\", \n",
    "                \"Geoid\", \"Free air\", \"DEM\", \"Bouguer\", \"Mag.\", \n",
    "                \"Lith. ρ\", \"Crust ρ\",  \n",
    "                 \"Volcano\", \"REG\", \"GliM\", ]\n",
    "    \n",
    "# \"vp/vs\"\n",
    "# Units to display in plots etc\n",
    "obs[\"UNITS\"] = [\"km\",  \"si\", \"km\", \"km\",\n",
    "             \"$\\delta$$S_v$ %\",\"$\\delta$$P_v$ %\", \n",
    "             \"m\", \"mGal\", \"m\", \"mGal\",  \"f(nT)\", \n",
    "                 \"kg/m$^3$\", \"kg/m$^3$\",\n",
    "                \"km\",  \"class\", \"class\"]\n",
    "\n",
    "\n",
    "\n",
    "obs[\"UNITS_gmt\"] = [\"km\",  \"si\", \"km\", \"km\",\n",
    "             \"km/s\",\"km/s\", \n",
    "             \"m\", \"mGal\", \"m\", \"mGal\",  \"f(nT)\", \n",
    "                 \"kg/m@+3@+\", \"kg/m@+3@+\",\n",
    "                \"km\",  \"class\", \"class\"]\n",
    "        \n",
    "# Range of colormap for plots. Similar data are placed in same ranges for consistancy\n",
    "obs[\"V_RANGE\"] = [(0,50), (-1,1),(0,300),(15,60),\n",
    "              (-0.075,0.075), (-0.02,0.02), \n",
    "              (-45,45), (-100,100) , (-2200, 2200),(-100,100),  (-0.4, 0.4), \n",
    "                   (3260, 3360), (2650, 2950),\n",
    "                  (0,1), (1,6),(1,16),]\n",
    "\n",
    "\n",
    "    \n",
    "obs[\"V_RANGE_AFR\"] = [(0,50), (-1,1),(50,250),(20,50),\n",
    "          (-0.075,0.075), (-0.02,0.02), \n",
    "          (-45,45), (-100,100) , (-2200, 2200),(-100,100),  (-200, 200), \n",
    "               (3260, 3360), (2650, 2950),\n",
    "              (0,100), (1,6),(1,15),]\n",
    "\n",
    "\n",
    "obs[\"CMAPS\"] = [\"batlow\",  \"broc\", \"bamako\", \"batlow\", \n",
    "             \"roma\",\"roma\", \n",
    "             \"bamako\", \"broc\", \"bukavu\", \"broc\", \"batlow\",            \n",
    "                \"batlow\", \"batlow\",\n",
    "               \"bamako\",  \"batlowS\",\"categorical\", ]\n",
    "\n",
    "obs[\"CMAPS\"] = [\"SCM/bamako\",  \"SCM/broc\", \"SCM/bamako\", \"SCM/bamako\", \n",
    "             \"SCM/roma\",\"SCM/roma\", \n",
    "             \"SCM/bamako\", \"SCM/broc\", \"SCM/oleron\", \"SCM/broc\", \"SCM/bilbao\",            \n",
    "                \"SCM/batlow\", \"SCM/batlow\",\n",
    "               \"SCM/broc\",  \"gmt/categorical\",\"gmt/categorical\", ]\n",
    "\n",
    "new_index = [0,1,2,3,4,5,6,8,7,9,10,11,12,13,14,15]\n",
    "\n",
    "#new_index = [4,3,15,6,7,0, 14, 10,16, 8, 9,2, 13, 12, 8, 11, ]\n",
    "\n",
    "obs = obs.reindex(new_index)\n",
    "\n",
    "#obs.index = np.arange(0,len(obs))\n",
    "\n",
    "pd.options.display.width = 370\n",
    "pd.options.display.max_colwidth = 16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "obs_dict = obs.to_dict(orient='records')\n",
    "\n",
    "obs.set_index(['OBS_REF'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c52e68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_afr = xr.load_dataset(DIR/'Grids'/'Inputs'/\"ds_afr.nc\")\n",
    "#ds_afr_hr = xr.load_dataset(DIR/'Grids'/'Inputs'/\"ds_afr_hr.nc\")\n",
    "#ds_world = xr.load_dataset(dir_p/'Grids'/'inputs'/\"ds_world.nc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d31693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CTD',\n",
       " 'SI',\n",
       " 'LAB',\n",
       " 'MOHO',\n",
       " 'SV',\n",
       " 'PV',\n",
       " 'GEOID',\n",
       " 'DEM',\n",
       " 'FA',\n",
       " 'BG',\n",
       " 'EMAG2_CLASS',\n",
       " 'RHO_L',\n",
       " 'RHO_C',\n",
       " 'VOLC_DIST_W',\n",
       " 'REG',\n",
       " 'GLIM',\n",
       " 'lon',\n",
       " 'lat',\n",
       " 'grid_index_world',\n",
       " 'grid_index_afr',\n",
       " 'GHF']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "target = 'GHF'\n",
    "coord = ['lon', 'lat']\n",
    "grid_index_world = 'grid_index_world'\n",
    "grid_index_afr ='grid_index_afr'\n",
    "\n",
    "hq_lower_bound = 25\n",
    "hq_upper_bound = 100\n",
    "\n",
    "\n",
    "#######\n",
    "\n",
    "features_ex = []\n",
    "features_ghf = []\n",
    "\n",
    "\n",
    "\n",
    "features = obs.index.to_list()\n",
    "\n",
    "\n",
    "\n",
    "in_features = set(features)\n",
    "\n",
    "features_ex = copy.deepcopy(features)\n",
    "features_ex.extend(coord)\n",
    "features_ex.append(grid_index_world)\n",
    "features_ex.append(grid_index_afr)\n",
    "\n",
    "features_ex.append(target)\n",
    "\n",
    "features_ghf = copy.deepcopy(features)\n",
    "features_ghf.append(target)\n",
    "\n",
    "\n",
    "features_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e3ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rating = 'ra'\n",
    "outlier = 'OD'\n",
    "\n",
    "\n",
    "file_label = f'{outlier}_{rating}'\n",
    "\n",
    "w_OD_ra_f =  DIR/'Dataset'/'Preprocessed'/f'W_OD_ra.csv'\n",
    "W_OD_ra = pd.read_csv(w_OD_ra_f, sep='\\t')\n",
    "\n",
    "#mask_afr = W_OD_ra['lon'].between(afr_lon_min, afr_lon_max)& W_OD_ra['lat'].between(afr_lat_min, afr_lat_max)\n",
    "#Afr_OD_ra = W_OD_ra[~mask_afr]\n",
    "\n",
    "Afr_OD_ra_f =  DIR/'Dataset'/'Preprocessed'/f'Afr_OD_ra.csv'\n",
    "Afr_OD_ra = pd.read_csv(Afr_OD_ra_f,  sep='\\t')\n",
    "\n",
    "\n",
    "Afr_NOD_ra_f =  DIR/'Dataset'/'Preprocessed'/f'Afr_NOD_ra.csv'\n",
    "Afr_NOD_ra = pd.read_csv(Afr_NOD_ra_f,sep='\\t')\n",
    "\n",
    "\n",
    "#######\n",
    "W_OD_ra['GLIM']  = W_OD_ra['GLIM'].astype('category')\n",
    "W_OD_ra['REG']  = W_OD_ra['REG'].astype('category')\n",
    "\n",
    "Afr_OD_ra['GLIM']  = Afr_OD_ra['GLIM'].astype('int').astype('category')\n",
    "Afr_OD_ra['REG']   = Afr_OD_ra['REG'].astype('int').astype('category')\n",
    "\n",
    "Afr_NOD_ra['GLIM']  = Afr_NOD_ra['GLIM'].astype('int').astype('category')\n",
    "Afr_NOD_ra['REG']   = Afr_NOD_ra['REG'].astype('int').astype('category')\n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "X_w = W_OD_ra[features]\n",
    "y_w = W_OD_ra[target].values.reshape(-1,1) \n",
    "\n",
    "\n",
    "X_afr = Afr_OD_ra[features]\n",
    "y_afr = Afr_OD_ra[target].values.reshape(-1,1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bs_rfr_hyp =  DIR/'Hyperparameters'/f'BS_hyperparameter.csv'\n",
    "\n",
    "\n",
    "\n",
    "bs_rfr_hyp_df = pd.read_csv(bs_rfr_hyp, sep='\\t')\n",
    "\n",
    "\n",
    "best_params = bs_rfr_hyp_df.to_dict('r')[0]\n",
    "\n",
    "print(file_label)\n",
    "\n",
    "\n",
    "print(len(Afr_OD_ra))\n",
    "print(len(W_OD_ra))\n",
    "\n",
    "\n",
    "X_afr.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2577d0",
   "metadata": {},
   "source": [
    "# pre-evaluation world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b1d9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) \n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    cost  = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return (100 - cost) * 100\n",
    "\n",
    "def min_e(y_true, y_pred):\n",
    "    cost  = abs(y_test - y_predict)\n",
    "    return cost.min()\n",
    "\n",
    "def mpe(y_true, y_pred):\n",
    "    return (np.mean((y_test -y_predict)/y_test) , 2)\n",
    "\n",
    "\n",
    "\n",
    "scores_cv = {\n",
    "\n",
    "'RMSE'     :  make_scorer(mean_squared_error , squared=False),\n",
    "#'NRMSE'    :  make_scorer(nrmse),\n",
    "'MAE'      :  make_scorer(mean_absolute_error),    \n",
    "#'MAPE'     :  make_scorer(mean_absolute_percentage_error ),\n",
    "#'ACC'      :  make_scorer(accuracy) ,\n",
    "'MPE'      :  make_scorer(mpe),\n",
    "'CD'       :  make_scorer(r2_score),\n",
    "#'EV'       :  make_scorer(explained_variance_score),\n",
    "#'MAX_E'    :  make_scorer( max_error),\n",
    "#'MIN_E'    :  make_scorer(min_e),\n",
    "#'MedAE'    :  make_scorer(median_absolute_error),\n",
    "#'CCC'      :  make_scorer(concordance_correlation_coefficient),\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429523d6",
   "metadata": {},
   "source": [
    "# Pre-evalaution Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3c8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 3\n",
    "\n",
    "KPI_afr_lr = pd.DataFrame()\n",
    "\n",
    "\n",
    "for best_features in tqdm_notebook(\n",
    "    range(8,16), desc = 'Processing: '):\n",
    "\n",
    "\n",
    "    regressor = RandomForestRegressor()\n",
    "    \n",
    "    tuned_params = {item[11:]: best_params[item] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "    rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "    numeric_transformer = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe),   (\"regressor\", regressor)]\n",
    "\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "    \n",
    "    #pipeline.set_params(**best_params)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    for key, scoring in tqdm_notebook( scores_cv.items(), desc='Scoring: ' ):\n",
    "    \n",
    "        KPI_afr_lr.loc[key, f'{best_features}_{file_label}']  = np.mean(cross_validate(\n",
    "                    pipeline, \n",
    "                    X_afr_lr, \n",
    "                    y_afr_lr,\n",
    "                    scoring=scoring,\n",
    "                      cv=cv)['test_score'])\n",
    "  \n",
    "\n",
    "    \n",
    "    # Print message to user\n",
    "    print('#'*60)\n",
    "\n",
    "\n",
    "\n",
    "####16 faetures\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "\n",
    "numeric_transformer = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "   (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe), (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "# Initialize Pipeline object\n",
    "pipeline= Pipeline(steps = steps)\n",
    "\n",
    "pipeline.set_params(**best_params)\n",
    "for key, scoring in tqdm_notebook( scores_cv.items(), desc='Scoring: ' ):\n",
    "\n",
    "    KPI_afr_lr.loc[key, f'{best_features}_{file_label}']  = np.mean(cross_validate(\n",
    "                pipeline, \n",
    "                X_afr_lr, \n",
    "                y_afr_lr,\n",
    "                scoring=scoring,\n",
    "                  cv=cv)['test_score'])\n",
    "\n",
    "# Print message to user\n",
    "print('#'*60)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74167b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "####16 faetures\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "\n",
    "\n",
    "numeric_transformer = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "   (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "steps=[(\"preprocessor\", preprocessor), (\"reducer\", rfe), (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "# Initialize Pipeline object\n",
    "pipeline= Pipeline(steps = steps)\n",
    "\n",
    "pipeline.set_params(**best_params)\n",
    "for key, scoring in tqdm_notebook( scores_cv.items(), desc='Scoring: ' ):\n",
    "\n",
    "    KPI_afr_lr.loc[key, f'str({best_features})_{file_label}']  = np.mean(cross_validate(\n",
    "                pipeline, \n",
    "                X_afr_lr, \n",
    "                y_afr_lr,\n",
    "                scoring=scoring,\n",
    "                  cv=cv)['test_score'])\n",
    "\n",
    "# Print message to user\n",
    "print('#'*60)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbbd077",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "\n",
    "# Set figure size and create barplot\n",
    "\n",
    "fig, axs = plt.subplots(8,2,figsize=(15, 100))\n",
    "\n",
    "plt.rcParams.update(plt_params)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 2)\n",
    "#fig.set_size_inches(30,30)\n",
    "\n",
    "#scores = ['RMSE', 'NRMSE','MAE', 'MAPE', 'CD','EV', 'MAX_E','MIN_E' ,'MedAE', 'MPE']\n",
    "\n",
    "scores = ['RMSE', 'MAE', 'NRMSE','MAPE', 'CD','EV', 'MAX_E', 'MAX', \n",
    "          'Stdev', 'RSD', 'Mean','Median','MedAE', 'MPE', 'ACC', 'CCC']\n",
    "\n",
    "scores = ['RMSE','MPE','CD', 'MAE']\n",
    "\n",
    "# Set graph style\n",
    "sns.set(font_scale = 2)\n",
    "n_models = 30\n",
    "#subfile = 'HOD'\n",
    "#files_rg = [ x for x in files_rg if subfile in x ]\n",
    "for score, ax in tqdm_notebook(zip(scores, axs.flatten()), total = len(scores)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    cols  = KPI_afr_lr.loc[score,:].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "\n",
    "    if score in ['CD','EV' ,'MAX', 'MPE', 'ACC','CCC']:\n",
    "        \n",
    "        \n",
    "        x_data = KPI_afr_lr.loc[score,cols].sort_values(ascending=False).index\n",
    "        y_data = KPI_afr_lr.loc[score,cols].sort_values(ascending=False).round(2)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0])\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        x_data = KPI_afr_lr.loc[score,cols].sort_values().index\n",
    "        y_data = KPI_afr_lr.loc[score,cols].sort_values().round(2)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0], )\n",
    "\n",
    "        # Generate a bolded horizontal line at y = 0\n",
    "        ax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1cf0b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rfecv this process is more stable\n",
    " \n",
    "kfold = 5\n",
    "\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean())\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "r2 = make_scorer(r2_score)\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "#ccc_score = make_scorer(concordance_correlation_coefficient , greater_is_better=True)\n",
    "\n",
    "scorings = {\n",
    "    'NRMSe':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    'R2':r2,\n",
    "    #'EV':'explained_variance'   \n",
    "    #'$p_c$': ccc_score,    \n",
    "}\n",
    "\n",
    "\n",
    "results_cv ={}\n",
    "\n",
    "tuned_params = {item[11:]: best_params[item] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "for key, score in scorings.items():\n",
    "    regressor = RandomForestRegressor()\n",
    "    \n",
    "    regressor = RandomForestRegressor(random_state=None)\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "\n",
    "    numeric_transformer = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"rfecv\", RFECV(regressor, \n",
    "                                    cv = cv, step = 1, #n_jobs=-1, \n",
    "                             scoring = score, verbose = 1))]\n",
    "\n",
    "\n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize RFECV object\n",
    "    #feature_selector = RFECV(pipeline['regressor'], cv = cv, step = 1, #n_jobs=-1, \n",
    "    #                         scoring = score, verbose = 1)\n",
    "    \n",
    "\n",
    "    # Fit RFECV\n",
    "    pipeline.fit(X_afr_lr, np.ravel(y_afr_lr))\n",
    "    #feature_selector .fit(X_w, np.ravel(y_w))\n",
    "    results_cv[key] = pipeline\n",
    "\n",
    "    # Get selected features\n",
    "    #feature_names = X_train_corr.columns\n",
    "    #selected_features = feature_names[feature_selector.support_].tolist()\n",
    "\n",
    "    print(f'terminated {key} {score}\\n')\n",
    "    print('terminated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a366f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RFECV progression score\n",
    "score_progression = pd.DataFrame()\n",
    "score_progression[\"NRMSe_RFECV\"] = results_cv['NRMSe']['rfecv'].cv_results_['mean_test_score'] * -1\n",
    "score_progression[\"R2_RFECV\"] = results_cv['R2']['rfecv'].cv_results_['mean_test_score']\n",
    "score_progression[\"n_features\"]= list(range(1,17))\n",
    "score_progression = score_progression.set_index(\"n_features\")\n",
    "score_progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "# Set figure size and create barplot\n",
    "#sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots( figsize=(30, 15))\n",
    "\n",
    "\n",
    "plt.rcParams.update(plt_params)\n",
    "\n",
    "\n",
    "\n",
    "feature_importance = pd.DataFrame()\n",
    " \n",
    "\n",
    "\n",
    "# Load hyper parameter \n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "\n",
    "numeric_transformer = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "   (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "    ]\n",
    ")\n",
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "steps=[(\"preprocessor\", preprocessor), (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "# Initialize Pipeline object\n",
    "pipeline= Pipeline(steps = steps)\n",
    "\n",
    "pipeline.set_params(**best_params)\n",
    "\n",
    "\n",
    "pipeline.fit(X_afr_lr,y_afr_lr)\n",
    "\n",
    "\n",
    "\n",
    "obs = obs.reset_index(drop=False).set_index('OBS_REF')\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance[\"RI\"] = pipeline['regressor'].feature_importances_\n",
    "feature_importance[\"LABELS\"]= obs.loc[features , 'LABELS'].values\n",
    "\n",
    "feature_importance.set_index('LABELS', inplace=True)\n",
    "\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"RI\", ascending=False)\n",
    "\n",
    "\n",
    "feature_importance[\"CUMSUM\"] = feature_importance[\"RI\"].cumsum()\n",
    "\n",
    "score_progression[\"CUMSUM\"] = feature_importance[\"CUMSUM\"].values\n",
    "\n",
    "sns.barplot(x = feature_importance[\"RI\"].values, \n",
    "            y = feature_importance[\"RI\"].index, ax=ax,\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 16)),  data = feature_importance)\n",
    "\n",
    "\n",
    "ax.set_ylabel('')\n",
    "\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "ax.locator_params(axis='x', nbins=7)\n",
    "\n",
    "\n",
    "ax.set_title(f'{sub_figs[0]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "#fig.savefig(dir_p/ 'fig'/\"fig_5.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db181328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# individual RFECV to calculate conribution of each feature to R2 and NRMSe\n",
    "\n",
    "for feature in obs.index:\n",
    "\n",
    "    print(feature)\n",
    "\n",
    "\n",
    "    X_train_afr_lr_feature = X_afr_lr[feature].to_frame()\n",
    "\n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    numeric_transformer = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "    pipeline.set_params(**best_params)\n",
    "\n",
    "    for key, scoring in scorings.items():\n",
    "        feature_importance.loc[obs.loc[feature, 'LABELS'], key] = np.mean(cross_validate(\n",
    "            pipeline, \n",
    "            X_train_afr_lr_feature, \n",
    "            y_afr_lr,\n",
    "            scoring=scoring,\n",
    "              cv=cv)['test_score'])\n",
    "\n",
    "\n",
    "feature_importance = feature_importance.abs() \n",
    "\n",
    "print('terminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a9264",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_RV_NRMSE = (feature_importance['RI'] < feature_importance['NRMSe']) & (feature_importance['NRMSe'] < feature_importance['R2'])\n",
    "\n",
    "mask_NRMSE_RV = (feature_importance['NRMSe'] < feature_importance['RI']) & (feature_importance['RI'] < feature_importance['R2']) \n",
    "    \n",
    "mask_R2_RV = (feature_importance['R2'] < feature_importance['RI']) & (feature_importance['RI'] < feature_importance['NRMSe'])\n",
    "\n",
    "\n",
    "mask_RV_R2 = (feature_importance['RI'] < feature_importance['R2']) & (feature_importance['R2'] < feature_importance['NRMSe'])\n",
    "\n",
    "mask_NRMSE_R2 = (feature_importance['NRMSe'] < feature_importance['R2']) & (feature_importance['R2'] < feature_importance['RI']) \n",
    "\n",
    "\n",
    "mask_R2_NRMSE = (feature_importance['R2'] < feature_importance['NRMSe']) & (feature_importance['NRMSe'] < feature_importance['RI'])\n",
    "\n",
    "\n",
    "\n",
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "fig, axes = plt.subplots(1,2, figsize=(30, 13),gridspec_kw={'width_ratios': [3, 2.5]})\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.rcParams.update(plt_params)\n",
    "\n",
    "\n",
    "\n",
    "axes.ravel()\n",
    "#sns.set(style=\"whitegrid\", color_codes=True, font_scale = 3)\n",
    "\n",
    "\n",
    "\n",
    "###1\n",
    "if mask_RV_NRMSE.any():\n",
    "    sns.barplot(x = feature_importance['R2'].values * mask_RV_NRMSE.astype(int).values, \n",
    "                y = feature_importance.index, \n",
    "                ax=axes[0], color='lightblue',\n",
    "                )\n",
    "\n",
    "\n",
    "    sns.barplot(x = feature_importance['NRMSe'].values * mask_RV_NRMSE.astype(int).values, \n",
    "                y = feature_importance.index, \n",
    "                ax=axes[0], color='orange', label='NRMSe',\n",
    "                )\n",
    "    sns.barplot(x = feature_importance[\"RI\"].values * mask_RV_NRMSE.astype(int).values, \n",
    "                y = feature_importance.index,  \n",
    "                ax=axes[0],  color='lightgreen',label=f\"\"\"Relative\n",
    "    importance\"\"\"\n",
    "                        )\n",
    "\n",
    "###2\n",
    "if mask_NRMSE_RV.any():\n",
    "    sns.barplot(x = feature_importance['R2'].values * mask_NRMSE_RV.astype(int).values, \n",
    "                y = feature_importance.index, \n",
    "                ax=axes[0], color='lightblue',\n",
    "                )\n",
    "\n",
    "\n",
    "    sns.barplot(x = feature_importance[\"RI\"].values * mask_NRMSE_RV.astype(int).values, \n",
    "                y = feature_importance.index,  \n",
    "                ax=axes[0],  color='lightgreen',label=f\"\"\"Relative\n",
    "    importance\"\"\"\n",
    "                        )\n",
    "\n",
    "    sns.barplot(x = feature_importance['NRMSe'].values * mask_NRMSE_RV.astype(int).values, \n",
    "                y = feature_importance.index, \n",
    "                ax=axes[0], color='orange', label='NRMSe',\n",
    "                )\n",
    "    \n",
    "\n",
    "###3\n",
    "if mask_R2_RV.any():\n",
    "    sns.barplot(x = feature_importance['NRMSe'].values * mask_R2_RV.astype(int).values, \n",
    "                y = feature_importance.index, \n",
    "                ax=axes[0], color='orange', label='NRMSe',\n",
    "                )\n",
    "\n",
    "\n",
    "    sns.barplot(x = feature_importance[\"RI\"].values * mask_R2_RV.astype(int).values, \n",
    "                y = feature_importance.index,  \n",
    "                ax=axes[0],  color='lightgreen',label=f\"\"\"Relative\n",
    "    importance\"\"\"\n",
    "                        )\n",
    "\n",
    "\n",
    "    \n",
    "    sns.barplot(x = feature_importance['R2'].values * mask_R2_RV.astype(int).values, \n",
    "            y = feature_importance.index, \n",
    "            ax=axes[0], color='lightblue',\n",
    "            )\n",
    "    \n",
    "\n",
    "###4\n",
    "if mask_RV_R2.any():\n",
    "    \n",
    "    sns.barplot(x = feature_importance['NRMSe'].values * mask_RV_R2.astype(int).values, \n",
    "                y = feature_importance.index, \n",
    "                ax=axes[0], color='orange', label='NRMSe',\n",
    "                )\n",
    "    \n",
    "    sns.barplot(x = feature_importance['R2'].values * mask_RV_R2.astype(int).values, \n",
    "                y = feature_importance.index, \n",
    "                ax=axes[0], color='lightblue',\n",
    "                )\n",
    "\n",
    "    sns.barplot(x = feature_importance[\"RI\"].values * mask_RV_R2.astype(int).values, \n",
    "                y = feature_importance.index,  \n",
    "                ax=axes[0],  color='lightgreen',label=f\"\"\"Relative\n",
    "    importance\"\"\"\n",
    "                        )\n",
    "\n",
    "###5\n",
    "    \n",
    "if mask_NRMSE_RV.any():\n",
    "    sns.barplot(x = feature_importance['R2'].values * mask_NRMSE_RV.astype(int).values, \n",
    "                y = feature_importance.index, \n",
    "                ax=axes[0], color='lightblue',\n",
    "                )\n",
    "\n",
    "\n",
    "    sns.barplot(x = feature_importance[\"RI\"].values * mask_NRMSE_RV.astype(int).values, \n",
    "                y = feature_importance.index,  \n",
    "                ax=axes[0],  color='lightgreen',label=f\"\"\"Relative\n",
    "    importance\"\"\"\n",
    "                        )\n",
    "\n",
    "    sns.barplot(x = feature_importance['NRMSe'].values * mask_NRMSE_RV.astype(int).values, \n",
    "                y = feature_importance.index, \n",
    "                ax=axes[0], color='orange', label='NRMSe',\n",
    "                )\n",
    "    \n",
    "####6\n",
    "if mask_R2_RV.any():\n",
    "    \n",
    "   \n",
    "    sns.barplot(x = feature_importance['NRMSe'].values * mask_R2_RV.astype(int).values, \n",
    "                y = feature_importance.index, \n",
    "                ax=axes[0], color='orange', label='NRMSe',\n",
    "                )\n",
    "    sns.barplot(x = feature_importance[\"RI\"].values * mask_R2_RV.astype(int).values, \n",
    "                y = feature_importance.index,  \n",
    "                ax=axes[0],  color='lightgreen',label=f\"\"\"Relative\n",
    "    importance\"\"\"\n",
    "                        )\n",
    "    \n",
    "    sns.barplot(x = feature_importance['R2'].values * mask_R2_RV.astype(int).values, \n",
    "            y = feature_importance.index, \n",
    "            ax=axes[0], color='lightblue',\n",
    "            )\n",
    "    \n",
    "    \n",
    "### optimal\n",
    "\n",
    "'''\n",
    "if mask_RV_NRMSE.any():\n",
    "    sns.barplot(x = feature_importance.loc[mask_RV_NRMSE[0:11], 'R2'].values, \n",
    "                y = feature_importance.loc[mask_RV_NRMSE[0:11], 'R2'].index, \n",
    "                ax=axes[0], color='lightblue',\n",
    "                )\n",
    "\n",
    "\n",
    "    sns.barplot(x = feature_importance.loc[mask_RV_NRMSE[0:11],'NRMSe'].values, \n",
    "                y = feature_importance.loc[mask_RV_NRMSE[0:11],'NRMSe'].index, \n",
    "                ax=axes[0], color='orange', label='NRMSe',\n",
    "                )\n",
    "    sns.barplot(x = feature_importance.loc[mask_RV_NRMSE[0:11],\"RI\"].values, \n",
    "                y = feature_importance.loc[mask_RV_NRMSE[0:11],\"RI\"].index,  \n",
    "                ax=axes[0],  color='lightgreen',label=f\"\"\"Relative\n",
    "    importance\"\"\"\n",
    "                        )\n",
    "    \n",
    "''' \n",
    "\n",
    "\n",
    "axes[0].set_ylabel('')\n",
    "axes[0].grid(False)\n",
    "\n",
    "\n",
    "\n",
    "#axes[0].patch.set_edgecolor('black')  \n",
    "#axes[0].patch.set_linewidth('3') \n",
    "# Hide the right and top spines\n",
    "axes[0].spines.right.set_visible(False)\n",
    "axes[0].spines.top.set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "axes[0].yaxis.set_ticks_position('left')\n",
    "axes[0].xaxis.set_ticks_position('bottom')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axes[0].locator_params(axis='x', nbins=7)\n",
    "#axes[0].legend(loc=[.55, .6], framealpha=0.5)\n",
    "\n",
    "#axes[0].set_title(f'{sub_figs[0]})', loc ='left', pad=20, size=40,  y=1.1)\n",
    "axes[0].set_xlabel(\"Normalized Score\")\n",
    "\n",
    "\n",
    "for key, score in scorings.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    #print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    if key == 'NRMSe':\n",
    "        #results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X_afr_lr.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "\n",
    "        axes[1].plot(score_progression.index, \n",
    "                 score_progression['NRMSe_RFECV'], color='orange', linewidth=6,\n",
    "                   marker=\"^\", label='$NRMSe$', markersize=22,)\n",
    "\n",
    "\n",
    "    else:\n",
    "        axes[1].plot(score_progression.index,\n",
    "                 score_progression['R2_RFECV'], color='lightblue', \n",
    "                     linewidth=6, marker=\"o\",  label='$R^2$', markersize=22,\n",
    "                       )\n",
    "\n",
    "\n",
    "axes[1].plot(score_progression.index, \n",
    "         score_progression['CUMSUM'], linewidth=6, \n",
    "            color='lightgreen',  marker=\"d\", \n",
    "             label=f'''Importance''', markersize=22,)\n",
    "\n",
    "\n",
    "axes[1].set_xlabel(\"Number of observables\")\n",
    "\n",
    "axes[1].set_ylabel(\"Normalized Score\")\n",
    "axes[1].legend(loc=[.45, .18], frameon=False)\n",
    "#axes[1].legend(loc=[.01, .7])\n",
    "#plt.axesvline(results[key].n_features_ ,color='r')\n",
    "#axes[1].set_title(f'{sub_figs[1]})', loc ='left', pad=20, size=40,  y=1.1)\n",
    "axes[1].locator_params(axis='y', nbins=10)\n",
    "axes[1].locator_params(axis='x', nbins=9)\n",
    "axes[1].grid(False)\n",
    "\n",
    "axes[1].spines.right.set_visible(False)\n",
    "axes[1].spines.top.set_visible(False)\n",
    "\n",
    "# Only show ticks on the left and bottom spines\n",
    "axes[1].yaxis.set_ticks_position('left')\n",
    "axes[1].xaxis.set_ticks_position('bottom')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "#fig.savefig(dir_p/'fig'/'presentation'/\"fig_p6d.jpeg\", bbox_inches='tight', dpi=300 )\n",
    "#fig.savefig(DIR/'fig'/\"fig_8.pdf\", bbox_inches='tight', dpi=300 )\n",
    "#fig.savefig(DIR/'fig'/\"fig_8.jpg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e6431a",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ebd8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "sorted_features = obs.reset_index(drop=False).set_index('LABELS')\n",
    "\n",
    "\n",
    "\n",
    "selected_features = []\n",
    "for best_feature in range(16,3, -1):\n",
    "    selected_features.extend([sorted_features.loc[feature_importance.index, 'OBS_REF'].values[0 :best_feature]])\n",
    "\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3af2f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline_dict = {}\n",
    "grids_dict = {}\n",
    "selected_features_dict = {}\n",
    "\n",
    "\n",
    "best_features = ['16', '15','14', '13','12', '11','10',\n",
    "                 '09','08', '07','06','05','04'\n",
    "                 ]\n",
    "\n",
    "\n",
    "scoring = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "\n",
    "kfold =10\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "\n",
    "label = 'AFR' \n",
    "\n",
    "for best_feature, selected_feature in tqdm_notebook(\n",
    "    zip(best_features ,selected_features) , total=len(best_features)   , desc = 'Training: '):\n",
    "\n",
    "    y_Afr = Afr_OD_ra_lr[target]\n",
    "    x_Afr = Afr_OD_ra_lr[selected_feature]\n",
    "    \n",
    "    \n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "\n",
    "    numeric_transformer = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[ (\"preprocessor\", preprocessor),  (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "    # Initialize Pipeline object\n",
    "    model_pipeline= Pipeline(steps = steps)\n",
    "    model_pipeline.set_params(**best_params)\n",
    "\n",
    "\n",
    "  \n",
    "    trained_model = model_pipeline.fit(x_Afr, y_Afr )\n",
    "    \n",
    "   \n",
    "\n",
    "    ######### save\n",
    "\n",
    "   \n",
    "    pipeline_dict[f'RFE_{best_feature}'] = trained_model\n",
    "    \n",
    "    #grids_dict[f'RFE_{best_feature}'] =  ds_afr[selected_feature].to_array().values\n",
    "    \n",
    "    selected_features_dict[f'RFE_{best_feature}']   = selected_feature\n",
    "\n",
    "    print(f'RFE_{best_feature} fitting is terminated' )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a1d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "grids_dict = {}\n",
    "\n",
    "n_features = ['16','15', '14', '13', '12', '11', '10', '09', '08', '07', '06', '05', '04']\n",
    "for selected_feature, n_feature in tqdm_notebook(zip(selected_features, n_features), \n",
    "                                                 total = len(n_features),\n",
    "                                      desc= 'Import from grid: ' ):\n",
    "    df = pd.DataFrame({'X': ds_afr_lr.XV.values.ravel(), 'Y': ds_afr_lr.YV.values.ravel()})\n",
    "\n",
    "    for feature in tqdm_notebook(selected_feature , \n",
    "                                            desc=f'{selected_feature}: ', leave=False ):\n",
    "        sleep(0.01)\n",
    "        df[feature] = ds_afr_lr[feature].values.ravel()\n",
    "    grids_dict[f'RFE_{n_feature}'] = df[selected_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2c9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = {}\n",
    "xs = range(len(ds_afr_lr.X))\n",
    "ys = range(len(ds_afr_lr.Y))\n",
    "nn = (len(ds_afr_lr.Y), len( ds_afr_lr.X))\n",
    "\n",
    "\n",
    "hq_gt = Afr_OD_ra_lr[[grid_index_afr, target]].set_index(grid_index_afr)\n",
    "hq_gt.index.names = ['index']\n",
    "\n",
    "for key, pipeline  in tqdm_notebook(pipeline_dict.items() , \n",
    "                                            desc=f'Modelling: '):\n",
    "    print(key)\n",
    "    pipeline = pipeline_dict[key]\n",
    "    AFR_Q_RFR = np.zeros(nn) # predicted HF value\n",
    "    AFR_grid = grids_dict[key][selected_features_dict[key]]\n",
    "    predictions_df[key] = pd.DataFrame({'X': ds_afr_lr.XV.values.ravel(), 'Y': ds_afr_lr.YV.values.ravel()})\n",
    "\n",
    "    if 'GLIM' in selected_features_dict[key]:\n",
    "        AFR_grid['GLIM']  = AFR_grid['GLIM'].astype('int').astype('category')\n",
    "    if 'REG' in selected_features_dict[key]:\n",
    "        AFR_grid['REG']  = AFR_grid['REG'].astype('int').astype('category')\n",
    "    predictions_df[key]['Prediction'] = pipeline.predict(AFR_grid).reshape(-1,1)\n",
    "    predictions_df[key].index.names = ['index']\n",
    "    final_df = pd.merge(predictions_df[key], hq_gt,  how=\"left\", on=\"index\")\n",
    "    final_df.to_csv(DIR/'Grids'/'Outputs'/f'{key}_ra.csv' , index=False, header=True, sep='\\t')\n",
    "    ds_afr_lr[key] = (('Y', 'X'), predictions_df[key]['Prediction'].values.reshape(nn) )\n",
    "    \n",
    "ds_afr_lr.to_netcdf(DIR/'Grids'/'Outputs'/\"ds_afr_rfr_ra_lr.nc\", mode='w', \n",
    "                    engine='netcdf4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef010e9",
   "metadata": {},
   "source": [
    "# RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4943c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "#create two datsets for A ratibng and b ratings\n",
    "hq_f = DIR / 'Dataset'/ 'References'/'q_Heat_Flow'/'NGHF.csv'\n",
    "\n",
    "elev_cut = -1000\n",
    "\n",
    "record_total = pd.read_csv(hq_f)\n",
    "\n",
    "record_total = record_total.rename(columns={'heat-flow (mW/m2)': target, 'longitude': 'lon', 'latitude': 'lat'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "hq_afr_lat = record_total[record_total['lat'].between(afr_lat_min, afr_lat_max, inclusive='both')]\n",
    "record_total_afr = hq_afr_lat[hq_afr_lat['lon'].between(afr_lon_min, afr_lon_max, inclusive='both')]\n",
    "\n",
    "\n",
    "\n",
    "hq_no_pole_afr = record_total_afr.dropna(subset = ['lon', 'lat', target])\n",
    "\n",
    "hq_no_pole_afr = hq_no_pole_afr[hq_no_pole_afr[target].between(hq_lower_bound, hq_upper_bound, inclusive='both')]\n",
    "\n",
    "\n",
    "#hq_no_pole_afr = hq_clean[hq_clean['lat'].between(world_lat_min, world_lat_max, inclusive='both')]\n",
    "hq_deep_afr = hq_no_pole_afr[(hq_no_pole_afr['elevation (m)']>elev_cut)][['lon', 'lat',target]]\n",
    "\n",
    "\n",
    "\n",
    "hq_final_a_afr = hq_no_pole_afr[(hq_no_pole_afr ['code6']=='A') & (hq_no_pole_afr ['elevation (m)']>elev_cut)][['lon', 'lat',target]]\n",
    "hq_final_b_afr= hq_no_pole_afr[(hq_no_pole_afr ['code6']=='B') & (hq_no_pole_afr ['elevation (m)']>elev_cut)][['lon', 'lat',target]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855e82a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Best_feature = 11\n",
    "\n",
    "obs = obs.reset_index(drop=False).set_index('LABELS')\n",
    "\n",
    "reduced_datsets = obs.loc[feature_importance.iloc[0:Best_feature, 0].index, :]\n",
    "reduced_datsets = reduced_datsets.reset_index()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "obs = obs.reset_index(drop=False).set_index('OBS_AFR')\n",
    "\n",
    "reduced_datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22acf1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "projection = 'M5.4i'\n",
    "\n",
    "\n",
    "frames = ['wNes', 'wNes','wNEs','Wnes', 'wnes', 'wnes','wnEs','WneS', 'wneS', 'wneS','wnES','wnES']\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "\n",
    "pygmt.config(FONT='25p')\n",
    "\n",
    "with fig.subplot(\n",
    "    nrows=6,\n",
    "    ncols=4,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['A)+o0.3/-1.5'],\n",
    "    margins=[\"0.3c\", \"2.7c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    #sharex=\"bt\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    #frame=\"WSrt\",\n",
    "):\n",
    "\n",
    "    with fig.set_panel(panel=0):\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=DIR/'GMT'/'temperature.cpt', #temp 19lev\n",
    "            #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=projection, frame='WNes', panel=0)\n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=projection,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.001p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            land='darkgrey'\n",
    "            #borders=[\"1/0.5p,black\"],\n",
    "            #water='white',\n",
    "            \n",
    "            )\n",
    "\n",
    "        fig.plot(x=hq_final_a_afr.lon, y=hq_final_a_afr.lat,  cmap=True, projection=projection,\n",
    "             color=hq_final_a_afr[target], #label=f\"'A Rating'\",\n",
    "                      pen=\"0.01p,darkgrey\", style=\"c0.21c\")\n",
    "        fig.plot(x=hq_final_b_afr.lon, y=hq_final_b_afr.lat,  cmap=True, projection=projection,\n",
    "             color=hq_final_b_afr[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.01p,darkgrey\", style=\"c0.21c\")\n",
    "        fig.colorbar(frame=[\"af\", f\"x+lGHF\\t\\t[mW/m@+2@+]\"], \n",
    "                     position=f\"g{str(afr_lon_min-1)}/{str(afr_lat_min-8.2)}+w12.5c/0.5c+h+e\")\n",
    "    \n",
    "\n",
    "    for  cmap_i, grid_label, v_range, label_i ,unit, importance, panel,  in zip(\n",
    "         reduced_datsets['CMAPS'],  reduced_datsets['OBS_AFR'],\n",
    "                    reduced_datsets['V_RANGE_AFR'], reduced_datsets['LABELS_gmt'],\n",
    "        reduced_datsets['UNITS_gmt'], feature_importance['RI'],\n",
    "        list(range(len(reduced_datsets)))):\n",
    "\n",
    "        \n",
    "        with fig.set_panel(panel=panel+1):\n",
    "            if cmap_i =='bilbao':\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]}',\n",
    "                #continuous=True,\n",
    "                reverse=True,\n",
    "                )\n",
    "            elif unit == 'class':\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]+1}/1',\n",
    "                categorical=list(range(v_range[0],v_range[1]+1)),\n",
    "                #continuous=True,\n",
    "                )\n",
    "            elif grid_label in ['SV_Velocity', 'PV_Velocity']:\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{ds_afr_lr[grid_label].min().values}/{ds_afr_lr[grid_label].max().values}',\n",
    "                #continuous=True,\n",
    "                reverse=False,\n",
    "                )\n",
    "            elif grid_label == 'EMAG2':\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]}',\n",
    "                #continuous=True,\n",
    "                reverse=False,\n",
    "                )\n",
    "            else:\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]}',\n",
    "                #continuous=True,\n",
    "                reverse=False,\n",
    "                )\n",
    "                \n",
    "\n",
    "            fig.basemap(region=region_gmt, projection=projection, frame=frames[panel], panel=panel+1)\n",
    "\n",
    "\n",
    "\n",
    "            fig.grdimage(\n",
    "                 grid=ds_afr_lr[grid_label], # xarray.DataArray containing VSV values\n",
    "                 region=region_gmt,\n",
    "                 projection=projection,\n",
    "                     cmap=cmap,\n",
    "\n",
    "                #shading='+a45+nt0.5'\n",
    "                #shading=dgrid\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            fig.coast(\n",
    "                projection=projection,\n",
    "                #shorelines=0.5,\n",
    "                water=\"lightblue\", \n",
    "                shorelines=\"0.1p,black\",\n",
    "                borders=[\"1/0.001p,black\"],\n",
    "                lakes=\"lightblue\",\n",
    "                rivers=\"lightblue\" ,\n",
    "                #borders=[\"1/0.5p,black\"],\n",
    "                #water='white',\n",
    "                )\n",
    "\n",
    "            #print(f'{importance} {label_i}')\n",
    "            #fig.colorbar(frame=[\"af\", f'x+l\"{label_i}\"\\t\\t\"[{unit}]\"\\t\\t({str(round(importance*100,1))}\\%)',\n",
    "            fig.colorbar(frame=[\"af\", f'x+l\"{label_i}\"\\t\\t\"[{unit}]\"',                           ],\n",
    "                    position=f\"g{str(afr_lon_min-1)}/{str(afr_lat_min-8.2)}+w12.5c/0.5c+h+e\")\n",
    "            \n",
    "\n",
    " \n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "\n",
    "#fig.savefig(DIR/'fig'/\"fig_3.pdf\", dpi=300 )\n",
    "#fig.savefig(DIR/'fig'/\"fig_3.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a49659f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
