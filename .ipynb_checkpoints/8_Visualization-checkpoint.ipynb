{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131fae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agrid.grid import Grid\n",
    "from pathlib import Path\n",
    "import os, sys, pickle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from numpy import load\n",
    "\n",
    "from scipy import stats, interpolate, spatial, io\n",
    "from scipy.ndimage import gaussian_filter, median_filter\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib as mpl\n",
    "from matplotlib.patches import Arc \n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "import pyproj as proj\n",
    "import rasterio\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numba as nb\n",
    "from numba import jit\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# helper function for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import make_scorer , r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import RFECV,RFE\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import gstools as gst\n",
    "from pykrige.rk import RegressionKriging\n",
    "import operator\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns; sns.set()\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error, mean_squared_error, r2_score, max_error, \\\n",
    "median_absolute_error, mean_absolute_percentage_error, mean_poisson_deviance, mean_gamma_deviance\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "\n",
    "import pygmt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder , PowerTransformer\n",
    "\n",
    "from sklearn.compose import TransformedTargetRegressor ,  ColumnTransformer\n",
    "\n",
    "\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b30f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parent directory\n",
    "\n",
    "#parent directory\n",
    "\n",
    "dir_p = Path().resolve() \n",
    "\n",
    "src_crs=4326\n",
    "src_crs_aus = 3577\n",
    "    \n",
    "#constants\n",
    "km = 1000\n",
    "milli = 0.001\n",
    "micro = 0.000001\n",
    "\n",
    "# fig size for presentation\n",
    "fig_pres_small = (4,3)\n",
    "\n",
    "fig_pres_small_cbar = (4,2)\n",
    "#aspect ratio\n",
    "fig_pres_large = (16,9)\n",
    "\n",
    "\n",
    "\n",
    "# We can exclude Arctic ocean and Antarctica, as there are no HF measurements to use\n",
    "world_lon_min, world_lon_max, world_lat_min, world_lat_max  = -180, 180, -60, 80\n",
    "\n",
    "# map extents of Africa and Australia\n",
    "afr_lon_min, afr_lon_max, afr_lat_min, afr_lat_max =  -20, 52, -37 , 38  \n",
    "aus_lon_min, aus_lon_max, aus_lat_min, aus_lat_max =  108,  156 , -45, -10\n",
    "\n",
    "\n",
    "# create grid for each region\n",
    "# crs Coordinate reference system\n",
    "\n",
    "#EPSG is projection\n",
    "# 0.2 degrees equal roughly 20 km\n",
    "\n",
    "World = Grid(res=[0.2, 0.2], up=world_lat_max, down=world_lat_min)\n",
    "\n",
    "# africa grid\n",
    "\n",
    "Africa =    Grid(res=[0.2, 0.2],  left = afr_lon_min, right= afr_lon_max, up=afr_lat_max , down=afr_lat_min)\n",
    "\n",
    "# africa grid low resolution 50 x 50 km\n",
    "\n",
    "Africa_50 =    Grid(res=[0.5, 0.5],  left = afr_lon_min, right= afr_lon_max, up=afr_lat_max , down=afr_lat_min)\n",
    "\n",
    "\n",
    "# to be added as verification set\n",
    "Aus = Grid(crs=3577, res = [20*km, 20*km], extent=[-2000*km, 2200*km, -5000*km, -1200*km])\n",
    "\n",
    "\n",
    "#dictionary of all grids\n",
    "\n",
    "grids = {}\n",
    "\n",
    "grids['Afr'] = Africa\n",
    "grids['Afr_50'] = Africa_50\n",
    "grids['Aus'] = Aus\n",
    "grids['World'] = World\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f28ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SeabornFig2Grid():\n",
    "\n",
    "    def __init__(self, seaborngrid, fig,  subplot_spec):\n",
    "        self.fig = fig\n",
    "        self.sg = seaborngrid\n",
    "        self.subplot = subplot_spec\n",
    "        if isinstance(self.sg, sns.axisgrid.FacetGrid) or \\\n",
    "            isinstance(self.sg, sns.axisgrid.PairGrid):\n",
    "            self._movegrid()\n",
    "        elif isinstance(self.sg, sns.axisgrid.JointGrid):\n",
    "            self._movejointgrid()\n",
    "        self._finalize()\n",
    "\n",
    "    def _movegrid(self):\n",
    "        \"\"\" Move PairGrid or Facetgrid \"\"\"\n",
    "        self._resize()\n",
    "        n = self.sg.axes.shape[0]\n",
    "        m = self.sg.axes.shape[1]\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(n,m, subplot_spec=self.subplot)\n",
    "        for i in range(n):\n",
    "            for j in range(m):\n",
    "                self._moveaxes(self.sg.axes[i,j], self.subgrid[i,j])\n",
    "\n",
    "    def _movejointgrid(self):\n",
    "        \"\"\" Move Jointgrid \"\"\"\n",
    "        h= self.sg.ax_joint.get_position().height\n",
    "        h2= self.sg.ax_marg_x.get_position().height\n",
    "        r = int(np.round(h/h2))\n",
    "        self._resize()\n",
    "        self.subgrid = gridspec.GridSpecFromSubplotSpec(r+1,r+1, subplot_spec=self.subplot)\n",
    "\n",
    "        self._moveaxes(self.sg.ax_joint, self.subgrid[1:, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_x, self.subgrid[0, :-1])\n",
    "        self._moveaxes(self.sg.ax_marg_y, self.subgrid[1:, -1])\n",
    "\n",
    "    def _moveaxes(self, ax, gs):\n",
    "        #https://stackoverflow.com/a/46906599/4124317\n",
    "        ax.remove()\n",
    "        ax.figure=self.fig\n",
    "        self.fig.axes.append(ax)\n",
    "        self.fig.add_axes(ax)\n",
    "        ax._subplotspec = gs\n",
    "        ax.set_position(gs.get_position(self.fig))\n",
    "        ax.set_subplotspec(gs)\n",
    "\n",
    "    def _finalize(self):\n",
    "        plt.close(self.sg.fig)\n",
    "        self.fig.canvas.mpl_connect(\"resize_event\", self._resize)\n",
    "        self.fig.canvas.draw()\n",
    "\n",
    "    def _resize(self, evt=None):\n",
    "        self.sg.fig.set_size_inches(self.fig.get_size_inches())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072107a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concordance_correlation_coefficient(y_true, y_pred):\n",
    "    \"\"\"Concordance correlation coefficient.\"\"\"\n",
    "    # Remove NaNs\n",
    "    df = pd.DataFrame({\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred\n",
    "    })\n",
    "    df = df.dropna()\n",
    "    y_true = df['y_true']\n",
    "    y_pred = df['y_pred']\n",
    "    # Pearson product-moment correlation coefficients\n",
    "    cor = np.corrcoef(y_true, y_pred)[0][1]\n",
    "    # Mean\n",
    "    mean_true = np.mean(y_true)\n",
    "    mean_pred = np.mean(y_pred)\n",
    "    # Variance\n",
    "    var_true = np.var(y_true)\n",
    "    var_pred = np.var(y_pred)\n",
    "    # Standard deviation\n",
    "    sd_true = np.std(y_true)\n",
    "    sd_pred = np.std(y_pred)\n",
    "    # Calculate CCC\n",
    "    numerator = 2 * cor * sd_true * sd_pred\n",
    "    denominator = var_true + var_pred + (mean_true - mean_pred)**2\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee2ea4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to ease looping with dictionaries\n",
    "\n",
    "regions_a_a5 = [ 'Afr','Afr_50' ]\n",
    "\n",
    "regions_w_a = [ 'World' ,'Afr',]\n",
    "\n",
    "\n",
    "regions_w_a_a5 = [ 'World' ,'Afr', 'Afr_50']\n",
    "\n",
    "\n",
    "regions_Total = ['World' ,'Afr', 'Afr_50',]\n",
    "\n",
    "# raster exenets to adjust map\n",
    "raster_extent_Afr = [grids['Afr'].extent[0], grids['Afr'].extent[1], grids['Afr'].extent[3], grids['Afr'].extent[2]]\n",
    "raster_extent_Afr_50 = [grids['Afr_50'].extent[0], grids['Afr_50'].extent[1], grids['Afr_50'].extent[3], grids['Afr_50'].extent[2]]\n",
    "raster_extent_World = [grids['World'].extent[0], grids['World'].extent[1], grids['World'].extent[3], grids['World'].extent[2]]\n",
    "\n",
    "# to correct plot maps\n",
    "raster_extents = {}\n",
    "\n",
    "raster_extents['Afr'] = raster_extent_Afr\n",
    "raster_extents['Afr_50'] = raster_extent_Afr_50\n",
    "raster_extents['World'] = raster_extent_World\n",
    "\n",
    "\n",
    "# list of latitudes and longitudes\n",
    "lon_dict = {}\n",
    "lat_dict = {}\n",
    "\n",
    "lon_dict['Afr'] = [afr_lon_min, afr_lon_max]\n",
    "lon_dict['Afr_50'] = [afr_lon_min, afr_lon_max]\n",
    "lon_dict['World'] = [world_lon_min, world_lon_max]\n",
    "\n",
    "lat_dict['Afr'] = [afr_lat_min, afr_lat_max]\n",
    "lat_dict['Afr_50'] = [afr_lat_min, afr_lat_max]\n",
    "lat_dict['World'] = [world_lat_min, world_lat_max]\n",
    "\n",
    "\n",
    "print('terminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6fcb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/nvkelso/natural-earth-vector\n",
    "# natural earth 10 m land shape\n",
    "ne_10m_land = dir_p / 'data'/ 'Shapefiles'/'NE'/ 'ne_10m_land.shp'\n",
    "continents = dir_p /'data'/ 'Shapefiles'/'continents'/ 'continent.shp'\n",
    "\n",
    "# LAND is water vs land\n",
    "#Continet describes each continent\n",
    "\n",
    "#assign_shape Rasterize vector polygons to grid \n",
    "\n",
    "for region in regions_a_a5:\n",
    "    # Use continental plates instead\n",
    "    grids[region].ds['LAND'] = (('Y', 'X'), grids[region].assign_shape(ne_10m_land, \n",
    "                                               'scalerank', map_to_int = False, burn_val = 1))\n",
    "\n",
    "\n",
    "    grids[region].ds['CONTINENT'] = (('Y', 'X'), grids[region].assign_shape(continents, \n",
    "                                               'CONTINENT', map_to_int = True))\n",
    "\n",
    "\n",
    "\n",
    "    grids[region].map_grid('CONTINENT', raster_extent= raster_extents[region], \n",
    "                          cmap='jet', figsize=(10,10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42de9a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pd.DataFrame()\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "obs[\"REF_n\"] = [ \"MOHO\",\"LAB\", \"RHO_C\", \"SV\", \"PV\", \"CTD\",\n",
    "             \"RHO_L\", \"DEM\", \n",
    "                \"VOLC_DIST_W\", \"A_MEDIAN_W\", \"FA\", \"SI\",\"LITH_MANTLE\", \n",
    "                \"EMAG2_CLASS\", \"GEOID\", \"BG\",\n",
    "              \"GLIM\"]\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "obs[\"OBS_REF_IDW\"] = [\"CTD_IDW\" ,  \"SI_IDW\",\"LAB_IDW\", \"MOHO_IDW\",\n",
    "            \"SV_IDW\",\"PV_IDW\", \n",
    "            \"GEOID_IDW\",\"FA_IDW\",\"DEM\",\"BG_IDW\", \"EMAG2_CLASS\",\n",
    "                   \"RHO_L_IDW\", \"RHO_C_IDW\", \n",
    "                  \"VOLC_DIST_W\", \"REG\", \"GLIM\"]\n",
    "\n",
    "\n",
    "\n",
    "obs[\"OBS_REF_LN\"] = [\"CTD_LN\" ,  \"SI_LN\",\"LAB_LN\", \"MOHO_LN\",\n",
    "            \"SV_LN\",\"PV_LN\", \n",
    "            \"GEOID_LN\",\"FA_LN\",\"DEM\",\"BG_LN\", \"EMAG2_CLASS\",\n",
    "                  \"RHO_L_LN\", \"RHO_C_LN\", \n",
    "                      \"VOLC_DIST_W\",\"REG\", \"GLIM\"]\n",
    "\n",
    "obs[\"OBS_AFR_IDW\"] = [\"CTD_IDW\" ,  \"SI_IDW\",\"LAB_IDW\", \"MOHO_IDW\",\n",
    "            \"SV_SPEED_IDW\",\"PV_SPEED_IDW\", \n",
    "            \"GEOID_IDW\",\"FA_IDW\",\"DEM\",\"BG_IDW\", \"EMAG2\",\n",
    "                   \"RHO_L_IDW\", \"RHO_C_IDW\", \n",
    "                  \"VOLC_DIST\", \"REG\", \"GLIM\"]\n",
    "  \n",
    "     \n",
    "# Labels for plots etc\n",
    "obs[\"LABELS\"] = [\"CTD\",  \"Shape index\", \"LAB\", \"Moho\", \n",
    "                \"S@_v@ 150km\", \"P@_v@ 150km\", \n",
    "                \"Geoid\", \"Free air\", \"DEM\", \"Bouguer\", \"Mag.\", \n",
    "                \"Lith. rho\", \"Crust rho\",  \n",
    "                 \"Volcano\", \"REG\", \"GliM\", ]  \n",
    "\n",
    "\n",
    "obs[\"LABELS\"] = [\"CTD\",  \"Shape index\", \"LAB\", \"Moho\", \n",
    "                \"$S_v$ @150km\", \"$P_v$ @150km\", \n",
    "                \"Geoid\", \"Free air\", \"DEM\", \"Bouguer\", \"Mag.\", \n",
    "                \"Lith. ρ\", \"Crust ρ\",  \n",
    "                 \"Volcano\", \"REG\", \"GliM\", ]\n",
    "    \n",
    "# \"vp/vs\"\n",
    "# Units to display in plots etc\n",
    "obs[\"UNITS\"] = [\"km\",  \"si\", \"km\", \"km\",\n",
    "             \"$\\delta$ v_s %\",\"$\\delta$ v_p %\", \n",
    "             \"m\", \"mGal\", \"m\", \"mGal\",  \"f(nT)\", \n",
    "                 \"kg/m$^3$\", \"kg/m$^3$\",\n",
    "                \"km\",  \"class\", \"class\"]\n",
    "\n",
    "\n",
    "\n",
    "obs[\"UNITS\"] = [\"km\",  \"si\", \"km\", \"km\",\n",
    "             \"km/s\",\"km/s\", \n",
    "             \"m\", \"mGal\", \"m\", \"mGal\",  \"nT\", \n",
    "                 \"kg/m@+3@+\", \"kg/m@+3@+\",\n",
    "                \"km\",  \"class\", \"class\"]\n",
    "        \n",
    "# Range of colormap for plots. Similar data are placed in same ranges for consistancy\n",
    "obs[\"V_RANGE\"] = [(0,50), (-1,1),(0,300),(15,60),\n",
    "              (-0.075,0.075), (-0.02,0.02), \n",
    "              (-45,45), (-100,100) , (-2200, 2200),(-100,100),  (-0.4, 0.4), \n",
    "                   (3260, 3360), (2650, 2950),\n",
    "                  (0,1), (1,6),(1,16),]\n",
    "\n",
    "\n",
    "    \n",
    "obs[\"V_RANGE_AFR\"] = [(0,50), (-1,1),(50,250),(20,50),\n",
    "          (-0.075,0.075), (-0.02,0.02), \n",
    "          (-45,45), (-100,100) , (-2200, 2200),(-100,100),  (-200, 200), \n",
    "               (3260, 3360), (2650, 2950),\n",
    "              (0,100), (1,6),(1,15),]\n",
    "\n",
    "\n",
    "obs[\"CMAPS\"] = [\"batlow\",  \"broc\", \"bamako\", \"batlow\", \n",
    "             \"roma\",\"roma\", \n",
    "             \"bamako\", \"broc\", \"bukavu\", \"broc\", \"batlow\",            \n",
    "                \"batlow\", \"batlow\",\n",
    "               \"bamako\",  \"batlowS\",\"topo\", ]\n",
    "\n",
    "\n",
    "#new_index = [4,3,15,6,7,0,14,10,16,17,9, 2,1,5,13,12, 8,11,]\n",
    "\n",
    "#new_index = [4,3,15,6,7,0, 14, 10,16, 8, 9,2, 13, 12, 8, 11, ]\n",
    "\n",
    "#obs = obs.reindex(new_index)\n",
    "\n",
    "obs.index = np.arange(0,len(obs))\n",
    "\n",
    "pd.options.display.width = 370\n",
    "pd.options.display.max_colwidth = 12\n",
    "print(obs)\n",
    "\n",
    "n_obs = len(obs)\n",
    "\n",
    "obs_dict = obs.to_dict(orient=\"records\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969658c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'heat-flow (mW/m2)'\n",
    "coord = ['lon', 'lat']\n",
    "\n",
    "\n",
    "\n",
    "#features_ex_idw = []\n",
    "#features_ex_ln = []\n",
    "\n",
    "\n",
    "features_idw = obs['OBS_REF_IDW'].tolist()\n",
    "features_ln = obs['OBS_REF_LN'].tolist()\n",
    "\n",
    "\n",
    "#in_features_idw = set(features_idw)\n",
    "#in_features_ln = set(features_ln)\n",
    "\n",
    "#in_features_ln_but_not_in_features_idw = in_features_ln - in_features_idw\n",
    "\n",
    "#features_all = features_idw + list(in_features_ln_but_not_in_features_idw)\n",
    "\n",
    "\n",
    "features_ex_idw = copy.deepcopy(features_idw)\n",
    "features_ex_idw.extend(coord)\n",
    "features_ex_idw.append(target)\n",
    "\n",
    "\n",
    "features_ex_ln = copy.deepcopy(features_ln)\n",
    "features_ex_ln.extend(coord)\n",
    "features_ex_ln.append(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82f536",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_Afr_50_ra_f =  dir_p/'data'/'dataset'/'Preprocessed'/'Training_Afr_50_OD_IDW_ra.csv'\n",
    "training_Afr_50_ra = pd.read_csv(training_Afr_50_ra_f, sep='\\t')\n",
    "\n",
    "training_Afr_50_rab_f =  dir_p/'data'/'dataset'/'Preprocessed'/'Training_Afr_50_OD_IDW_rab.csv'\n",
    "training_Afr_50_rab = pd.read_csv(training_Afr_50_rab_f, sep='\\t')\n",
    "\n",
    "#######\n",
    "\n",
    "training_Afr_50_int_ra_f =  dir_p/'data'/'dataset'/'Preprocessed'/'Training_Afr_50_ra_int.csv'\n",
    "training_Afr_50_int_ra = pd.read_csv(training_Afr_50_int_ra_f)\n",
    "\n",
    "training_Afr_50_int_rab_f =  dir_p/'data'/'dataset'/'Preprocessed'/'Training_Afr_50_rab_int.csv'\n",
    "training_Afr_50_int_rab = pd.read_csv(training_Afr_50_int_rab_f)\n",
    "\n",
    "\n",
    "mask_ra = training_Afr_50_int_ra[target] <200\n",
    "\n",
    "training_Afr_50_int_ra  = training_Afr_50_int_ra[mask_ra]\n",
    "\n",
    "\n",
    "mask_rab = training_Afr_50_int_rab[target] <200\n",
    "\n",
    "training_Afr_50_int_rab  = training_Afr_50_int_rab[mask_rab]\n",
    "######\n",
    "\n",
    "\n",
    "training_Afr_50_int_ra\n",
    "\n",
    "\n",
    "\n",
    "training_Afr_50_rab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033b85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_Afr_ra_f =  dir_p/'data'/'dataset'/'Preprocessed'/'Training_Afr_OD_IDW_ra.csv'\n",
    "training_Afr_ra = pd.read_csv(training_Afr_ra_f, sep='\\t')\n",
    "\n",
    "training_Afr_rab_f =  dir_p/'data'/'dataset'/'Preprocessed'/'Training_Afr_OD_IDW_rab.csv'\n",
    "training_Afr_rab = pd.read_csv(training_Afr_rab_f, sep='\\t')\n",
    "\n",
    "#######\n",
    "\n",
    "training_Afr_int_ra_f =  dir_p/'data'/'dataset'/'Preprocessed'/'Training_Afr_ra_int.csv'\n",
    "training_Afr_int_ra = pd.read_csv(training_Afr_int_ra_f)\n",
    "\n",
    "training_Afr_int_rab_f =  dir_p/'data'/'dataset'/'Preprocessed'/'Training_Afr_rab_int.csv'\n",
    "training_Afr_int_rab = pd.read_csv(training_Afr_int_rab_f)\n",
    "\n",
    "\n",
    "mask_ra = training_Afr_int_ra[target] <200\n",
    "\n",
    "training_Afr_int_ra  = training_Afr_int_ra[mask_ra]\n",
    "\n",
    "\n",
    "mask_rab = training_Afr_int_rab[target] <200\n",
    "\n",
    "training_Afr_int_rab  = training_Afr_int_rab[mask_rab]\n",
    "######\n",
    "\n",
    "\n",
    "training_Afr_int_ra\n",
    "\n",
    "\n",
    "\n",
    "training_Afr_rab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee4b99",
   "metadata": {},
   "source": [
    "# Comaprison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4f2150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "files = [\n",
    "        #'OD_IDW_ra',\n",
    "        #'NOD_IDW_ra',\n",
    "         'OD_IDW_rab',\n",
    "        'NOD_IDW_rab',\n",
    "\n",
    "        ]\n",
    "\n",
    "observables = [    \n",
    "        #features_idw, features_idw,\n",
    "        features_idw, features_idw,\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file_label, observable in zip(files, observables):\n",
    "    \n",
    "     \n",
    "    KPI_50_df = pd.DataFrame()\n",
    "\n",
    "    #### training\n",
    "    tarin_Afr_50_f =  dir_p/ 'data'/'dataset'/'Preprocessed'/f'Training_Afr_50_{file_label}.csv'\n",
    "    \n",
    "        \n",
    "    train = pd.read_csv(tarin_Afr_50_f, sep='\\t')\n",
    "\n",
    "    \n",
    "    X = train[observable] \n",
    "    y = train[target]\n",
    "    \n",
    "    X['GLIM']  = X['GLIM'].astype('int').astype('category')\n",
    "    X['REG']  = X['REG'].astype('int').astype('category')\n",
    "\n",
    "    # hyperparameter\n",
    "    bs_rfr_hyp =  dir_p/'RF_Hyperparameters'/f'RFR_{file_label}.csv'\n",
    "\n",
    "\n",
    "    bs_rfr_hyp_df = pd.read_csv(bs_rfr_hyp, sep='\\t')\n",
    "\n",
    "\n",
    "    best_params = bs_rfr_hyp_df.to_dict('list')\n",
    "\n",
    "\n",
    "    # Load hyper parameter \n",
    "\n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "    \n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[ (\"preprocessor\", preprocessor),  (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "    \n",
    "    model_pipeline.fit(X, y )\n",
    "    \n",
    "    y_hat = model_pipeline.predict(X)\n",
    "\n",
    "    print('optimized')\n",
    "\n",
    "    errors      = abs(y - y_hat)\n",
    "    mape        = round( mean_absolute_percentage_error(y, y_hat), 2)  \n",
    "    accuracy    = round(100 - mape*100, 2)\n",
    "    mae         = round(mean_absolute_error(y, y_hat ), 2)\n",
    "    rmse        = round(mean_squared_error(y, y_hat , squared=False), 2)\n",
    "    nrmse       = round( rmse/(y.mean()) , 2)\n",
    "    r2          = round(r2_score(y, y_hat ), 2)\n",
    "    ev          = round( explained_variance_score(y, y_hat), 2)\n",
    "    max_e       = round( max_error(y, y_hat), 2)\n",
    "    min_e       = round( errors.min(), 2)\n",
    "    mnae        = round( median_absolute_error(y, y_hat), 2) \n",
    "    #mpd         = round( mean_poisson_deviance(y, y_hat), 2) \n",
    "    #mgd         = round( mean_gamma_deviance(y, y_hat), 2) \n",
    "    # # Mean Absolute Error (MAE)\n",
    "    mpe         =  round(np.mean((y -y_hat)/y) , 2)\n",
    "    ccc         =   round( concordance_correlation_coefficient(y, y_hat), 2) \n",
    "\n",
    "\n",
    "\n",
    "    KPI_50_df.loc['NRMSe', f'{file_label}'] = nrmse\n",
    "    KPI_50_df.loc['RMSE', f'{file_label}'] = rmse\n",
    "    KPI_50_df.loc['MAE', f'{file_label}'] = mae\n",
    "    KPI_50_df.loc['MAPE', f'{file_label}'] = mape\n",
    "    KPI_50_df.loc['$R^2$', f'{file_label}'] = r2\n",
    "    KPI_50_df.loc['EV', f'{file_label}'] = ev\n",
    "    KPI_50_df.loc['Max_e', f'{file_label}'] = max_e\n",
    "    KPI_50_df.loc['MIN_E', f'{file_label}'] = min_e\n",
    "    KPI_50_df.loc['MedAE', f'{file_label}'] = mnae\n",
    "    KPI_50_df.loc['MPe', f'{file_label}'] = mpe\n",
    "    KPI_50_df.loc['Max', f'{file_label}'] = round(y_hat.max(),1)\n",
    "    KPI_50_df.loc['MIN', f'{file_label}'] = y_hat.min()\n",
    "    KPI_50_df.loc['ACC', f'{file_label}'] = accuracy\n",
    "    KPI_50_df.loc['Mean', f'{file_label}'] = round(np.mean(y_hat),2)\n",
    "    KPI_50_df.loc['Median', f'{file_label}'] = round(np.median(y_hat),2)\n",
    "    KPI_50_df.loc['Stdev', f'{file_label}'] = round(np.std(y_hat),2)\n",
    "    KPI_50_df.loc['RSD', f'{file_label}'] = round(np.std(y_hat) / np.mean(y_hat) ,2)\n",
    "    KPI_50_df.loc['$p_c$', f'{file_label}'] = ccc\n",
    "    #save results\n",
    "    kpi_f =  dir_p/'KPI'/'Afr_50'/f'KPI_Afr_50_{file_label}.csv'\n",
    "\n",
    "    KPI_50_df.to_csv(kpi_f , sep='\\t')\n",
    "    \n",
    "    \n",
    "    print(f'terminated {file_label}')\n",
    "\n",
    "print('terminated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99806f89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "KPI_50_df = pd.DataFrame()\n",
    "files_f = [filename for filename in os.listdir(dir_p/'KPI'/'Afr_50') if 'KPI_Afr_50' in filename]\n",
    "for file in zip(files_f):\n",
    "    path = dir_p/'KPI'/'Afr_50'/f'{file[0]}'\n",
    "    tmp_df = pd.read_csv(path, index_col=0, sep='\\t')\n",
    "    KPI_50_df = pd.concat([tmp_df, KPI_50_df], axis=1)\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "\n",
    "# Set figure size and create barplot\n",
    "\n",
    "fig, axs = plt.subplots(2,3,figsize=(30, 16))\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 2)\n",
    "#fig.set_size_inches(30,30)\n",
    "\n",
    "#scores = ['RMSE', 'NRMSE','MAE', 'MAPE', 'CD','EV', 'MAX_E','MIN_E' ,'MedAE', 'MPE']\n",
    "scores = ['NRMSe', '$R^2$', '$p_c$', 'MPe', 'Max_e', 'Max'\n",
    "           ]\n",
    "\n",
    "#subfile = 'HOD'\n",
    "#files = [ x for x in files if subfile in x ]\n",
    "for score, ax in zip(scores, axs.flatten()):\n",
    "\n",
    "\n",
    "\n",
    "    if score in ['$R^2$','EV' ,'Max', 'MPe', 'ACC','$p_c$']:\n",
    "        x_data = KPI_50_df.loc[score,files].sort_values(ascending=False).index\n",
    "        y_data = KPI_50_df.loc[score,files].sort_values(ascending=False)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0])\n",
    "\n",
    "\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        x_data = KPI_50_df.loc[score,files].sort_values().index\n",
    "        y_data = KPI_50_df.loc[score,files].sort_values()\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0], )\n",
    "\n",
    "\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "#plt.savefig(f\"{score.__name__} Scores.png\", dpi = 1080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ff4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_label  ='OD_IDW_rab'\n",
    "\n",
    "#### training\n",
    "tarin_Afr_50_f =  dir_p/ 'data'/'dataset'/'Preprocessed'/f'Training_Afr_50_{file_label}.csv'\n",
    "\n",
    "\n",
    "train = pd.read_csv(tarin_Afr_50_f, sep='\\t')\n",
    "\n",
    "X = train[features_idw]\n",
    "y = train[target]\n",
    "\n",
    "X['GLIM']  = X['GLIM'].astype('int').astype('category')\n",
    "X['REG']  = X['REG'].astype('int').astype('category')\n",
    "\n",
    "\n",
    " \n",
    "kfold = 10 \n",
    "\n",
    "\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) \n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "ccc_score = make_scorer(concordance_correlation_coefficient , greater_is_better=True)\n",
    "\n",
    "scoring = {\n",
    "    '$NRMSe$':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    '$R^2$':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'$p_c$': ccc_score,    \n",
    "}\n",
    "\n",
    "\n",
    "results ={}\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize RFECV object\n",
    "    feature_selector = RFECV(regressor, cv = cv, step = 1, #n_jobs=-1, \n",
    "                             scoring = score, verbose = 1)\n",
    "\n",
    "    # Fit RFECV\n",
    "    feature_selector.fit(X, np.ravel(y))\n",
    "    results[key] = feature_selector\n",
    "\n",
    "    # Get selected features\n",
    "    #feature_names = X_train_corr.columns\n",
    "    #selected_features = feature_names[feature_selector.support_].tolist()\n",
    "\n",
    "    print(f'terminated {key} {score}\\n')\n",
    "    print('terminated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc30b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "files = [\n",
    "        #'OD_IDW_ra',\n",
    "        #'NOD_IDW_ra',\n",
    "         'OD_IDW_rab',\n",
    "        'NOD_IDW_rab',\n",
    "\n",
    "        ]\n",
    "\n",
    "observables = [    \n",
    "        features_idw, features_idw,\n",
    "        features_idw, features_idw,\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for file_label, observable in zip(files, observables):\n",
    "    \n",
    "     \n",
    "    KPI_df = pd.DataFrame()\n",
    "\n",
    "    #### training\n",
    "    tarin_Afr_f =  dir_p/ 'data'/'dataset'/'Preprocessed'/f'Training_Afr_{file_label}.csv'\n",
    "    \n",
    "        \n",
    "    train = pd.read_csv(tarin_Afr_f, sep='\\t')\n",
    "\n",
    "    \n",
    "    X = train[observable] \n",
    "    y = train[target]\n",
    "    \n",
    "    X['GLIM']  = X['GLIM'].astype('int').astype('category')\n",
    "    X['REG']  = X['REG'].astype('int').astype('category')\n",
    "\n",
    "    # hyperparameter\n",
    "    bs_rfr_hyp =  dir_p/'RF_Hyperparameters'/f'RFR_{file_label}.csv'\n",
    "\n",
    "\n",
    "    bs_rfr_hyp_df = pd.read_csv(bs_rfr_hyp, sep='\\t')\n",
    "\n",
    "\n",
    "    best_params = bs_rfr_hyp_df.to_dict('list')\n",
    "\n",
    "\n",
    "    # Load hyper parameter \n",
    "\n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "    \n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[ (\"preprocessor\", preprocessor),  (\"regressor\", regressor)]\n",
    "\n",
    "\n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "    \n",
    "    model_pipeline.fit(X, y )\n",
    "    \n",
    "    y_hat = model_pipeline.predict(X)\n",
    "\n",
    "    print('optimized')\n",
    "\n",
    "    errors      = abs(y - y_hat)\n",
    "    mape        = round( mean_absolute_percentage_error(y, y_hat), 2)  \n",
    "    accuracy    = round(100 - mape*100, 2)\n",
    "    mae         = round(mean_absolute_error(y, y_hat ), 2)\n",
    "    rmse        = round(mean_squared_error(y, y_hat , squared=False), 2)\n",
    "    nrmse       = round( rmse/(y.mean()) , 2)\n",
    "    r2          = round(r2_score(y, y_hat ), 2)\n",
    "    ev          = round( explained_variance_score(y, y_hat), 2)\n",
    "    max_e       = round( max_error(y, y_hat), 2)\n",
    "    min_e       = round( errors.min(), 2)\n",
    "    mnae        = round( median_absolute_error(y, y_hat), 2) \n",
    "    #mpd         = round( mean_poisson_deviance(y, y_hat), 2) \n",
    "    #mgd         = round( mean_gamma_deviance(y, y_hat), 2) \n",
    "    # # Mean Absolute Error (MAE)\n",
    "    mpe         =  round(np.mean((y -y_hat)/y) , 2)\n",
    "    ccc         =   round( concordance_correlation_coefficient(y, y_hat), 2) \n",
    "\n",
    "\n",
    "\n",
    "    KPI_df.loc['NRMSe', f'{file_label}'] = nrmse\n",
    "    KPI_df.loc['RMSE', f'{file_label}'] = rmse\n",
    "    KPI_df.loc['MAE', f'{file_label}'] = mae\n",
    "    KPI_df.loc['MAPE', f'{file_label}'] = mape\n",
    "    KPI_df.loc['$R^2$', f'{file_label}'] = r2\n",
    "    KPI_df.loc['EV', f'{file_label}'] = ev\n",
    "    KPI_df.loc['Max_e', f'{file_label}'] = max_e\n",
    "    KPI_df.loc['MIN_E', f'{file_label}'] = min_e\n",
    "    KPI_df.loc['MedAE', f'{file_label}'] = mnae\n",
    "    KPI_df.loc['MPe', f'{file_label}'] = mpe\n",
    "    KPI_df.loc['Max', f'{file_label}'] = round(y_hat.max(),1)\n",
    "    KPI_df.loc['MIN', f'{file_label}'] = y_hat.min()\n",
    "    KPI_df.loc['ACC', f'{file_label}'] = accuracy\n",
    "    KPI_df.loc['Mean', f'{file_label}'] = round(np.mean(y_hat),2)\n",
    "    KPI_df.loc['Median', f'{file_label}'] = round(np.median(y_hat),2)\n",
    "    KPI_df.loc['Stdev', f'{file_label}'] = round(np.std(y_hat),2)\n",
    "    KPI_df.loc['RSD', f'{file_label}'] = round(np.std(y_hat) / np.mean(y_hat) ,2)\n",
    "    KPI_df.loc['$p_c$', f'{file_label}'] = ccc\n",
    "    #save results\n",
    "    kpi_f =  dir_p/'KPI'/'Afr'/f'KPI_Afr_{file_label}.csv'\n",
    "\n",
    "    KPI_df.to_csv(kpi_f , sep='\\t')\n",
    "    \n",
    "    \n",
    "    print(f'terminated {file_label}')\n",
    "\n",
    "print('terminated')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0257d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "KPI_df = pd.DataFrame()\n",
    "files_f = [filename for filename in os.listdir(dir_p/'KPI'/'Afr') if 'KPI_Afr' in filename]\n",
    "for file in zip(files_f):\n",
    "    path = dir_p/'KPI'/'Afr'/f'{file[0]}'\n",
    "    tmp_df = pd.read_csv(path, index_col=0, sep='\\t')\n",
    "    KPI_df = pd.concat([tmp_df, KPI_df], axis=1)\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "\n",
    "# Set figure size and create barplot\n",
    "\n",
    "fig, axs = plt.subplots(2,3,figsize=(30, 16))\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 2)\n",
    "#fig.set_size_inches(30,30)\n",
    "\n",
    "#scores = ['RMSE', 'NRMSE','MAE', 'MAPE', 'CD','EV', 'MAX_E','MIN_E' ,'MedAE', 'MPE']\n",
    "scores = ['NRMSe', '$R^2$', '$p_c$', 'MPe', 'Max_e', 'Max'\n",
    "           ]\n",
    "\n",
    "#subfile = 'HOD'\n",
    "#files = [ x for x in files if subfile in x ]\n",
    "for score, ax in zip(scores, axs.flatten()):\n",
    "\n",
    "\n",
    "\n",
    "    if score in ['$R^2$','EV' ,'Max', 'MPe', 'ACC','$p_c$']:\n",
    "        x_data = KPI_df.loc[score,files].sort_values(ascending=False).index\n",
    "        y_data = KPI_df.loc[score,files].sort_values(ascending=False)\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0])\n",
    "\n",
    "\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        x_data = KPI_df.loc[score,files].sort_values().index\n",
    "        y_data = KPI_df.loc[score,files].sort_values()\n",
    "        bar = sns.barplot(y_data[:], x_data[:] ,     ax=ax)\n",
    "        bar.bar_label(ax.containers[0], )\n",
    "\n",
    "\n",
    "\n",
    "        # Turn frame off\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "        #ax.legend(loc='upper left')\n",
    "\n",
    "        # Tight layout\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "#plt.savefig(f\"{score.__name__} Scores.png\", dpi = 1080)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ff895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file_label  ='OD_IDW_rab'\n",
    "\n",
    "#### training\n",
    "tarin_Afr_f =  dir_p/ 'data'/'dataset'/'Preprocessed'/f'Training_Afr_{file_label}.csv'\n",
    "\n",
    "\n",
    "train = pd.read_csv(tarin_Afr_f, sep='\\t')\n",
    "\n",
    "X = train[features_idw]\n",
    "y = train[target]\n",
    "\n",
    "X['GLIM']  = X['GLIM'].astype('int').astype('category')\n",
    "X['REG']  = X['REG'].astype('int').astype('category')\n",
    "\n",
    "\n",
    " \n",
    "kfold = 10 \n",
    "\n",
    "\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) \n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "ccc_score = make_scorer(concordance_correlation_coefficient , greater_is_better=True)\n",
    "\n",
    "scoring = {\n",
    "    '$NRMSe$':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    '$R^2$':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'$p_c$': ccc_score,    \n",
    "}\n",
    "\n",
    "\n",
    "results ={}\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize RFECV object\n",
    "    feature_selector = RFECV(regressor, cv = cv, step = 1, #n_jobs=-1, \n",
    "                             scoring = score, verbose = 1)\n",
    "\n",
    "    # Fit RFECV\n",
    "    feature_selector.fit(X, np.ravel(y))\n",
    "    results[key] = feature_selector\n",
    "\n",
    "    # Get selected features\n",
    "    #feature_names = X_train_corr.columns\n",
    "    #selected_features = feature_names[feature_selector.support_].tolist()\n",
    "\n",
    "    print(f'terminated {key} {score}\\n')\n",
    "    print('terminated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c9fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 10 \n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "KPI_Feature = pd.DataFrame()\n",
    "KPI_Feature_CV = pd.DataFrame()\n",
    "results_feature_CV = pd.DataFrame()\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) *-1\n",
    "\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "\n",
    "scorings = [ make_scorer(nrmse, greater_is_better=False),\n",
    "            #make_scorer(mean_absolute_percentage_error,  greater_is_better=False),\n",
    "            make_scorer(r2_score, greater_is_better=True),\n",
    "            #make_scorer(explained_variance_score, greater_is_better=True),\n",
    "            #make_scorer(concordance_correlation_coefficient, greater_is_better=True),\n",
    "           ]\n",
    "scores_titles = ['$NRMSe$', '$R^2$']\n",
    "for feature in features_idw:  \n",
    "    print(feature)\n",
    "    \n",
    "    if feature in ['REG','GLIM']:\n",
    "        X_train_afr_feature = X[feature].cat.codes\n",
    "    else:\n",
    "        X_train_afr_feature = X[feature]\n",
    "    \n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "\n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"regressor\", regressor)]\n",
    "\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "    '''\n",
    "\n",
    "    for score_title,  scoring in zip(scores_titles, scorings):\n",
    "        score = cross_val_score(model_pipeline, X_train_afr_feature, y_train_afr, \n",
    "                                  cv=5)\n",
    "\n",
    "\n",
    "        KPI_Feature_CV.loc[score_title, f'RFE_{best_features}'] = score.mean()\n",
    "    '''\n",
    "    regressor.fit(X_train_afr_feature.values.reshape(-1, 1), y.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    y_predict = regressor.predict(X_train_afr_feature.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    KPI_Feature.loc['$NRMSe$', f'{feature}'] = nrmse(y, y_predict) *-1\n",
    "    #KPI_Feature.loc['MAPE', f'{feature}'] = mean_absolute_percentage_error(y, y_predict) \n",
    "    KPI_Feature.loc['$R^2$', f'{feature}'] = r2_score(y, y_predict)\n",
    "    #KPI_Feature.loc['EV', f'{feature}'] = explained_variance_score(y, y_predict)\n",
    "    #KPI_Feature.loc['CCC', f'{feature}'] = concordance_correlation_coefficient(y, y_predict)\n",
    "\n",
    "\n",
    "    for score_title,  scoring in zip(scores_titles, scorings):\n",
    "        score = cross_val_score(regressor, \n",
    "                                X_train_afr_feature.values.reshape(-1, 1), \n",
    "                                y.values.reshape(-1, 1),\n",
    "                                scoring=scoring,\n",
    "                                  cv=cv)\n",
    "\n",
    "\n",
    "        if score_title in ['MAPE']:\n",
    "            KPI_Feature_CV.loc[score_title, f'{feature}'] = score.mean() * -1\n",
    "        else:\n",
    "            KPI_Feature_CV.loc[score_title, f'{feature}'] = score.mean()\n",
    "\n",
    "            \n",
    "\n",
    "print('terminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e30a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "# Set figure size and create barplot\n",
    "#sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(1,2, figsize=(30, 10))\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "scoring = {\n",
    "    '$NRMSe$':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squaorange_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    '$R^2$':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'$p_c$': ccc_score,    \n",
    "}\n",
    "# Load hyper parameter \n",
    "sns.set(style='whitegrid',  font_scale = 3.5)\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X, y).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X[selected_features],y)\n",
    "\n",
    "obs.reset_index()\n",
    "obs_selected = obs.set_index('OBS_REF_IDW')\n",
    "\n",
    "selected_labels = obs_selected.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"Observables\"])\n",
    "feature_importance = feature_importance.set_index('Observables')\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "feature_importance['NRMSe']   = KPI_Feature_CV.T['$NRMSe$']\n",
    "feature_importance['$R^2$']   = KPI_Feature_CV.T['$R^2$']\n",
    "\n",
    "\n",
    "selected_labels = feature_importance.index.to_list()\n",
    "feature_importance['$R^2$ RV'] = 0\n",
    "feature_importance.loc[selected_labels[12:14], '$R^2$ RV'] = feature_importance.loc[selected_labels[12:14],'$R^2$']\n",
    "feature_importance['NRMSe RV'] = 0\n",
    "feature_importance.loc[selected_labels[12:14], 'NRMSe RV'] = feature_importance.loc[selected_labels[12:14],'NRMSe']\n",
    "\n",
    "feature_importance['$R^2$ REG'] = 0\n",
    "feature_importance.loc[selected_labels[15], '$R^2$ REG'] = feature_importance.loc[selected_labels[15],'$R^2$']\n",
    "feature_importance['NRMSe REG'] = 0\n",
    "feature_importance.loc[selected_labels[15], 'NRMSe REG'] = feature_importance.loc[selected_labels[15],'NRMSe']\n",
    "\n",
    "feature_importance['Relative Importance REG'] = 0\n",
    "feature_importance.loc[selected_labels[15], 'Relative Importance REG'] = feature_importance.loc[selected_labels[15],'Relative Importance']\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "sns.barplot(x = feature_importance['$R^2$'].values, \n",
    "            y = feature_importance['$R^2$'].index, \n",
    "            ax=ax[0], color='lightblue',\n",
    "            )\n",
    "\n",
    "sns.barplot(x = feature_importance['NRMSe'].values, \n",
    "            y = feature_importance['NRMSe'].index, \n",
    "            ax=ax[0], color='orange',\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "sns.barplot(x = feature_importance['NRMSe RV'].values, \n",
    "            y = feature_importance['NRMSe RV'].index, \n",
    "            ax=ax[0], color='orange', label='$NRMSe$',\n",
    "            )\n",
    "\n",
    "sns.barplot(x = feature_importance['$R^2$ RV'].values, \n",
    "            y = feature_importance['$R^2$ RV'].index, \n",
    "            ax=ax[0], color='lightblue', label='$R^2$',\n",
    "            )\n",
    "\n",
    "sns.barplot(x = feature_importance[\"Relative Importance\"].values, \n",
    "            y = feature_importance[\"Relative Importance\"].index, \n",
    "            ax=ax[0],  color='lightgreen',label=f'''Relative\n",
    "importance'''\n",
    "                    )\n",
    "\n",
    "####\n",
    "\n",
    "sns.barplot(x = feature_importance['NRMSe REG'].values, \n",
    "            y = feature_importance['NRMSe REG'].index, \n",
    "            ax=ax[0], color='orange',\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "sns.barplot(x = feature_importance[\"Relative Importance REG\"].values, \n",
    "            y = feature_importance[\"Relative Importance REG\"].index, \n",
    "            ax=ax[0],  color='lightgreen',\n",
    "                    )\n",
    "\n",
    "sns.barplot(x = feature_importance['$R^2$ REG'].values, \n",
    "            y = feature_importance['$R^2$ REG'].index, \n",
    "            ax=ax[0], color='lightblue',\n",
    "            )\n",
    "\n",
    "\n",
    "ax[0].set_ylabel('')\n",
    "ax[0].grid(False)\n",
    "\n",
    "# Turn frame off\n",
    "ax[0].set_frame_on(False)\n",
    "ax[0].locator_params(axis='x', nbins=7)\n",
    "ax[0].legend(loc=[.55, .6], framealpha=0.5)\n",
    "\n",
    "ax[0].set_title(f'{sub_figs[0]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "ax[0].set_xlabel(\"Score\")\n",
    "\n",
    "for key, score in scoring.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "    if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "        ax[1].plot(range(1, len(results[key].grid_scores_) + 1),                  \n",
    "                   results[key].grid_scores_.mean(axis=1)*-1, label=key)\n",
    "        ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "                    results[key].grid_scores_.mean(axis=1)*-1, marker='x')\n",
    "\n",
    "    else:\n",
    "        ax[1].plot(range(1, len(results[key].grid_scores_) + 1), \n",
    "                 results[key].grid_scores_.mean(axis=1), label=key)\n",
    "        ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "                    results[key].grid_scores_.mean(axis=1), marker='x')\n",
    "        \n",
    "ax[1].plot(range(1, len(results[key].grid_scores_) + 1), \n",
    "         feature_importance['Relative Importance'].cumsum().values, label=f'''Cumulative\n",
    "importance''',  color='lightgreen')\n",
    "ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "            feature_importance['Relative Importance'].cumsum().values,  color='lightgreen',marker='x')\n",
    "\n",
    "ax[1].set_xlabel(\"Number of geo-observables\")\n",
    "ax[1].set_xticks([ 1,3,5,7,9,11,13,15])\n",
    "ax[1].set_ylabel(\"Score\")\n",
    "ax[1].legend(loc=[.56, .21])\n",
    "#plt.axvline(results[key].n_features_ ,color='r')\n",
    "ax[1].set_title(f'{sub_figs[1]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "\n",
    "ax[1].grid(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "fig.savefig(dir_p/ 'fig'/\"fig_8.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd2ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "# Set figure size and create barplot\n",
    "#sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(1,2, figsize=(18, 8))\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "scoring = {\n",
    "    '$NRMSe$':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    '$R^2$':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'$p_c$': ccc_score,    \n",
    "}\n",
    "# Load hyper parameter \n",
    "sns.set(style='whitegrid',  font_scale = 2.2)\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X, y).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X[selected_features],y)\n",
    "\n",
    "obs.reset_index()\n",
    "obs_selected = obs.set_index('OBS_REF_IDW')\n",
    "\n",
    "selected_labels = obs_selected.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"Observables\"])\n",
    "feature_importance = feature_importance.set_index('Observables')\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "\n",
    "sns.barplot(x = feature_importance[\"Relative Importance\"].values, \n",
    "            y = feature_importance[\"Relative Importance\"].index, ax=ax[0],\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 16)),  data = feature_importance)\n",
    "\n",
    "\n",
    "ax[0].set_ylabel('')\n",
    "\n",
    "\n",
    "# Turn frame off\n",
    "ax[0].set_frame_on(False)\n",
    "ax[0].locator_params(axis='x', nbins=7)\n",
    "\n",
    "\n",
    "ax[0].set_title(f'{sub_figs[0]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "    if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "        ax[1].plot(range(1, len(results[key].grid_scores_) + 1),                  results[key].grid_scores_.mean(axis=1)*-1, label=key)\n",
    "        ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "                    results[key].grid_scores_.mean(axis=1)*-1, marker='x')\n",
    "\n",
    "    else:\n",
    "        ax[1].plot(range(1, len(results[key].grid_scores_) + 1), \n",
    "                 results[key].grid_scores_.mean(axis=1), label=key)\n",
    "        ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "                    results[key].grid_scores_.mean(axis=1), marker='x')\n",
    "        \n",
    "ax[1].plot(range(1, len(results[key].grid_scores_) + 1), \n",
    "         feature_importance['Relative Importance'].cumsum().values, label=f'''Cumulative\n",
    "importance''')\n",
    "ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "            feature_importance['Relative Importance'].cumsum().values, marker='x')\n",
    "\n",
    "ax[1].set_xlabel(\"Number of geo-observables\")\n",
    "ax[1].set_xticks([ 1,3,5,7,9,11,13,15])\n",
    "ax[1].set_ylabel(\"Score\")\n",
    "ax[1].legend(loc=[.56, .21])\n",
    "#plt.axvline(results[key].n_features_ ,color='r')\n",
    "ax[1].set_title(f'{sub_figs[1]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "\n",
    "\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "fig.savefig(dir_p/ 'fig'/\"fig_5.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8256a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "# Set figure size and create barplot\n",
    "#sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(1,2, figsize=(18, 8))\n",
    "\n",
    "best_features = 12\n",
    "\n",
    "scoring = {\n",
    "    '$NRMSe$':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    '$R^2$':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'$p_c$': ccc_score,    \n",
    "}\n",
    "# Load hyper parameter \n",
    "sns.set(style='whitegrid',  font_scale = 2.2)\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X, y).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X[selected_features],y)\n",
    "\n",
    "obs.reset_index()\n",
    "obs_selected = obs.set_index('OBS_REF_IDW')\n",
    "\n",
    "selected_labels = obs_selected.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"Covaraite\"])\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "\n",
    "sns.barplot(x = \"Relative Importance\", y = \"Covaraite\", ax=ax[0],\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 16)),  data = feature_importance)\n",
    "\n",
    "\n",
    "ax[0].set_ylabel('')\n",
    "\n",
    "\n",
    "# Turn frame off\n",
    "ax[0].set_frame_on(False)\n",
    "ax[0].locator_params(axis='x', nbins=7)\n",
    "\n",
    "\n",
    "ax[0].set_title(f'{sub_figs[0]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "    if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "        ax[1].plot(range(1, best_features + 1),  results[key].grid_scores_.mean(axis=1)[:best_features]*-1, label=key)\n",
    "        ax[1].scatter(range(1, best_features + 1), \n",
    "                    results[key].grid_scores_.mean(axis=1)[:best_features]*-1, marker='x')\n",
    "\n",
    "    else:\n",
    "        ax[1].plot(range(1, best_features + 1), \n",
    "                 results[key].grid_scores_.mean(axis=1)[:best_features], label=key)\n",
    "        ax[1].scatter(range(1, best_features + 1), \n",
    "                    results[key].grid_scores_.mean(axis=1)[:best_features], marker='x')\n",
    "        \n",
    "ax[1].plot(range(1, best_features + 1), \n",
    "         feature_importance['Relative Importance'].cumsum()[:best_features].values, label=f'''Cumulative\n",
    "importance''')\n",
    "ax[1].scatter(range(1, best_features + 1), \n",
    "            feature_importance['Relative Importance'].cumsum()[:best_features].values, marker='x')\n",
    "\n",
    "ax[1].set_xlabel(\"Number of geo-observables\")\n",
    "ax[1].set_xticks([ 1,3,5,7,9,11,13,15])\n",
    "ax[1].set_ylabel(\"Score\")\n",
    "ax[1].legend(loc=[.56, .21])\n",
    "#plt.axvline(results[key].n_features_ ,color='r')\n",
    "ax[1].set_title(f'{sub_figs[1]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "#fig.savefig(\"fig_5.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a118fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "label = 'AFR' \n",
    "\n",
    "\n",
    "x_Afr = copy.deepcopy(training_Afr_rab[coord])\n",
    "\n",
    "y_Afr = training_Afr_rab[target]\n",
    "p_Afr = training_Afr_rab[features_idw]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####visulaize\n",
    "\n",
    "regressor_rk = RandomForestRegressor()\n",
    "\n",
    "best_params = {'bootstrap': False,\n",
    " 'ccp_alpha': 0.0,\n",
    " 'criterion': 'squared_error',\n",
    " 'max_depth': 2,\n",
    " 'max_features': 'log2',\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_samples': None,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'min_samples_leaf': 3,\n",
    " 'min_samples_split': 6,\n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " 'n_estimators': 450,\n",
    " 'n_jobs': None,\n",
    " 'oob_score': False,\n",
    " 'random_state': None,\n",
    " 'verbose': 0,\n",
    " 'warm_start': False}\n",
    "\n",
    "\n",
    "regressor_rk.set_params(**best_params)\n",
    "\n",
    "\n",
    "regressor_rk.fit(p_Afr,y_Afr)\n",
    "\n",
    "regressor_rk.get_params()\n",
    "\n",
    "rf = regressor_rk\n",
    "\n",
    "fn= ['CTD',\n",
    " 'SI',\n",
    " 'LAB',\n",
    " 'MOHO',\n",
    " 'SV',\n",
    " 'PV',\n",
    " 'GEOID',\n",
    " 'FA',\n",
    " 'DEM',\n",
    " 'BG',\n",
    " 'EMAG2',\n",
    " 'RHO_L',\n",
    " 'RHO_C',\n",
    " 'VOLC_D',\n",
    " 'REG',\n",
    " 'GLIM']\n",
    "\n",
    "cn=target\n",
    "fig, axes = plt.subplots(figsize = (20,20) )\n",
    "\n",
    "\n",
    "tree.plot_tree(rf.estimators_[100],\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               fontsize=21,\n",
    "               filled = True);\n",
    "\n",
    "\n",
    "fig.savefig(dir_p/ 'fig'/'presentation'/\"fig_3.JPEG\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85330e39",
   "metadata": {},
   "source": [
    "# Visualiazation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed9ce22",
   "metadata": {},
   "source": [
    "# AFR 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa41ecaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "region ='Afr_50'\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "\n",
    "# Set figure size and create \n",
    "# ra with training ra\n",
    "\n",
    "\n",
    "KPI_RK_ra = pd.DataFrame()\n",
    "threshold = 15\n",
    "\n",
    "\n",
    "\n",
    "files_ra = [filename \\\n",
    "         for filename in os.listdir(dir_p/'Grids'/'outputs'/'AFR_50') \n",
    "         if 'rab' not  in filename and 'RK' in filename ]\n",
    "\n",
    "labels_RK_ra_lr = [filename.replace('.nc', '') for filename in files_ra ]\n",
    "\n",
    "labels_RK_ra_lr = [ label_ra.replace('_9', '_09')  if '_9' in label_ra \n",
    "             else label_ra for label_ra in labels_RK_ra_lr ]\n",
    "\n",
    "labels_RK_ra_lr = [ label_ra.replace('_8', '_08')  if '_8' in label_ra \n",
    "             else label_ra for label_ra in labels_RK_ra_lr ]\n",
    "\n",
    "labels_RK_ra_lr = [ label_ra.replace('_7', '_07')  if '_7' in label_ra \n",
    "             else label_ra for label_ra in labels_RK_ra_lr ]\n",
    "\n",
    "labels_RK_ra_lr = [ label_ra.replace('_6', '_06')  if '_6' in label_ra \n",
    "             else label_ra for label_ra in labels_RK_ra_lr ]\n",
    "\n",
    "labels_RK_ra_lr = [ label_ra.replace('_5', '_05')  if '_5' in label_ra \n",
    "             else label_ra for label_ra in labels_RK_ra_lr ]\n",
    "\n",
    "labels_RK_ra_lr = [ label_ra.replace('_4', '_04')  if '_4' in label_ra \n",
    "             else label_ra for label_ra in labels_RK_ra_lr ]\n",
    "\n",
    "for label, file in zip(labels_RK_ra_lr , files_ra):\n",
    "    path_grd_RK_ra_lr = dir_p/'Grids'/'outputs'/'AFR_50'/f'RK_{file[3:]}'\n",
    "\n",
    "\n",
    "    grids[region].ds[f'RK_{label[-5:]}'] = (('Y', 'X'), grids[region].read_raster(\n",
    "        path_grd_RK_ra_lr , src_crs=src_crs))\n",
    "   \n",
    "    prediction_df = pd.DataFrame()\n",
    "\n",
    "    prediction_df['y'] = training_Afr_50_ra[target]\n",
    "    prediction_df['y_hat'] = grids[region].ds[f'RK_{label[-5:]}'].values.ravel()[training_Afr_50_ra['grid_index']]\n",
    "\n",
    "    prediction_df.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "    bias        = round(prediction_df['y_hat'].mean() -  prediction_df['y'].mean(), 2)\n",
    "    errors      = abs( prediction_df['y'] - prediction_df['y_hat'])\n",
    "    mape        = round( mean_absolute_percentage_error( prediction_df['y'], prediction_df['y_hat']), 2) \n",
    "    accuracy    = round(1 - mape , 2)\n",
    "    mae         = round(mean_absolute_error( prediction_df['y'], prediction_df['y_hat'] ), 2)\n",
    "    rmse        = round(mean_squared_error( prediction_df['y'], prediction_df['y_hat'] , squared=False), 2)\n",
    "    nrmse       = round( rmse/( prediction_df['y'].mean()) , 2) \n",
    "    r2          = round(r2_score( prediction_df['y'], prediction_df['y_hat'] ), 2)\n",
    "    ev          = round( explained_variance_score( prediction_df['y'], prediction_df['y_hat']), 2)\n",
    "    max_e       = round( max_error( prediction_df['y'], prediction_df['y_hat']), 0)\n",
    "    min_e       = round( errors.min(), 2)\n",
    "    mnae        = round( median_absolute_error( prediction_df['y'], prediction_df['y_hat']), 2) \n",
    "    mpe         =  -1 * round(np.mean(( prediction_df['y'] -prediction_df['y_hat'])/ prediction_df['y']) , 2)\n",
    "    ccc         = round(concordance_correlation_coefficient( prediction_df['y'], prediction_df['y_hat']),2)\n",
    "\n",
    "    KPI_RK_ra.loc['NRMSe', f'{label[-5:-3]}'] = nrmse\n",
    "    KPI_RK_ra.loc['RMSE', f'{label[-5:-3]}'] = rmse\n",
    "    KPI_RK_ra.loc['MAE', f'{label[-5:-3]}'] = mae\n",
    "    KPI_RK_ra.loc['MAPE', f'{label[-5:-3]}'] = mape\n",
    "    KPI_RK_ra.loc['$R^2$', f'{label[-5:-3]}'] = r2\n",
    "    KPI_RK_ra.loc['EV', f'{label[-5:-3]}'] = ev\n",
    "    KPI_RK_ra.loc['Max_e', f'{label[-5:-3]}'] = max_e\n",
    "    KPI_RK_ra.loc['MIN_E', f'{label[-5:-3]}'] = min_e\n",
    "    KPI_RK_ra.loc['MedAE', f'{label[-5:-3]}'] = mnae\n",
    "    KPI_RK_ra.loc['Mean', f'{label[-5:-3]}'] = round(prediction_df['y_hat'].mean(),0)\n",
    "    KPI_RK_ra.loc['MPe', f'{label[-5:-3]}'] = mpe\n",
    "    KPI_RK_ra.loc['ACC', f'{label[-5:-3]}'] = accuracy\n",
    "    KPI_RK_ra.loc['Max', f'{label[-5:-3]}'] = round(prediction_df['y_hat'].max(), 0) \n",
    "    KPI_RK_ra.loc['MIN', f'{label[-5:-3]}'] = round(prediction_df['y_hat'].min(), 0)   \n",
    "    KPI_RK_ra.loc['RSD', f'{label[-5:-3]}'] = round(np.std(prediction_df['y_hat']) / np.mean(prediction_df['y_hat']) ,2)\n",
    "    KPI_RK_ra.loc['$p_c$', f'{label[-5:-3]}'] =  ccc\n",
    "    KPI_RK_ra.loc['BIAS', f'{label[-5:-3]}'] =  bias\n",
    "\n",
    "\n",
    "###RF\n",
    "\n",
    "\n",
    "\n",
    "KPI_RF_ra = pd.DataFrame()\n",
    "\n",
    "files_ra = [filename \\\n",
    "         for filename in os.listdir(dir_p/'Grids'/'outputs'/'AFR_50') \n",
    "         if 'rab' not in filename and 'RF' in filename ]\n",
    "\n",
    "\n",
    "labels_RF_ra_lr = [filename.replace('.nc', '') for filename in files_ra]\n",
    "\n",
    "\n",
    "labels_RF_ra_lr = [ label_ra.replace('_9', '_09')  if '_9' in label_ra \n",
    "             else label_ra for label_ra in labels_RF_ra_lr ]\n",
    "\n",
    "labels_RF_ra_lr = [ label_ra.replace('_8', '_08')  if '_8' in label_ra \n",
    "             else label_ra for label_ra in labels_RF_ra_lr ]\n",
    "\n",
    "labels_RF_ra_lr = [ label_ra.replace('_7', '_07')  if '_7' in label_ra \n",
    "             else label_ra for label_ra in labels_RF_ra_lr ]\n",
    "\n",
    "labels_RF_ra_lr = [ label_ra.replace('_6', '_06')  if '_6' in label_ra \n",
    "             else label_ra for label_ra in labels_RF_ra_lr ]\n",
    "\n",
    "labels_RF_ra_lr = [ label_ra.replace('_5', '_05')  if '_5' in label_ra \n",
    "             else label_ra for label_ra in labels_RF_ra_lr ]\n",
    "\n",
    "labels_RF_ra_lr = [ label_ra.replace('_4', '_04')  if '_4' in label_ra \n",
    "             else label_ra for label_ra in labels_RF_ra_lr ]\n",
    "\n",
    "# 8 or 14\n",
    "\n",
    "for label, file in zip(labels_RF_ra_lr, files_ra):\n",
    "    path_grd_RF_ra_lr = dir_p/'Grids'/'outputs'/'AFR_50'/f'RF_{file[3:]}'\n",
    "\n",
    "\n",
    "    grids[region].ds[f'RF_{label[-5:]}']  = (('Y', 'X'), grids[region].read_raster(\n",
    "        path_grd_RF_ra_lr ,  src_crs=src_crs))\n",
    "   \n",
    "\n",
    "    prediction_df = pd.DataFrame()\n",
    "\n",
    "    prediction_df['y'] = training_Afr_50_ra[target]\n",
    "    prediction_df['y_hat'] = grids[region].ds[f'RF_{label[-5:]}'].values.ravel()[training_Afr_50_ra['grid_index']]\n",
    "\n",
    "    prediction_df.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    bias        = round(prediction_df['y_hat'].mean() -  prediction_df['y'].mean(), 2)\n",
    "    errors      = abs( prediction_df['y'] - prediction_df['y_hat'])\n",
    "    mape        = round( mean_absolute_percentage_error( prediction_df['y'], prediction_df['y_hat']), 2) \n",
    "    accuracy    = round(1 - mape , 2)\n",
    "    mae         = round(mean_absolute_error( prediction_df['y'], prediction_df['y_hat'] ), 2)\n",
    "    rmse        = round(mean_squared_error( prediction_df['y'], prediction_df['y_hat'] , squared=False), 2)\n",
    "    nrmse       = round( rmse/( prediction_df['y'].mean()) , 2) \n",
    "    r2          = round(r2_score( prediction_df['y'], prediction_df['y_hat'] ), 2)\n",
    "    ev          = round( explained_variance_score( prediction_df['y'], prediction_df['y_hat']), 2)\n",
    "    max_e       = round( max_error( prediction_df['y'], prediction_df['y_hat']), 0)\n",
    "    min_e       = round( errors.min(), 2)\n",
    "    mnae        = round( median_absolute_error( prediction_df['y'], prediction_df['y_hat']), 2) \n",
    "    mpe         =  -1 * round(np.mean(( prediction_df['y'] -prediction_df['y_hat'])/ prediction_df['y']) , 2)    \n",
    "    ccc         = round(concordance_correlation_coefficient( prediction_df['y'], prediction_df['y_hat']),2)\n",
    "\n",
    "    KPI_RF_ra.loc['NRMSe', f'{label[-5:-3]}'] = nrmse\n",
    "    KPI_RF_ra.loc['RMSE', f'{label[-5:-3]}'] = rmse\n",
    "    KPI_RF_ra.loc['MAE', f'{label[-5:-3]}'] = mae\n",
    "    KPI_RF_ra.loc['MAPE', f'{label[-5:-3]}'] = mape\n",
    "    KPI_RF_ra.loc['$R^2$', f'{label[-5:-3]}'] = r2\n",
    "    KPI_RF_ra.loc['EV', f'{label[-5:-3]}'] = ev\n",
    "    KPI_RF_ra.loc['Max_e', f'{label[-5:-3]}'] = max_e\n",
    "    KPI_RF_ra.loc['MIN_E', f'{label[-5:-3]}'] = min_e\n",
    "    KPI_RF_ra.loc['MedAE', f'{label[-5:-3]}'] = mnae\n",
    "    KPI_RF_ra.loc['Mean', f'{label[-5:-3]}'] = round(prediction_df['y_hat'].mean(),0)\n",
    "    KPI_RF_ra.loc['MPe', f'{label[-5:-3]}'] = mpe\n",
    "    KPI_RF_ra.loc['ACC', f'{label[-5:-3]}'] = accuracy\n",
    "    KPI_RF_ra.loc['Max', f'{label[-5:-3]}'] = round(prediction_df['y_hat'].max(), 0) \n",
    "    KPI_RF_ra.loc['MIN', f'{label[-5:-3]}'] = round(prediction_df['y_hat'].min(), 0)   \n",
    "    KPI_RF_ra.loc['RSD', f'{label[-5:-3]}'] = round(np.std(prediction_df['y_hat']) / np.mean(prediction_df['y_hat']) ,2)\n",
    "    KPI_RF_ra.loc['$p_c$', f'{label[-5:-3]}'] =  ccc\n",
    "    KPI_RF_ra.loc['BIAS', f'{label[-5:-3]}'] =  bias\n",
    "\n",
    "##'MedAE',   'BIAS', 'ACC', 'EV', 'RSD', 'Mean',  'MAX', 'MIN', \n",
    "scores = ['NRMSe', '$R^2$', 'Max_e', 'Max'\n",
    "           ]\n",
    "\n",
    "\n",
    "n_labels = 30\n",
    "#subfile = 'HOD'\n",
    "#files_ra = [ x for x in files_ra if subfile in x ]\n",
    "\n",
    "fontsize = 40\n",
    "i = 0\n",
    "fig, axs = plt.subplots(2,2,figsize=(15, 30))\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1)\n",
    "#fig.set_size_inches(30,30)\n",
    "for score, axi in zip(scores, axs.flatten()):\n",
    "\n",
    "\n",
    "    # Set graph style\n",
    "    \n",
    "    axi.set(facecolor = \"white\")\n",
    "    \n",
    "    #cols  = KPI_RK_ra.loc[score,:].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "\n",
    "    if score in ['$R^2$','EV' ,'Max', 'ACC','$p_c$','RSD']:\n",
    "        \n",
    "\n",
    "               \n",
    "        x_data_KED = KPI_RK_ra.loc[score,:].sort_values(ascending=False).index\n",
    "        y_data_KED = KPI_RK_ra.loc[score,:].sort_values(ascending=False)\n",
    "        \n",
    "        \n",
    "        #x_data_RFR = KPI_RF_ra.loc[score,:].sort_values(ascending=False).index\n",
    "        y_data_RFR = KPI_RF_ra.loc[score,x_data_KED]\n",
    "        \n",
    "        KPI = pd.DataFrame({'$\\hat{y}_{KED}$': y_data_KED,\n",
    "                   '$\\hat{y}_{RF}$': y_data_RFR}, index=x_data_KED).sort_values(\n",
    "            ascending=True, by=['$\\hat{y}_{KED}$'])\n",
    "        \n",
    "        ax = KPI.plot.barh(rot=0, width=0.9, ax=axi, fontsize=fontsize)\n",
    "        axi.set_title(score, fontsize=fontsize)\n",
    "        ax.legend(loc='lower left', fontsize=fontsize)\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fontsize=fontsize)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        x_data_KED = KPI_RK_ra.loc[score,:].sort_values().index\n",
    "        y_data_KED = KPI_RK_ra.loc[score,:].sort_values()\n",
    "        #bar = sns.barplot(y_data[:], x_data[:] , color='darkgreen',      ax=ax)\n",
    "        #x_data_RFR = KPI_RF_ra.loc[score,:].sort_values().index\n",
    "        y_data_RFR = KPI_RF_ra.loc[score,x_data_KED]\n",
    "        \n",
    "        KPI = pd.DataFrame({'$\\hat{y}_{KED}$': y_data_KED,\n",
    "                   '$\\hat{y}_{RF}$': y_data_RFR}, index=x_data_KED).sort_values(\n",
    "            ascending=False, by=['$\\hat{y}_{KED}$'])        \n",
    "        ax = KPI.plot.barh(rot=0, width=0.9, ax=axi, fontsize=fontsize)\n",
    "        axi.set_title(score, fontsize=fontsize)\n",
    "        ax.legend(loc='lower left', fontsize=fontsize)\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fontsize=fontsize)\n",
    "            \n",
    "    \n",
    "    if (i%3) ==0:\n",
    "        ax.set_ylabel('Number of geo-observables',  fontsize=fontsize)\n",
    "    else:\n",
    "        ax.set_ylabel('')\n",
    "        #g0.get_yaxis().set_visible(False)\n",
    "        #g0.ax_joint.get_yaxis().set_visible(False) \n",
    "\n",
    "    ax.locator_params(axis='x', nbins=6)  # set divisor \n",
    "    #ax.set(yticklabels=[])  \n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0, bottom=1, right=2, top=2, wspace=0.3, hspace=0.1)\n",
    "    i+=1\n",
    "fig.savefig(dir_p/'fig'/\"fig_s5.jpeg\", bbox_inches='tight', dpi=300 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded224c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "region ='Afr_50'\n",
    "\n",
    "# Initialize auc_score dictionary\n",
    "\n",
    "# Set figure size and create \n",
    "# rb with training rb\n",
    "\n",
    "\n",
    "KPI_RK_rab = pd.DataFrame()\n",
    "threshold = 15\n",
    "\n",
    "\n",
    "\n",
    "files_rab = [filename \\\n",
    "         for filename in os.listdir(dir_p/'Grids'/'outputs'/'AFR_50') \n",
    "         if 'rab' in filename and 'RK' in filename ]\n",
    "\n",
    "labels_RK_rab_lr = [filename.replace('.nc', '') for filename in files_rab ]\n",
    "\n",
    "labels_RK_rab_lr = [ label_rab.replace('_9', '_09')  if '_9' in label_rab \n",
    "             else label_rab for label_rab in labels_RK_rab_lr ]\n",
    "\n",
    "labels_RK_rab_lr = [ label_rab.replace('_8', '_08')  if '_8' in label_rab \n",
    "             else label_rab for label_rab in labels_RK_rab_lr ]\n",
    "\n",
    "labels_RK_rab_lr = [ label_rab.replace('_7', '_07')  if '_7' in label_rab \n",
    "             else label_rab for label_rab in labels_RK_rab_lr ]\n",
    "\n",
    "labels_RK_rab_lr = [ label_rab.replace('_6', '_06')  if '_6' in label_rab \n",
    "             else label_rab for label_rab in labels_RK_rab_lr ]\n",
    "\n",
    "labels_RK_rab_lr = [ label_rab.replace('_5', '_05')  if '_5' in label_rab \n",
    "             else label_rab for label_rab in labels_RK_rab_lr ]\n",
    "\n",
    "labels_RK_rab_lr = [ label_rab.replace('_4', '_04')  if '_4' in label_rab \n",
    "             else label_rab for label_rab in labels_RK_rab_lr ]\n",
    "\n",
    "for label, file in zip(labels_RK_rab_lr , files_rab):\n",
    "    path_grd_RK_rab_lr = dir_p/'Grids'/'outputs'/'AFR_50'/f'RK_{file[3:]}'\n",
    "\n",
    "\n",
    "    grids[region].ds[f'RK_{label[-6:]}'] = (('Y', 'X'), grids[region].read_raster(\n",
    "        path_grd_RK_rab_lr , src_crs=src_crs))\n",
    "   \n",
    "    prediction_df = pd.DataFrame()\n",
    "\n",
    "    prediction_df['y'] = training_Afr_50_rab[target]\n",
    "    prediction_df['y_hat'] = grids[region].ds[f'RK_{label[-6:]}'].values.ravel()[training_Afr_50_rab['grid_index']]\n",
    "\n",
    "    prediction_df.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "    bias        = round(prediction_df['y_hat'].mean() -  prediction_df['y'].mean(), 2)\n",
    "    errors      = abs( prediction_df['y'] - prediction_df['y_hat'])\n",
    "    mape        = round( mean_absolute_percentage_error( prediction_df['y'], prediction_df['y_hat']), 2) \n",
    "    accuracy    = round(1 - mape , 2)\n",
    "    mae         = round(mean_absolute_error( prediction_df['y'], prediction_df['y_hat'] ), 2)\n",
    "    rmse        = round(mean_squared_error( prediction_df['y'], prediction_df['y_hat'] , squared=False), 2)\n",
    "    nrmse       = round( rmse/( prediction_df['y'].mean()) , 2) \n",
    "    r2          = round(r2_score( prediction_df['y'], prediction_df['y_hat'] ), 2)\n",
    "    ev          = round( explained_variance_score( prediction_df['y'], prediction_df['y_hat']), 2)\n",
    "    max_e       = round( max_error( prediction_df['y'], prediction_df['y_hat']), 0)\n",
    "    min_e       = round( errors.min(), 2)\n",
    "    mnae        = round( median_absolute_error( prediction_df['y'], prediction_df['y_hat']), 2) \n",
    "    mpe         =  -1 * round(np.mean(( prediction_df['y'] -prediction_df['y_hat'])/ prediction_df['y']) , 2)\n",
    "    ccc         = round(concordance_correlation_coefficient( prediction_df['y'], prediction_df['y_hat']),2)\n",
    "\n",
    "    KPI_RK_rab.loc['NRMSe', f'{label[-6:-4]}'] = nrmse\n",
    "    KPI_RK_rab.loc['RMSE', f'{label[-6:-4]}'] = rmse\n",
    "    KPI_RK_rab.loc['MAE', f'{label[-6:-4]}'] = mae\n",
    "    KPI_RK_rab.loc['MAPE', f'{label[-6:-4]}'] = mape\n",
    "    KPI_RK_rab.loc['$R^2$', f'{label[-6:-4]}'] = r2\n",
    "    KPI_RK_rab.loc['EV', f'{label[-6:-4]}'] = ev\n",
    "    KPI_RK_rab.loc['Max_e', f'{label[-6:-4]}'] = max_e\n",
    "    KPI_RK_rab.loc['MIN_E', f'{label[-6:-4]}'] = min_e\n",
    "    KPI_RK_rab.loc['MedAE', f'{label[-6:-4]}'] = mnae\n",
    "    KPI_RK_rab.loc['Mean', f'{label[-6:-4]}'] = round(prediction_df['y_hat'].mean(),0)\n",
    "    KPI_RK_rab.loc['MPe', f'{label[-6:-4]}'] = mpe\n",
    "    KPI_RK_rab.loc['ACC', f'{label[-6:-4]}'] = accuracy\n",
    "    KPI_RK_rab.loc['Max', f'{label[-6:-4]}'] = round(prediction_df['y_hat'].max(), 0) \n",
    "    KPI_RK_rab.loc['MIN', f'{label[-6:-4]}'] = round(prediction_df['y_hat'].min(), 0)   \n",
    "    KPI_RK_rab.loc['RSD', f'{label[-6:-4]}'] = round(np.std(prediction_df['y_hat']) / np.mean(prediction_df['y_hat']) ,2)\n",
    "    KPI_RK_rab.loc['$p_c$', f'{label[-6:-4]}'] =  ccc\n",
    "    KPI_RK_rab.loc['BIAS', f'{label[-6:-4]}'] =  bias\n",
    "\n",
    "\n",
    "###RF\n",
    "\n",
    "\n",
    "\n",
    "KPI_RF_rab = pd.DataFrame()\n",
    "\n",
    "files_rab = [filename \\\n",
    "         for filename in os.listdir(dir_p/'Grids'/'outputs'/'AFR_50') \n",
    "         if 'rab' in filename and 'RF' in filename ]\n",
    "\n",
    "\n",
    "labels_RF_rab_lr = [filename.replace('.nc', '') for filename in files_rab]\n",
    "\n",
    "\n",
    "labels_RF_rab_lr = [ label_rab.replace('_9', '_09')  if '_9' in label_rab \n",
    "             else label_rab for label_rab in labels_RF_rab_lr ]\n",
    "\n",
    "labels_RF_rab_lr = [ label_rab.replace('_8', '_08')  if '_8' in label_rab \n",
    "             else label_rab for label_rab in labels_RF_rab_lr ]\n",
    "\n",
    "labels_RF_rab_lr = [ label_rab.replace('_7', '_07')  if '_7' in label_rab \n",
    "             else label_rab for label_rab in labels_RF_rab_lr ]\n",
    "\n",
    "labels_RF_rab_lr = [ label_rab.replace('_6', '_06')  if '_6' in label_rab \n",
    "             else label_rab for label_rab in labels_RF_rab_lr ]\n",
    "\n",
    "labels_RF_rab_lr = [ label_rab.replace('_5', '_05')  if '_5' in label_rab \n",
    "             else label_rab for label_rab in labels_RF_rab_lr ]\n",
    "\n",
    "labels_RF_rab_lr = [ label_rab.replace('_4', '_04')  if '_4' in label_rab \n",
    "             else label_rab for label_rab in labels_RF_rab_lr ]\n",
    "\n",
    "# 8 or 14\n",
    "\n",
    "for label, file in zip(labels_RF_rab_lr, files_rab):\n",
    "    path_grd_RF_rab_lr = dir_p/'Grids'/'outputs'/'AFR_50'/f'RF_{file[3:]}'\n",
    "\n",
    "\n",
    "    grids[region].ds[f'RF_{label[-6:]}']  = (('Y', 'X'), grids[region].read_raster(\n",
    "        path_grd_RF_rab_lr ,  src_crs=src_crs))\n",
    "   \n",
    "\n",
    "    prediction_df = pd.DataFrame()\n",
    "\n",
    "    prediction_df['y'] = training_Afr_50_rab[target]\n",
    "    prediction_df['y_hat'] = grids[region].ds[f'RF_{label[-6:]}'].values.ravel()[training_Afr_50_rab['grid_index']]\n",
    "\n",
    "    prediction_df.dropna(inplace=True)\n",
    "\n",
    "    \n",
    "\n",
    "    bias        = round(prediction_df['y_hat'].mean() -  prediction_df['y'].mean(), 2)\n",
    "    errors      = abs( prediction_df['y'] - prediction_df['y_hat'])\n",
    "    mape        = round( mean_absolute_percentage_error( prediction_df['y'], prediction_df['y_hat']), 2) \n",
    "    accuracy    = round(1 - mape , 2)\n",
    "    mae         = round(mean_absolute_error( prediction_df['y'], prediction_df['y_hat'] ), 2)\n",
    "    rmse        = round(mean_squared_error( prediction_df['y'], prediction_df['y_hat'] , squared=False), 2)\n",
    "    nrmse       = round( rmse/( prediction_df['y'].mean()) , 2) \n",
    "    r2          = round(r2_score( prediction_df['y'], prediction_df['y_hat'] ), 2)\n",
    "    ev          = round( explained_variance_score( prediction_df['y'], prediction_df['y_hat']), 2)\n",
    "    max_e       = round( max_error( prediction_df['y'], prediction_df['y_hat']), 0)\n",
    "    min_e       = round( errors.min(), 2)\n",
    "    mnae        = round( median_absolute_error( prediction_df['y'], prediction_df['y_hat']), 2) \n",
    "    mpe         =  -1 * round(np.mean(( prediction_df['y'] -prediction_df['y_hat'])/ prediction_df['y']) , 2)    \n",
    "    ccc         = round(concordance_correlation_coefficient( prediction_df['y'], prediction_df['y_hat']),2)\n",
    "\n",
    "    KPI_RF_rab.loc['NRMSe', f'{label[-6:-4]}'] = nrmse\n",
    "    KPI_RF_rab.loc['RMSE', f'{label[-6:-4]}'] = rmse\n",
    "    KPI_RF_rab.loc['MAE', f'{label[-6:-4]}'] = mae\n",
    "    KPI_RF_rab.loc['MAPE', f'{label[-6:-4]}'] = mape\n",
    "    KPI_RF_rab.loc['$R^2$', f'{label[-6:-4]}'] = r2\n",
    "    KPI_RF_rab.loc['EV', f'{label[-6:-4]}'] = ev\n",
    "    KPI_RF_rab.loc['Max_e', f'{label[-6:-4]}'] = max_e\n",
    "    KPI_RF_rab.loc['MIN_E', f'{label[-6:-4]}'] = min_e\n",
    "    KPI_RF_rab.loc['MedAE', f'{label[-6:-4]}'] = mnae\n",
    "    KPI_RF_rab.loc['Mean', f'{label[-6:-4]}'] = round(prediction_df['y_hat'].mean(),0)\n",
    "    KPI_RF_rab.loc['MPe', f'{label[-6:-4]}'] = mpe\n",
    "    KPI_RF_rab.loc['ACC', f'{label[-6:-4]}'] = accuracy\n",
    "    KPI_RF_rab.loc['Max', f'{label[-6:-4]}'] = round(prediction_df['y_hat'].max(), 0) \n",
    "    KPI_RF_rab.loc['MIN', f'{label[-6:-4]}'] = round(prediction_df['y_hat'].min(), 0)   \n",
    "    KPI_RF_rab.loc['RSD', f'{label[-6:-4]}'] = round(np.std(prediction_df['y_hat']) / np.mean(prediction_df['y_hat']) ,2)\n",
    "    KPI_RF_rab.loc['$p_c$', f'{label[-6:-4]}'] =  ccc\n",
    "    KPI_RF_rab.loc['BIAS', f'{label[-6:-4]}'] =  bias\n",
    "\n",
    "##'MedAE',   'BIAS', 'ACC', 'EV', 'RSD', 'Mean',  'MAX', 'MIN', \n",
    "scores = ['NRMSe', '$R^2$',   'Max_e', 'Max', \n",
    "           ]\n",
    "\n",
    "\n",
    "n_labels = 30\n",
    "#subfile = 'HOD'\n",
    "#files_rab = [ x for x in files_rab if subfile in x ]\n",
    "\n",
    "fontsize = 40\n",
    "i = 0\n",
    "fig, axs = plt.subplots(2,2,figsize=(15, 30))\n",
    "\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1)\n",
    "#fig.set_size_inches(30,30)\n",
    "for score, axi in zip(scores, axs.flatten()):\n",
    "\n",
    "\n",
    "    # Set graph style\n",
    "    \n",
    "    axi.set(facecolor = \"white\")\n",
    "    \n",
    "    #cols  = KPI_RK_rab.loc[score,:].sort_values(ascending=False).index.tolist()\n",
    "\n",
    "\n",
    "    if score in ['$R^2$','EV' ,'Max', 'ACC','$p_c$','RSD']:\n",
    "        \n",
    "\n",
    "               \n",
    "        x_data_KED = KPI_RK_rab.loc[score,:].sort_values(ascending=False).index\n",
    "        y_data_KED = KPI_RK_rab.loc[score,:].sort_values(ascending=False)\n",
    "        \n",
    "        \n",
    "        #x_data_RFR = KPI_RF_rab.loc[score,:].sort_values(ascending=False).index\n",
    "        y_data_RFR = KPI_RF_rab.loc[score,x_data_KED]\n",
    "        \n",
    "        KPI = pd.DataFrame({'$\\hat{y}_{KED}$': y_data_KED,\n",
    "                   '$\\hat{y}_{RF}$': y_data_RFR}, index=x_data_KED).sort_values(\n",
    "            ascending=True, by=['$\\hat{y}_{KED}$'])\n",
    "        \n",
    "        ax = KPI.plot.barh(rot=0, width=0.9, ax=axi, fontsize=fontsize)\n",
    "        axi.set_title(score, fontsize=fontsize)\n",
    "        ax.legend(loc='lower left', fontsize=fontsize)\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fontsize=fontsize)\n",
    "\n",
    "        plt.tight_layout()\n",
    "    else:\n",
    "        x_data_KED = KPI_RK_rab.loc[score,:].sort_values().index\n",
    "        y_data_KED = KPI_RK_rab.loc[score,:].sort_values()\n",
    "        #bar = sns.barplot(y_data[:], x_data[:] , color='darkgreen',      ax=ax)\n",
    "        #x_data_RFR = KPI_RF_rab.loc[score,:].sort_values().index\n",
    "        y_data_RFR = KPI_RF_rab.loc[score,x_data_KED]\n",
    "        \n",
    "        KPI = pd.DataFrame({'$\\hat{y}_{KED}$': y_data_KED,\n",
    "                   '$\\hat{y}_{RF}$': y_data_RFR}, index=x_data_KED).sort_values(\n",
    "            ascending=False, by=['$\\hat{y}_{KED}$'])        \n",
    "        ax = KPI.plot.barh(rot=0, width=0.9, ax=axi, fontsize=fontsize)\n",
    "        axi.set_title(score, fontsize=fontsize)\n",
    "        ax.legend(loc='lower left', fontsize=fontsize)\n",
    "        for container in ax.containers:\n",
    "            ax.bar_label(container, fontsize=fontsize)\n",
    "            \n",
    "    \n",
    "    if (i%3) ==0:\n",
    "        ax.set_ylabel('Number of geo-observables',  fontsize=fontsize)\n",
    "    else:\n",
    "        ax.set_ylabel('')\n",
    "        #g0.get_yaxis().set_visible(False)\n",
    "        #g0.ax_joint.get_yaxis().set_visible(False) \n",
    "\n",
    "    ax.locator_params(axis='x', nbins=6)  # set divisor \n",
    "    #ax.set(yticklabels=[])  \n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(left=0, bottom=1, right=2, top=2, wspace=0.3, hspace=0.1)\n",
    "    i+=1\n",
    "fig.savefig(dir_p/'fig'/\"fig_s7.jpeg\", bbox_inches='tight', dpi=300 )\n",
    "\n",
    "\n",
    "prediction_df['y'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7cc48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'Afr_50'\n",
    "predictions_max_min_rab_lr = pd.DataFrame()\n",
    "labels = ['04', '05', '06','07','08', '09', '10', '11', '12', '13', '14', '15', '16']\n",
    "\n",
    "\n",
    "for label in labels:\n",
    "\n",
    "    predictions_max_min_rab_lr[f'RK_{label}_rab']  = pd.DataFrame(grids[region].ds[f'RK_{label}_rab'].T.values.reshape(-1,1))\n",
    "    predictions_max_min_rab_lr['max'] = predictions_max_min_rab_lr.max(1)\n",
    "    predictions_max_min_rab_lr['min'] = predictions_max_min_rab_lr.min(1)\n",
    "    \n",
    "predictions_max_min_rab_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc5e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'Afr_50'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "\n",
    "file_rfe = '11'\n",
    "\n",
    "\n",
    "label_ra_lr = [ label for label in labels_RK_ra_lr if file_rfe in label]\n",
    "\n",
    "\n",
    "label_rab_lr = [ label for label in labels_RK_rab_lr if file_rfe in label]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Afr_50_Q_RK_rab_lr = pd.DataFrame(grids[region].ds[f'RK_{label_rab_lr[0][-6:]}'].T.values.reshape(-1,1))\n",
    "Afr_50_Q_RF_rab_lr = pd.DataFrame(grids[region].ds[f'RF_{label_rab_lr[0][-6:]}'].T.values.reshape(-1,1))\n",
    "\n",
    "Afr_50_Q_RK_ra_lr = pd.DataFrame(grids[region].ds[f'RK_{label_ra_lr[0][-5:]}'].T.values.reshape(-1,1))\n",
    "Afr_50_Q_RF_ra_lr = pd.DataFrame(grids[region].ds[f'RF_{label_ra_lr[0][-5:]}'].T.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "print(f'max b {Afr_50_Q_RK_ra_lr.max()[0]} min {Afr_50_Q_RK_ra_lr.min()[0]}')\n",
    "print(f'max g {Afr_50_Q_RK_rab_lr.max()[0]} min {Afr_50_Q_RK_rab_lr.min()[0]}')\n",
    "\n",
    "lon = pd.DataFrame(grids[region].lon.T.reshape(-1,1))\n",
    "lat = pd.DataFrame(grids[region].lat.T.reshape(-1,1))\n",
    "'''\n",
    "df_Afr_50_rab_lr = pd.concat([lon, lat, Afr_50_Q_RK_rab_lr, Afr_50_Q_RF_rab_lr,\n",
    "                             (predictions_max_min_rab_lr['max'] - predictions_max_min_rab_lr['min'])/2,\n",
    "                          ] , axis=1).dropna()'''\n",
    "\n",
    "df_Afr_50_rab_lr = pd.concat([lon, lat, Afr_50_Q_RK_rab_lr, Afr_50_Q_RF_rab_lr,\n",
    "                             (predictions_max_min_rab_lr['max'] - predictions_max_min_rab_lr['min'])/2,\n",
    "                          ] , axis=1).dropna()\n",
    "\n",
    "df_Afr_50_rab_lr.columns = ['lon', 'lat','Q_RK', 'Q_RF' ,'UNC',]\n",
    "\n",
    "'''df_Afr_50_ra_lr = pd.concat([lon, lat, Afr_50_Q_RK_ra_lr, Afr_50_Q_RF_ra_lr,\n",
    "                         (predictions_max_min_ra_lr['max'] - predictions_max_min_ra_lr['min'])/2,\n",
    "                          ] , axis=1).dropna()'''\n",
    "\n",
    "df_Afr_50_ra_lr = pd.concat([lon, lat, Afr_50_Q_RK_ra_lr, Afr_50_Q_RF_ra_lr,\n",
    "                         (predictions_max_min_rab_lr['max'] - predictions_max_min_rab_lr['min'])/2,\n",
    "                          ] , axis=1).dropna()\n",
    "\n",
    "df_Afr_50_ra_lr.columns = ['lon', 'lat','Q_RK', 'Q_RF', 'UNC',]\n",
    "\n",
    "\n",
    "df_Afr_50_RK_rab_lr = df_Afr_50_rab_lr[['lon', 'lat','Q_RK']]\n",
    "data_RK_rab_lr = df_Afr_50_RK_rab_lr.values\n",
    "\n",
    "df_Afr_50_RK_ra_lr = df_Afr_50_ra_lr[['lon', 'lat','Q_RK']]\n",
    "data_RK_ra_lr = df_Afr_50_RK_ra_lr.values\n",
    "\n",
    "df_Afr_50_RF_rab_lr = df_Afr_50_rab_lr[['lon', 'lat','Q_RF']]\n",
    "data_RF_rab_lr = df_Afr_50_RF_rab_lr.values\n",
    "\n",
    "df_Afr_50_RF_ra_lr = df_Afr_50_ra_lr[['lon', 'lat','Q_RF']]\n",
    "data_RF_ra_lr = df_Afr_50_RF_ra_lr.values\n",
    "\n",
    "df_Afr_50_UNC_rab_lr = df_Afr_50_rab_lr[['lon', 'lat','UNC']]\n",
    "data_UNC_rab_lr = df_Afr_50_UNC_rab_lr.values\n",
    "\n",
    "df_Afr_50_UNC_ra_lr = df_Afr_50_ra_lr[['lon', 'lat','UNC']]\n",
    "data_UNC_ra_lr = df_Afr_50_UNC_ra_lr.values\n",
    "\n",
    "\n",
    "df_Afr_50_Diff_rab_lr = df_Afr_50_rab_lr[['lon', 'lat']]\n",
    "df_Afr_50_Diff_rab_lr['Q_Diff'] = df_Afr_50_rab_lr['Q_RK'] - df_Afr_50_ra_lr['Q_RK']\n",
    "data_Diff_rab_lr =  df_Afr_50_Diff_rab_lr.values \n",
    "\n",
    "df_Afr_50_Diff_ra_lr = df_Afr_50_ra_lr[['lon', 'lat']]\n",
    "df_Afr_50_Diff_ra_lr['Q_Diff'] = df_Afr_50_ra_lr['Q_RK'] - df_Afr_50_rab_lr['Q_RK']\n",
    "data_Diff_ra_lr =  df_Afr_50_Diff_ra_lr.values \n",
    "\n",
    "df_Afr_50_OK_rab_lr = df_Afr_50_rab_lr[['lon', 'lat']]\n",
    "df_Afr_50_OK_rab_lr['Q_OK'] = df_Afr_50_rab_lr['Q_RK'] - df_Afr_50_rab_lr['Q_RF']\n",
    "data_OK_rab_lr =  df_Afr_50_OK_rab_lr.values \n",
    "\n",
    "df_Afr_50_OK_ra_lr = df_Afr_50_ra_lr[['lon', 'lat']]\n",
    "df_Afr_50_OK_ra_lr['Q_OK'] = df_Afr_50_ra_lr['Q_RK'] - df_Afr_50_ra_lr['Q_RF']\n",
    "data_OK_ra_lr =  df_Afr_50_OK_ra_lr.values \n",
    "\n",
    "mu_rab_lr = df_Afr_50_rab_lr['Q_RK'].mean()\n",
    "mu_ra_lr = df_Afr_50_ra_lr['Q_RK'].mean()\n",
    "\n",
    "df_Afr_50_RSD_rab_lr = df_Afr_50_rab_lr[['lon', 'lat']]\n",
    "df_Afr_50_RSD_rab_lr['Q_RSD'] = (np.sqrt((df_Afr_50_rab_lr['Q_RK'] - mu_rab_lr)**2)/ mu_rab_lr)  *100\n",
    "data_RSD_rab_lr =  df_Afr_50_RSD_rab_lr.values \n",
    "\n",
    "df_Afr_50_RSD_ra_lr = df_Afr_50_ra_lr[['lon', 'lat']]\n",
    "df_Afr_50_RSD_ra_lr['Q_RSD'] = (np.sqrt((df_Afr_50_ra_lr['Q_RK'] - mu_ra_lr)**2)/ mu_ra_lr) *100\n",
    "data_RSD_ra_lr =  df_Afr_50_RSD_ra_lr.values \n",
    "\n",
    "\n",
    "prediction_df_ra_lr = pd.DataFrame()\n",
    "\n",
    "prediction_df_ra_lr['y'] = training_Afr_50_ra[target]\n",
    "prediction_df_ra_lr['lat'] = training_Afr_50_ra['lat']\n",
    "prediction_df_ra_lr['lon'] =  training_Afr_50_ra['lon']\n",
    "prediction_df_ra_lr['y_hat_RK'] = grids[region].ds[f'RK_{label_ra_lr[0][-5:]}'].values.ravel()[training_Afr_50_ra['grid_index']]\n",
    "prediction_df_ra_lr['y_hat_RF'] = grids[region].ds[f'RF_{label_ra_lr[0][-5:]}'].values.ravel()[training_Afr_50_ra['grid_index']]\n",
    "\n",
    "\n",
    "prediction_df_ra_lr.dropna(inplace=True)\n",
    "\n",
    "gt_Afr_50_ra_lr_lat = prediction_df_ra_lr['lat'].values\n",
    "gt_Afr_50_ra_lr_lon =  prediction_df_ra_lr['lon'].values\n",
    "y_test_ra_lr = prediction_df_ra_lr['y'].values\n",
    "y_pred_RK_ra_lr = prediction_df_ra_lr['y_hat_RK'].values\n",
    "y_pred_RF_ra_lr = prediction_df_ra_lr['y_hat_RF'].values\n",
    "\n",
    "prediction_df_rab_lr = pd.DataFrame()\n",
    "\n",
    "prediction_df_rab_lr['y'] = training_Afr_50_rab[target]\n",
    "prediction_df_rab_lr['lat'] = training_Afr_50_rab['lat']\n",
    "prediction_df_rab_lr['lon'] =  training_Afr_50_rab['lon']\n",
    "prediction_df_rab_lr['y_hat_RK'] = grids[region].ds[f'RK_{label_rab_lr[0][-6:]}'].values.ravel()[training_Afr_50_rab['grid_index']]\n",
    "prediction_df_rab_lr['y_hat_RF'] = grids[region].ds[f'RF_{label_rab_lr[0][-6:]}'].values.ravel()[training_Afr_50_rab['grid_index']]\n",
    "\n",
    "\n",
    "prediction_df_rab_lr.dropna(inplace=True)\n",
    "\n",
    "gt_Afr_50_rab_lr_lat = prediction_df_rab_lr['lat'].values\n",
    "gt_Afr_50_rab_lr_lon =  prediction_df_rab_lr['lon'].values\n",
    "y_test_rab_lr = prediction_df_rab_lr['y'].values\n",
    "y_pred_RK_rab_lr = prediction_df_rab_lr['y_hat_RK'].values\n",
    "y_pred_RF_rab_lr = prediction_df_rab_lr['y_hat_RF'].values\n",
    "\n",
    "prediction_df_rb_lr = pd.concat([prediction_df_rab_lr, prediction_df_ra_lr])\n",
    "\n",
    "prediction_df_rb_lr.drop_duplicates(['y' , 'lat', 'lon'], keep=False, inplace = True)\n",
    "\n",
    "\n",
    "gt_Afr_50_rb_lr_lat = prediction_df_rb_lr['lat'].values\n",
    "gt_Afr_50_rb_lr_lon =  prediction_df_rb_lr['lon'].values\n",
    "y_test_rb_lr = prediction_df_rb_lr['y'].values\n",
    "y_pred_RK_rb_lr = prediction_df_rb_lr['y_hat_RK'].values\n",
    "y_pred_RF_rb_lr = prediction_df_rb_lr['y_hat_RF'].values\n",
    "\n",
    "resid_rb_lr = (prediction_df_rb_lr['y'] - prediction_df_rb_lr['y_hat_RK'] ).values\n",
    "\n",
    "resid_rab_lr = (prediction_df_rab_lr['y'] - prediction_df_rab_lr['y_hat_RK'] ).values\n",
    " \n",
    "resid_ra_lr = (prediction_df_ra_lr['y']  - prediction_df_ra_lr['y_hat_RK'] ).values\n",
    "\n",
    "\n",
    "print(len(prediction_df_ra_lr))\n",
    "print(len(prediction_df_rb_lr))\n",
    "print(len(prediction_df_rab_lr))\n",
    "\n",
    "print(len(prediction_df_rab_lr[prediction_df_rab_lr['y'] > 125])/len(prediction_df_rab_lr))\n",
    "print(len(prediction_df_rab_lr[prediction_df_rab_lr['y'] < 50])/len(prediction_df_rab_lr))\n",
    "\n",
    "\n",
    "#len(training_Afr_50_rab[target])\n",
    "\n",
    "resid_rab_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813e4a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df = pd.DataFrame()\n",
    "prediction_df['lat'] = prediction_df_rab_lr['lat'].values\n",
    "prediction_df['lon'] =  prediction_df_rab_lr['lon'].values\n",
    "prediction_df['resid'] = (prediction_df_rab_lr['y'] - prediction_df_rab_lr['y_hat_RF'] ).values\n",
    "\n",
    "prediction_df.to_csv('kriging_residual.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d6a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create two datsets for A ratibng and b ratings\n",
    "HGHF_file = dir_p / 'data' / 'dataset'/ 'Reference'/'q_Heat_flow'/'NGHF.csv'\n",
    "\n",
    "\n",
    "hf = pd.read_csv(HGHF_file)\n",
    "# change heat flow to mili\n",
    "\n",
    "elev_cut = -1000\n",
    "\n",
    "\n",
    "\n",
    "record_total = pd.read_csv(HGHF_file)\n",
    "\n",
    "print(len(record_total))\n",
    "hf_clean = record_total.dropna(subset = ['longitude', 'latitude', 'heat-flow (mW/m2)'])\n",
    "\n",
    "\n",
    "hf_no_pole = hf_clean[hf_clean['latitude'].between(world_lat_min, world_lat_max, inclusive='both')]\n",
    "hf_deep = hf_no_pole[(hf_no_pole['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "hf_final_a = hf_no_pole[(hf_no_pole ['code6']=='A') & (hf_no_pole ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "hf_final_b = hf_no_pole[(hf_no_pole ['code6']=='B') & (hf_no_pole ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "hf_final_c = hf_no_pole[(hf_no_pole ['code6']=='C') & (hf_no_pole ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "hf_final_d = hf_no_pole[(hf_no_pole ['code6']=='D') & (hf_no_pole ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "\n",
    "######A rating\n",
    "\n",
    "hf_final_a.columns = ['lon', 'lat', 'heat-flow (mW/m2)']\n",
    "\n",
    "\n",
    "hf_final_a = hf_final_a.round(3)\n",
    "\n",
    "print(len(hf_final_a))\n",
    "hf_final_a.replace(' ', np.nan, inplace=True)\n",
    "hf_final_a.sort_values(by=['lon', 'lat'], ascending=True, inplace=True)\n",
    "hf_final_a.reset_index( inplace=True,drop=True)\n",
    "\n",
    "assert hf_final_a['lon'].max() <= 180, f\" max lon {hf_final_a['lon'].max()}\"\n",
    "assert hf_final_a['lon'].min() >= -180, f\" min lon {hf_final_a['lon'].min()}\"\n",
    "assert hf_final_a['lat'].max() <= 90, f\" max lat {hf_final_a['lat'].max()}\"\n",
    "assert hf_final_a['lat'].min() >= -90, f\" min lat {hf_final_a['lon'].min()}\"\n",
    "\n",
    "\n",
    "###### A+ B rating\n",
    "\n",
    "hf_final_b.columns = ['lon', 'lat', 'heat-flow (mW/m2)']\n",
    "\n",
    "\n",
    "hf_final_b = hf_final_b.round(3)\n",
    "\n",
    "hf_final_b.replace(' ', np.nan, inplace=True)\n",
    "hf_final_b.sort_values(by=['lon', 'lat'], ascending=True, inplace=True)\n",
    "hf_final_b.reset_index( inplace=True,drop=True)\n",
    "\n",
    "\n",
    "assert hf_final_b['lon'].max() <= 180, f\" max lon {hf_final_b['lon'].max()}\"\n",
    "assert hf_final_b['lon'].min() >= -180, f\" min lon {hf_final_b['lon'].min()}\"\n",
    "assert hf_final_b['lat'].max() <= 90, f\" max lat {hf_final_b['lat'].max()}\"\n",
    "assert hf_final_b['lat'].min() >= -90, f\" min lat {hf_final_b['lon'].min()}\"\n",
    "\n",
    "\n",
    "\n",
    "###### A+ B + C rating\n",
    "\n",
    "hf_final_c.columns = ['lon', 'lat', 'heat-flow (mW/m2)']\n",
    "\n",
    "\n",
    "hf_final_c = hf_final_c.round(3)\n",
    "\n",
    "hf_final_c.replace(' ', np.nan, inplace=True)\n",
    "hf_final_c.sort_values(by=['lon', 'lat'], ascending=True, inplace=True)\n",
    "hf_final_c.reset_index( inplace=True,drop=True)\n",
    "print(len(hf_final_c))\n",
    "\n",
    "assert hf_final_c['lon'].max() <= 180, f\" max lon {hf_final_c['lon'].max()}\"\n",
    "assert hf_final_c['lon'].min() >= -180, f\" min lon {hf_final_c['lon'].min()}\"\n",
    "assert hf_final_c['lat'].max() <= 90, f\" max lat {hf_final_c['lat'].max()}\"\n",
    "assert hf_final_c['lat'].min() >= -90, f\" min lat {hf_final_c['lon'].min()}\"\n",
    "\n",
    "\n",
    "###### A+ B + C rating and elevation\n",
    "\n",
    "hf_final_d.columns = ['lon', 'lat', 'heat-flow (mW/m2)']\n",
    "\n",
    "\n",
    "hf_final_d = hf_final_d.round(3)\n",
    "\n",
    "hf_final_d.replace(' ', np.nan, inplace=True)\n",
    "hf_final_d.sort_values(by=['lon', 'lat'], ascending=True, inplace=True)\n",
    "hf_final_d.reset_index( inplace=True,drop=True)\n",
    "\n",
    "\n",
    "assert hf_final_d['lon'].max() <= 180, f\" max lon {hf_final_d['lon'].max()}\"\n",
    "assert hf_final_d['lon'].min() >= -180, f\" min lon {hf_final_d['lon'].min()}\"\n",
    "assert hf_final_d['lat'].max() <= 90, f\" max lat {hf_final_d['lat'].max()}\"\n",
    "assert hf_final_d['lat'].min() >= -90, f\" min lat {hf_final_d['lon'].min()}\"\n",
    "\n",
    "\n",
    "print(len(hf_final_a))\n",
    "print(len(hf_final_b))\n",
    "\n",
    "print(len(hf_final_c))\n",
    "print(len(hf_final_d))\n",
    "\n",
    "\n",
    "print('terminated')\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(20, 12))\n",
    "print(plt.style.available)\n",
    "plt.style.use('_classic_test_patch')\n",
    "\n",
    "sns.set(style='white', font_scale = 2.6)\n",
    "\n",
    "record_total[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                          label = f'All records (n={len(record_total):,})')\n",
    "                          \n",
    "hf_clean[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                      label = f'Excluded incomplete records (n={len(hf_clean):,})')\n",
    "hf_no_pole[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                         label = f'Excluded high latitudes (n={len(hf_no_pole):,})')\n",
    "hf_deep[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                         label = f'Excluded deeper than {abs(elev_cut)} m (n={len(hf_deep):,})')\n",
    "\n",
    "pd.concat([hf_final_a[target], hf_final_b[target], hf_final_c[target], \n",
    "           hf_final_d[target]]).hist(\n",
    "    bins=100, range = (0, 200), ax=ax,\n",
    "label = f'Rating $A$-$D$ (n={len(hf_final_a) + len(hf_final_b)+ len(hf_final_c) + len(hf_final_d):,})')\n",
    "pd.concat([hf_final_a[target], hf_final_b[target], hf_final_c[target]]).hist(\n",
    "    bins=100,  range = (0, 200),ax=ax,\n",
    "label = f'Rating $A$-$C$ (n={len(hf_final_a) + len(hf_final_b) + len(hf_final_c):,})')\n",
    "pd.concat([hf_final_a[target], hf_final_b[target]]).hist(\n",
    "    bins=100,  range = (0, 200),ax=ax,\n",
    "                        label = f'Rating $A$-$B$ (n={len(hf_final_a) + len(hf_final_b ):,})')\n",
    "hf_final_a[target].hist(bins=100,  range = (0, 200),ax=ax,\n",
    "                        label = f'Rating $A$ (n={len(hf_final_a):,})')\n",
    "\n",
    "\n",
    "ax.set_title(f'{sub_figs[2]})', loc ='left', pad=20, )\n",
    "ax.legend()\n",
    "ax.set_ylabel(f'$n$')\n",
    "\n",
    "ax.set_xlabel('GHF [mW/m2]')\n",
    "    \n",
    "\n",
    "#ax.set_title('Distribution of different global GHF values', pad=40,)\n",
    "\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_s1b.jpeg\", bbox_inches='tight', dpi=300 , pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f37370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create two datsets for A ratibng and b ratings\n",
    "HGHF_file = dir_p / 'data' / 'dataset'/ 'Reference'/ 'q_Heat_flow'/'NGHF.csv'\n",
    "\n",
    "\n",
    "hf = pd.read_csv(HGHF_file)\n",
    "# change heat flow to mili\n",
    "\n",
    "elev_cut = -1000\n",
    "\n",
    "\n",
    "\n",
    "record_total_int = pd.read_csv(HGHF_file)\n",
    "\n",
    "hf_afr_lat = record_total_int[record_total_int['latitude'].between(afr_lat_min, afr_lat_max, inclusive='both')]\n",
    "record_total_afr = hf_afr_lat[hf_afr_lat['longitude'].between(afr_lon_min, afr_lon_max, inclusive='both')]\n",
    "\n",
    "\n",
    "\n",
    "hf_no_pole_afr = record_total_afr.dropna(subset = ['longitude', 'latitude', 'heat-flow (mW/m2)'])\n",
    "\n",
    "\n",
    "\n",
    "#hf_no_pole_afr = hf_clean[hf_clean['latitude'].between(world_lat_min, world_lat_max, inclusive='both')]\n",
    "hf_deep_afr = hf_no_pole_afr[(hf_no_pole_afr['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "hf_final_a_afr = hf_no_pole_afr[(hf_no_pole_afr ['code6']=='A') & (hf_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "hf_final_b_afr= hf_no_pole_afr[(hf_no_pole_afr ['code6']=='B') & (hf_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "hf_final_c_afr = hf_no_pole_afr[(hf_no_pole_afr ['code6']=='C') & (hf_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "hf_final_d_afr = hf_no_pole_afr[(hf_no_pole_afr ['code6']=='D') & (hf_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "hf_final_z_afr = hf_no_pole_afr[(hf_no_pole_afr ['code6']=='Z') & (hf_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude','heat-flow (mW/m2)']]\n",
    "\n",
    "\n",
    "hf_extreme_a = hf_final_a_afr[hf_final_a_afr[target] >=200]\n",
    "lon_hf_extreme_a = hf_extreme_a['longitude']\n",
    "lat_hf_extreme_a = hf_extreme_a['latitude']\n",
    "\n",
    "hf_extreme_b = hf_final_b_afr[hf_final_b_afr[target] >=200]\n",
    "lon_hf_extreme_b = hf_extreme_b['longitude']\n",
    "lat_hf_extreme_b = hf_extreme_b['latitude']\n",
    "\n",
    "hf_extreme = hf_no_pole_afr[hf_no_pole_afr[target] >=200]\n",
    "lon_hf_extreme = hf_extreme['longitude']\n",
    "lat_hf_extreme = hf_extreme['latitude']\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots( figsize=(20, 12))\n",
    "print(plt.style.available)\n",
    "plt.style.use('_classic_test_patch')\n",
    "\n",
    "sns.set(style='whitegrid', font_scale = 2.6)\n",
    "\n",
    "\n",
    "record_total_afr[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                          label = f'All records (n={len(record_total_afr):,})')\n",
    "                          \n",
    "#hf_clean[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "#                      label = f'Excluded incomplete records (n={len(hf_clean):,})')\n",
    "hf_no_pole_afr[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                         label = f'Excluded incomplete records (n={len(hf_no_pole_afr):,})')\n",
    "hf_deep_afr[target].hist(bins=100, range = (0, 200), ax=ax,\n",
    "                         label = f'Excluded deeper than {abs(elev_cut)} m (n={len(hf_deep_afr):,})')\n",
    "\n",
    "pd.concat([hf_final_a_afr[target], hf_final_b_afr[target], hf_final_c_afr[target], hf_final_d_afr[target]]).hist(\n",
    "    bins=100, range = (0, 200), ax=ax,\n",
    "                        label = f'Rating $A$-$D$ (n={len(hf_final_a_afr) + len(hf_final_b_afr) + len(hf_final_c_afr) + len(hf_final_d_afr):,})')\n",
    "pd.concat([hf_final_a_afr[target], hf_final_b_afr[target], hf_final_c_afr[target]]).hist(\n",
    "    bins=100,  range = (0, 200),ax=ax,\n",
    "                        label = f'Rating $A$-$C$ (n={len(hf_final_a_afr) + len(hf_final_b_afr) + len(hf_final_c_afr):,})')\n",
    "pd.concat([hf_final_a_afr[target], hf_final_b_afr[target]]).hist(\n",
    "    bins=100,  range = (0, 200),ax=ax,\n",
    "                        label = f'Rating $A$-$B$ (n={len(hf_final_a_afr) + len(hf_final_b_afr ):,})')\n",
    "hf_final_a_afr[target].hist(bins=100,  range = (0, 200),ax=ax,\n",
    "                        label = f'Rating $A$ (n={len(hf_final_a_afr):,})')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax.set_title(f'{sub_figs[2]})', loc ='left', pad=20, )\n",
    "ax.legend()\n",
    "ax.set_ylabel(f'$n$')\n",
    "\n",
    "ax.set_xlabel('GHF [mW/m2]')\n",
    "    \n",
    "\n",
    "#ax.set_title('Distribution of different global GHF values', pad=40,)\n",
    "\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_1b.jpeg\", bbox_inches='tight', dpi=300 , pad_inches=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b676710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#create two datsets for A ratibng and b ratings\n",
    "uncertainity_file = dir_p / 'data' / 'dataset'/ 'Reference'/ 'q_Heat_flow'/'NGHF.csv'\n",
    "\n",
    "\n",
    "\n",
    "elev_cut = -1000\n",
    "\n",
    "\n",
    "\n",
    "record_total_int = pd.read_csv(uncertainity_file)\n",
    "\n",
    "uncertainity_afr_lat = record_total_int[record_total_int['latitude'].between(afr_lat_min, afr_lat_max, inclusive='both')]\n",
    "record_total_afr = uncertainity_afr_lat[uncertainity_afr_lat['longitude'].between(afr_lon_min, afr_lon_max, inclusive='both')]\n",
    "\n",
    "target_unc = 'uncertainty hf (mW/m2)'\n",
    "\n",
    "uncertainity_no_pole_afr = record_total_afr.dropna(subset = ['longitude', 'latitude', target_unc])\n",
    "\n",
    "\n",
    "\n",
    "#uncertainity_no_pole_afr = uncertainity_clean[uncertainity_clean['latitude'].between(world_lat_min, world_lat_max, inclusive='both')]\n",
    "uncertainity_deep_afr = uncertainity_no_pole_afr[(uncertainity_no_pole_afr['elevation (m)']>elev_cut)][['longitude', 'latitude',target_unc]]\n",
    "\n",
    "uncertainity_final_a_afr = uncertainity_no_pole_afr[(uncertainity_no_pole_afr ['code6']=='A') & (uncertainity_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude',target_unc]]\n",
    "uncertainity_final_b_afr= uncertainity_no_pole_afr[(uncertainity_no_pole_afr ['code6']=='B') & (uncertainity_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude',target_unc]]\n",
    "\n",
    "uncertainity_final_c_afr = uncertainity_no_pole_afr[(uncertainity_no_pole_afr ['code6']=='C') & (uncertainity_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude',target_unc]]\n",
    "uncertainity_final_d_afr = uncertainity_no_pole_afr[(uncertainity_no_pole_afr ['code6']=='D') & (uncertainity_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude',target_unc]]\n",
    "uncertainity_final_z_afr = uncertainity_no_pole_afr[(uncertainity_no_pole_afr ['code6']=='Z') & (uncertainity_no_pole_afr ['elevation (m)']>elev_cut)][['longitude', 'latitude',target_unc]]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#pygmt.config(FONT_ANNOT = '180p')\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=2,\n",
    "    ncols=3,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['C)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"0.6c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey='r',  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    cmap= pygmt.makecpt(\n",
    "            cmap='davos', #temp 19lev\n",
    "            series=f\"0/20/1\",\n",
    "            continuous=True,\n",
    "            reverse=True,\n",
    "        )\n",
    "    \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame='ESnw', panel=[0, 0])\n",
    "        \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'{len(uncertainity_final_b_afr) +len(uncertainity_final_a_afr)}',\n",
    "                      pen=\"0.5p\", style=\"c0.2c\")\n",
    "      \n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"1p,black\",\n",
    "            borders=[\"1/0.5p,black\"],\n",
    "            land ='darkgrey'\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "        \n",
    "        fig.plot(x=uncertainity_final_a_afr.longitude, y=uncertainity_final_a_afr.latitude,  cmap=True, projection=proj,\n",
    "             color=uncertainity_final_a_afr[target_unc], \n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        fig.plot(x=uncertainity_final_b_afr.longitude, y=uncertainity_final_b_afr.latitude,  cmap=True, projection=proj,\n",
    "             color=uncertainity_final_b_afr[target_unc],\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        '''\n",
    "        fig.plot(x=uncertainity_final_c_afr.longitude, y=uncertainity_final_c_afr.latitude,  cmap=True, projection=proj,\n",
    "             color=uncertainity_final_c_afr[target_unc],\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")'''\n",
    "        '''\n",
    "        fig.plot(x=uncertainity_deep_afr.longitude, y=uncertainity_deep_afr.latitude,  cmap=True, projection=proj,\n",
    "             color=uncertainity_deep_afr[target_unc],\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")'''\n",
    "\n",
    "        fig.colorbar(frame=[\"af\", \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_max +14)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "        \n",
    "    \n",
    "        fig.legend(position=\"g-23/-3\", box=False)\n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_20_uncertainty_ab.jpg\", dpi=300 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68014b48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=2,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['A)+o0.3/-1.2'],\n",
    "    margins=[\"0.18c\", \"0.6c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    cmap= pygmt.makecpt(\n",
    "          cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "    \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RF\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj,  frame='wNse', panel=[0, 0])\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RF_rab_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            )\n",
    "\n",
    "\n",
    "        #fig.colorbar(frame=[\"af\", \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "          #       position=f\"g{str(afr_lon_max +2)}/{str(afr_lat_min+1)}+w14.5c/0.5c+v+e\")\n",
    "\n",
    "\n",
    "\n",
    "    #####Kriging\n",
    "    with fig.set_panel(panel=[0, 1]):\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='vik', #temp 19lev\n",
    "            series=f\"-15/15/1\",\n",
    "            continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='NsEw', panel=[0, 1])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_OK_rab_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "        #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        #fig.colorbar(frame=[\"af\",  \"y+l[mW/m@+2@+]\"], \n",
    "                 #    position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w11c/0.5c+h+e\")\n",
    "        fig.colorbar(frame=[\"af\", 'x+lKriging\\tof\\tGHFs\\tResidual\\t[mW/m@+2@+\\]'],\n",
    "                   position=f\"g{str(afr_lon_max +14)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    ###\n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_5a.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85282eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "\n",
    "    \n",
    "tectonics_shp_main = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "labels_main = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "              if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "\n",
    "tectonics_shp_sub = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "                    and 'gmt' in filename]\n",
    "labels_sub = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics') \n",
    "             if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "             and 'gmt' in filename]\n",
    "\n",
    "volc_erup = pd.read_csv(dir_p/'GMT'/'tectonics'/'volcanic_eruptions.dat', sep='\\s')\n",
    "# congo co KA kalhari\n",
    "\n",
    "\n",
    "#pygmt.config(FONT_ANNOT = '180p')\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=2,\n",
    "    ncols=3,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['C)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"0.6c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey='r',  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "    \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame='ESnw', panel=[0, 0])\n",
    "        \n",
    "        '''\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"GHF\"',\n",
    "                      pen=\"0.5p\", style=\"c0.2c\")'''\n",
    "      \n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rab_lr, region=region_gmt, spacing=spacing)\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region_gmt,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "              #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "        \n",
    "        '''\n",
    "                    \n",
    "        for shape, label in zip(tectonics_shp_sub, labels_sub):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1,white,--')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "            #fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, font='15' ,text=label, justify=\"ML\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        for shape, label in zip(tectonics_shp_main, labels_main):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1.5,white')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "                \n",
    "            if label == 'RTA':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()-10, y=shape_xy.iloc[:,1].median()+0.5, \n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            elif label == 'AAO':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()+2, y=shape_xy.iloc[:,1].median()+2,\n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            elif label == 'BB':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()-3, y=shape_xy.iloc[:,1].median(),\n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "\n",
    "            else:\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, \n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            \n",
    "\n",
    "        fig.plot(x=volc_erup.Lon, y=volc_erup.Lat,  projection=proj,\n",
    "             color='white', label=f'\"Eruptions\"',\n",
    "                      pen=\"0.5p\", style=\"a0.25c\")'''\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "        fig.plot(x=hf_final_a.lon, y=hf_final_a.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_a[target], transparency =50,\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        fig.plot(x=hf_final_b.lon, y=hf_final_b.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_b[target],transparency =50,\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        '''\n",
    "        fig.plot(x=hf_final_c.lon, y=hf_final_c.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_c[target], #label=\"'C Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "       \n",
    "        fig.text(text=\"_\", x=-19, y=-4, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Major Cratons\", x=-8, y=-4, font=\"13p,Helvetica,black\")\n",
    "        fig.text(text=\"KA : Kalhari Cr.\", x=-11, y=-7, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"CC : Congo Cr.\", x=-11, y=-10, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"RTA :\", x=-11, y=-13, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"BB :\", x=-8, y=-16, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"WAC : W. African Cr.\", x=-7, y=-19, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"SMC : Sah. Metacr.\", x=-8, y=-22, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"AAO :\", x=-8, y=-25, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"--\", x=-19, y=-28, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Minor Cratons\", x=-8, y=-28, font=\"14p,Helvetica,black\")'''\n",
    "\n",
    "        fig.colorbar(frame=[\"af\", \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_max +14)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "        \n",
    "    \n",
    "        fig.legend(position=\"g-23/-3\", box=False)\n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_5b.jpg\", dpi=300 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5b631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "\n",
    "    \n",
    "tectonics_shp_main = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename in ['CC.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', ]]\n",
    "labels_main = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "              if filename in ['CC.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt']]\n",
    "\n",
    "tectonics_shp_sub = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename not in ['CC.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt',]\n",
    "                    and 'gmt' in filename]\n",
    "labels_sub = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics') \n",
    "             if filename not in ['CC.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt',]\n",
    "             and 'gmt' in filename]\n",
    "\n",
    "volc_erup = pd.read_csv(dir_p/'GMT'/'tectonics'/'volcanic_eruptions.dat', sep='\\s')\n",
    "# congo co KA kalhari\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=2,\n",
    "    ncols=3,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['A)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"0.6c\"], # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame='WneS',  panel=[0, 0])\n",
    "\n",
    "          \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"A Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"c0.2c\")\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"B Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"t0.22c\")        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"C Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"s0.22c\")   \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"D Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"d0.22c\")        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"Z Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"h0.22c\") \n",
    "        fig.plot(x=volc_erup.Lon, y=volc_erup.Lat,  projection=proj,\n",
    "             color='white', label=f'\"Volcanoes\"',\n",
    "                      pen=\"0.5p\", style=\"a0.25c\")\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            land='darkgrey'\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "     \n",
    "        \n",
    "        fig.plot(x=hf_final_a_afr.longitude, y=hf_final_a_afr.latitude,  cmap=True, projection=proj,\n",
    "             color=hf_final_a_afr[target], #label=f\"'A Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"c0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_b_afr.longitude, y=hf_final_b_afr.latitude,  cmap=True, projection=proj,\n",
    "             color=hf_final_b_afr[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"t0.21c\")\n",
    "        fig.plot(x=hf_final_c_afr.longitude, y=hf_final_c_afr.latitude,   cmap=True, projection=proj,\n",
    "             color=hf_final_c_afr[target], #label=\"'C Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"s0.21c\")\n",
    "        fig.plot(x=hf_final_d_afr.longitude, y=hf_final_d_afr.latitude,   cmap=True, projection=proj,\n",
    "             color=hf_final_d_afr[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"d0.21c\")\n",
    "        fig.plot(x=hf_final_z_afr.longitude, y=hf_final_z_afr.latitude,   cmap=True, projection=proj,\n",
    "             color=hf_final_z_afr[target], #label=\"'C Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"h0.21c\")\n",
    "        \n",
    "        for shape, label in zip(tectonics_shp_main, labels_main):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj, \n",
    "                     region=region_gmt,   pen='1.5,white')      \n",
    "           \n",
    "  \n",
    "        \n",
    "        for shape, label in zip(tectonics_shp_sub, labels_sub):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj, \n",
    "                     region=region_gmt,   pen='1,white,..-')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "            #fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, font='15' ,text=label, justify=\"ML\")\n",
    "\n",
    "        \n",
    "        fig.text(text=\"_\", x=-20, y=-30, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Major Cratons\", x=-9.2, y=-30.5, font=\"12.5p,Helvetica,black\")\n",
    "        fig.text(text=\"..\", x=-20, y=-32.5, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Cratonic Blocks\", x=-8.7, y=-32.5, font=\"12.5p,Helvetica,black\")\n",
    "\n",
    "        fig.colorbar(frame=[\"af\",\"x+lGHF\\t[mW/m@+2@+]\"], \n",
    "                position=f\"g{str(afr_lon_max +10)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "        \n",
    "        \n",
    "        labels = [ 'KA', \n",
    "                  'NNB', 'KC', 'BB', 'TC', 'ASZ', 'ZC', 'RB']\n",
    "        starts = [[8,-18], \n",
    "                  [8,-31],[35,-32],[47,-10],[47,-5],[46,0], [40,-20],[8,-25]]   \n",
    "        \n",
    "        starts_labels = [ [4,-18], \n",
    "                         [2,-31],[36,-32], [48,-10],[47,-5],[46,0], [40,-20],[4,-25],]   \n",
    "        \n",
    "        ends = [[16,-22], \n",
    "                [23,-31],[32,-27], [32,-6], [34,0], [35,10], [32,-17],[21,-24]]\n",
    "        \n",
    "        for start, end, label ,starts_label in zip(starts, ends, labels, starts_labels):\n",
    "            style = \"=0.3c+s+e+a30+gblue+h0.3+p0.3p,blue\"\n",
    "            data = np.array([start + end])\n",
    "            fig.plot(data=data, style=style, pen=\"1.0p,blue\")\n",
    "\n",
    "            fig.text(\n",
    "                text=label, x=starts_label[0], y=starts_label[1], \n",
    "                font=\"13p,Helvetica-Bold,white\" ,  justify=\"ML\"\n",
    "            )\n",
    "            \n",
    "        labels = [ 'WAC', 'SMC','CC', 'AAO', 'KB', \n",
    "                  'AC', 'CG']\n",
    "        starts_labels = [[-14,25],  [20,26], [18,0],[-8.2,37.3],[23.4,-5], \n",
    "                         [14,-11], [10, 7],]  \n",
    "        for label ,starts_label in zip(labels, starts_labels):\n",
    "            fig.text(\n",
    "                    text=label, x=starts_label[0], y=starts_label[1],  \n",
    "                    font=\"13p,Helvetica-Bold,white\" ,  justify=\"ML\"\n",
    "                )\n",
    "\n",
    "    fig.legend(position=\"g-25/-15\", box=False)\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_4.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af37be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "\n",
    "    \n",
    "tectonics_shp_main = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "labels_main = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "              if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "\n",
    "tectonics_shp_sub = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "                    and 'gmt' in filename]\n",
    "labels_sub = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics') \n",
    "             if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "             and 'gmt' in filename]\n",
    "\n",
    "volc_erup = pd.read_csv(dir_p/'GMT'/'tectonics'/'volcanic_eruptions.dat', sep='\\s')\n",
    "# congo co KA kalhari\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=1,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['C)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"0c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    #sharex=\"bt\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    #frame=\"WSrt\",\n",
    "):\n",
    "\n",
    "\n",
    "    cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/130',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "    \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame=True,  panel=[0, 0])\n",
    "       \n",
    "       \n",
    "        fig.plot(x=0, y=0,  projection=proj, cmap=False,\n",
    "              label='\"Residual GHF\"',\n",
    "                      pen=\"0.5p\", style=\"c0.21c\")\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='green', label='\"GHF > 200\\t[mW/m@+2@+]\"',\n",
    "                      pen=\"0.5p\", style=\"t0.24c\")\n",
    "        \n",
    "        '''\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"C Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"s0.22c\")  '''   \n",
    "        \n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rab_lr, region=region_gmt, spacing=spacing)\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region_gmt,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             frame=True,\n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        for shape, label in zip(tectonics_shp_sub, labels_sub):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1,white,--')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "            #fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, font='15' ,text=label, justify=\"ML\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        for shape, label in zip(tectonics_shp_main, labels_main):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1.5,white')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "                \n",
    "            if label == 'RTA':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()-10, y=shape_xy.iloc[:,1].median()+0.5, \n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            elif label == 'AAO':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()+2, y=shape_xy.iloc[:,1].median()+2,\n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            elif label == 'BB':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()-3, y=shape_xy.iloc[:,1].median(),\n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "\n",
    "            else:\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, \n",
    "                         font='15' ,text=label, justify=\"ML\")'''\n",
    "        '''\n",
    "        fig.plot(x=volc_erup.Lon, y=volc_erup.Lat,  projection=proj,\n",
    "             color='white', label=f'\"Eruptions\"',\n",
    "                      pen=\"0.5p\", style=\"a0.25c\")'''\n",
    "        \n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            #water=\"lightblue\", \n",
    "            #water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #land='darkgrey'\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "        '''\n",
    "        fig.plot(x=hf_final_a.lon, y=hf_final_a.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_a[target], #label=f\"'A Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_b.lon, y=hf_final_b.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_b[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        fig.plot(x=hf_final_c.lon, y=hf_final_c.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_c[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_d.lon, y=hf_final_d.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_d[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")'''\n",
    "        \n",
    "        fig.plot(x=hf_no_pole_afr.longitude.values, y=hf_no_pole_afr.latitude.values,  \n",
    "                 cmap=True, projection=proj,\n",
    "             color=hf_no_pole_afr[target].values, #label=\"'C Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.16c\")\n",
    "        \n",
    "        fig.plot(x=lon_hf_extreme , y=lat_hf_extreme ,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "        \n",
    "        '''\n",
    "        fig.text(text=\"_\", x=-19, y=-4, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Major Cratons\", x=-8, y=-4, font=\"13p,Helvetica,black\")\n",
    "        fig.text(text=\"KA : Kalhari Cr.\", x=-11, y=-7, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"CC : Congo Cr.\", x=-11, y=-10, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"RTA :\", x=-11, y=-13, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"BB :\", x=-8, y=-16, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"WAC : W. African Cr.\", x=-7, y=-19, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"SMC : Sah. Metacr.\", x=-8, y=-22, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"AAO :\", x=-8, y=-25, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"--\", x=-19, y=-28, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Minor Cratons\", x=-8, y=-28, font=\"14p,Helvetica,black\") '''   \n",
    "\n",
    "        '''\n",
    "        cmap= pygmt.makecpt(\n",
    "                    cmap='vik', #temp 19lev\n",
    "                    series=f\"-30/30/3\",\n",
    "                    continuous=True,\n",
    "                    reverse=False,\n",
    "                )'''\n",
    "\n",
    "        '''\n",
    "        fig.plot(x=gt_Afr_50_rb_lr_lon, y=gt_Afr_50_rb_lr_lat,   cmap=True, projection=proj,\n",
    "                             size= 0.5 * abs((resid_rb_lr-resid_rb_lr.min())/(resid_rb_lr.max() - resid_rb_lr.min())),    \n",
    "                 color=  resid_rb_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"cc\")'''\n",
    "\n",
    "    \n",
    "\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     #position=f\"g{str(afr_lon_max +2)}/{str(afr_lat_min+1)}+w14.5c/0.5c+v+e\")\n",
    "        position=f\"g{str(afr_lon_min-4)}/{str(afr_lat_min-6)}+w13.5c/0.5c+h+e\") \n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        fig.legend(position=\"g29.1/40+w4.7/1\", box='+gwhite', transparency=30)\n",
    "\n",
    "   \n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_s17.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a043c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=3,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['A)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"2.4c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    #sharex=\"bt\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    #frame=\"WSrt\",\n",
    "):\n",
    "\n",
    "\n",
    "    #####Kriging\n",
    "      \n",
    "    with fig.set_panel(panel=[0, 0]):\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='WNes',  panel=[0, 0])\n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='green', label='\"GHF > 200\\t[mW/m@+2@+]\"',\n",
    "                      pen=\"0.5p\", style=\"t0.24c\")\n",
    "        fig.plot(x=0, y=0,  projection=proj, cmap=False,\n",
    "              label='\"Residual GHF\"',\n",
    "                      pen=\"0.5p\", style=\"c0.21c\")\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", shorelines=\"1p,black\",\n",
    "            borders=[\"1/0.5p,black\"],\n",
    "            land='lightgrey'\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "        \n",
    "        \n",
    "        cmap= pygmt.makecpt(\n",
    "                    cmap='vik', #temp 19lev\n",
    "                    series=f\"-30/30/3\",\n",
    "                    continuous=True,\n",
    "                    reverse=False,\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "        fig.plot(x=gt_Afr_50_ra_lr_lon, y=gt_Afr_50_ra_lr_lat,   cmap=True, projection=proj,\n",
    "                             size= 0.4 * abs((resid_ra_lr-resid_ra_lr.min())/(resid_ra_lr.max() - resid_ra_lr.min())),    \n",
    "                 color=  resid_ra_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"cc\")\n",
    "        fig.plot(x=lon_hf_extreme_a, y=lat_hf_extreme_a,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "        fig.plot(x=lon_hf_extreme_b, y=lat_hf_extreme_b,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-6)}+w13c/0.5c+h+e\")\n",
    "        \n",
    "        fig.legend(position=\"g-23/-10\", box=False)\n",
    "        \n",
    "    with fig.set_panel(panel=[0, 1]):\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj,frame='NEse',  panel=[0, 1])\n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='green', label='\"GHF > 200\\t[mW/m@+2@+]\"',\n",
    "                      pen=\"0.5p\", style=\"t0.24c\")\n",
    "        fig.plot(x=0, y=0,  projection=proj, cmap=False,\n",
    "              label='\"Residual GHF\"',\n",
    "                      pen=\"0.5p\", style=\"c0.21c\")\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", shorelines=\"1p,black\",\n",
    "            borders=[\"1/0.5p,black\"],\n",
    "            land='lightgrey'\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        cmap= pygmt.makecpt(\n",
    "                    cmap='vik', #temp 19lev\n",
    "                    series=f\"-30/30/3\",\n",
    "                    continuous=True,\n",
    "                    reverse=False,\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "        fig.plot(x=gt_Afr_50_rb_lr_lon, y=gt_Afr_50_rb_lr_lat,   cmap=True, projection=proj,\n",
    "                             size= 0.5 * abs((resid_rb_lr-resid_rb_lr.min())/(resid_rb_lr.max() - resid_rb_lr.min())),    \n",
    "                 color=  resid_rb_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"cc\")\n",
    "\n",
    "        fig.plot(x=lon_hf_extreme_a, y=lat_hf_extreme_a,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "        fig.plot(x=lon_hf_extreme_b, y=lat_hf_extreme_b,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")    \n",
    "\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "            position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-6)}+w13c/0.5c+h+e\")\n",
    "        fig.legend(position=\"g-23/-10\", box=False)\n",
    "        \n",
    "    with fig.set_panel(panel=[1, 0]):\n",
    "\n",
    "\n",
    "        cmap = pygmt.makecpt(\n",
    "            cmap='inferno', #temp 19lev\n",
    "            series='0/50/10',\n",
    "            continuous=True,\n",
    "            reverse=True,)\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='WSne',  panel=[1, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RSD_rab_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "           position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-7)}+w13c/0.5c+h+e\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", shorelines=\"1p,black\",\n",
    "            borders=[\"1/0.5p,black\"],\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    "   \n",
    "    with fig.set_panel(panel=[1, 1] ):\n",
    "        #####RL\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='davos', #temp 19lev\n",
    "            series=f\"0/20/1\",\n",
    "            continuous=True,\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='ESnw',   panel=[1, 1])\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_UNC_rab_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", shorelines=\"1p,black\",\n",
    "            borders=[\"1/0.5p,black\"],\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-7)}+w13c/0.5c+h+e\")       \n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "#fig.savefig(dir_p/'fig'/\"fig_7.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e46f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=3,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['A)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"2.4c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    #sharex=\"bt\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    #frame=\"WSrt\",\n",
    "):\n",
    "\n",
    "\n",
    "           \n",
    "    with fig.set_panel(panel=[0, 0]):\n",
    "\n",
    "\n",
    "        cmap = pygmt.makecpt(\n",
    "            cmap='inferno', #temp 19lev\n",
    "            series='0/50/10',\n",
    "            continuous=True,\n",
    "            reverse=True,)\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='WsNe',  panel=[0, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RSD_rab_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lCV\\tof\\tGHF\\t[mW/m@+2@+]\"],\n",
    "           position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-7)}+w13c/0.5c+h+e\")\n",
    "        \n",
    "        \n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "\n",
    "            #water='white',\n",
    "            )\n",
    "        \n",
    "        \n",
    "\n",
    "   \n",
    "    with fig.set_panel(panel=[0, 1] ):\n",
    "        #####RL\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='davos', #temp 19lev\n",
    "            series=f\"0/20/1\",\n",
    "            continuous=True,\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='eNsw',   panel=[0, 1])\n",
    "        '''\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='green', label='\"GHF > 200\\t[mW/m@+2@+]\"',\n",
    "                      pen=\"0.5p\", style=\"t0.24c\")'''\n",
    "        fig.plot(x=0, y=0,  projection=proj, cmap=False,\n",
    "              label='\"Residual of GHF\"',\n",
    "                      pen=\"0.5p\", style=\"c0.21c\")\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_UNC_rab_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lUncertainity\\tof\\tGHF\\t[mW/m@+2@+]\"],\n",
    "                 position=f\"g{str(afr_lon_max +10)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\") \n",
    "        \n",
    "        cmap= pygmt.makecpt(\n",
    "                    cmap='vik', #temp 19lev\n",
    "                    series=f\"-30/30/3\",\n",
    "                    continuous=True,\n",
    "                    reverse=False,\n",
    "                )\n",
    "\n",
    "\n",
    "        '''\n",
    "        fig.plot(x=gt_Afr_ra_lr_lon, y=gt_Afr_ra_lr_lat,   cmap=True, projection=proj,                                \n",
    "                 color=  resid_ra_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"c0.24c\")'''\n",
    "        fig.plot(x=gt_Afr_50_rab_lr_lon, y=gt_Afr_50_rab_lr_lat,   cmap=True, projection=proj,                                \n",
    "                 color=  resid_rab_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"c0.24c\")      \n",
    "        '''\n",
    "        fig.plot(x=lon_hf_extreme_a, y=lat_hf_extreme_a,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "        fig.plot(x=lon_hf_extreme_b, y=lat_hf_extreme_b,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")'''\n",
    "\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lResidual\\tof\\tGHF\\t[mW/m@+2@+]\"],\n",
    "                 position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-7)}+w13c/0.5c+h+e\")\n",
    "        \n",
    "        fig.legend(position=\"g-23/-10\", box=False)\n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_7.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14c5ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_identity(axes, *line_args, **line_kwargs):\n",
    "    identity, = axes.plot([], [], *line_args, **line_kwargs)\n",
    "    def callback(axes):\n",
    "        low_x, high_x = axes.get_xlim()\n",
    "        low_y, high_y = axes.get_ylim()\n",
    "        low = max(low_x, low_y)\n",
    "        high = min(high_x, high_y)\n",
    "        identity.set_data([low, high], [low, high])\n",
    "    callback(axes)\n",
    "    axes.callbacks.connect('xlim_changed', callback)\n",
    "    axes.callbacks.connect('ylim_changed', callback)\n",
    "    return axes\n",
    "\n",
    "KPI_df = pd.DataFrame()\n",
    "\n",
    "#define plotting region (2 rows, 2 columns)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(32,30), dpi=300)\n",
    "\n",
    "# Seaborn setting                                                                                                                                              \n",
    "#sns.set(style='white',  font_scale = 3)\n",
    "\n",
    "sns.set(style='white',  font_scale = 3.5)\n",
    "#parameters = {'axes.labelsize': 35,\n",
    "#          'axes.titlesize': 35}\n",
    "#plt.rcParams.update(parameters)\n",
    "font_size = 30\n",
    "\n",
    "point_size = 150\n",
    "\n",
    "#####\n",
    "errors      = abs(y_test_rab_lr - y_pred_RK_rab_lr)\n",
    "errors_lr     = abs(y_test_rab_lr - y_pred_RF_rab_lr)\n",
    "mape        = round( mean_absolute_percentage_error(y_test_rab_lr, y_pred_RK_rab_lr), 2) \n",
    "accuracy    = round(100 - mape *100, 3)\n",
    "mae         = round(mean_absolute_error(y_test_rab_lr, y_pred_RK_rab_lr ), 1)\n",
    "rmse        = round(mean_squared_error(y_test_rab_lr, y_pred_RK_rab_lr , squared=False), 1)\n",
    "nrmse       = round( rmse/(y_test_rab_lr.mean()) , 2) \n",
    "r2          = round(r2_score(y_test_rab_lr, y_pred_RK_rab_lr ), 2)\n",
    "ev          = round( explained_variance_score(y_test_rab_lr, y_pred_RK_rab_lr), 3)\n",
    "mnae        = round( median_absolute_error(y_test_rab_lr, y_pred_RK_rab_lr), 3) \n",
    "mpe         =  round(np.mean((y_test_rab_lr -y_pred_RK_rab_lr)/y_test_rab_lr) , 3)\n",
    "ccc         = round(concordance_correlation_coefficient(y_test_rab_lr, y_pred_RK_rab_lr),2)\n",
    "bias        = round(y_pred_RK_rab_lr.mean() - y_test_rab_lr.mean(), 2)\n",
    "max_e_rk       = round( max_error(y_test_rab_lr, y_pred_RK_rab_lr), 0)\n",
    "min_e_rk       = round( errors.min(), 3)\n",
    "Max_rk         = round(y_pred_RK_rab_lr.max(), 0)\n",
    "Min_rk         = round(y_pred_RK_rab_lr.min(), 0)\n",
    "\n",
    "rsd         = round(np.std(y_pred_RK_rab_lr) / np.mean(y_pred_RK_rab_lr) ,3)\n",
    "\n",
    "rmse_rl        = round(mean_squared_error(y_test_rab_lr, y_pred_RF_rab_lr , squared=False), 1)\n",
    "max_e_lr      = round( max_error(y_test_rab_lr, y_pred_RF_rab_lr), 0)\n",
    "min_e_lr      = round( errors_lr.min(), 3)\n",
    "Max_lr        = round(y_pred_RF_rab_lr.max(), 0)\n",
    "Min_lr        = round(y_pred_RF_rab_lr.min(), 0)\n",
    "\n",
    "KPI_df.loc['NRMSE', f'RK_{label_rab_lr[0][-9:]}'] = nrmse\n",
    "KPI_df.loc['RMSE', f'RK_{label_rab_lr[0][-9:]}'] = rmse\n",
    "KPI_df.loc['MAE', f'RK_{label_rab_lr[0][-9:]}'] = mae\n",
    "KPI_df.loc['MAPE', f'RK_{label_rab_lr[0][-9:]}'] = mape\n",
    "KPI_df.loc['CD', f'RK_{label_rab_lr[0][-9:]}'] = r2\n",
    "KPI_df.loc['EV', f'RK_{label_rab_lr[0][-9:]}'] = ev\n",
    "KPI_df.loc['MAX_E', f'RK_{label_rab_lr[0][-9:]}'] = max_e\n",
    "KPI_df.loc['MIN_E', f'RK_{label_rab_lr[0][-9:]}'] = min_e\n",
    "KPI_df.loc['MedAE', f'RK_{label_rab_lr[0][-9:]}'] = mnae\n",
    "KPI_df.loc['MPE', f'RK_{label_rab_lr[0][-9:]}'] = mpe\n",
    "KPI_df.loc['ACC', f'RK_{label_rab_lr[0][-9:]}'] = accuracy\n",
    "KPI_df.loc['MAX', f'RK_{label_rab_lr[0][-9:]}'] = Max_rk    \n",
    "KPI_df.loc['RSD', f'RK_{label_rab_lr[0][-9:]}'] = rsd\n",
    "KPI_df.loc['CCC', f'RK_{label_rab_lr[0][-9:]}'] = ccc\n",
    "KPI_df.loc['BIAS', f'RK_{label_rab_lr[0][-9:]}'] = bias\n",
    "\n",
    "KPI_df.loc['RI', f'RK_{label_rab_lr[0][-9:]}'] = (rmse_rl - rmse)/rmse_rl * 100\n",
    "\n",
    "mask = np.abs(y_test_rab_lr - y_pred_RK_rab_lr) > threshold\n",
    "\n",
    "sns.regplot(x=y_pred_RK_rab_lr, y=y_test_rab_lr,    ax= axes[0,0], \n",
    "            line_kws={\"color\": \"k\"} , scatter_kws={ \"edgecolor\":\"w\", 's':point_size, },\n",
    "            \n",
    "             \n",
    "     label=  \n",
    "     f\"\"\"     \n",
    "     $NRMSe$ :   {nrmse} \n",
    "     $R^2$         :   {r2}\n",
    "     $MPe$      :  {mpe}\n",
    "     \"\"\")\n",
    "#$R_i$          :  {round((rmse_rl - rmse)/rmse_rl,3)}\n",
    "add_identity(axes[0,0], color='grey', ls='--')\n",
    "#mn = min(plt.gca().axis()) and mx = max(plt.gca().axis())\n",
    "\n",
    "'''sns.scatterplot(x=y_pred_RK_rab_lr[mask],y=y_test_rab_lr[mask], color=\"red\", \n",
    "                s=point_size,  ax= axes[0,0], edgecolor=\"white\", \n",
    "               #label= \"Mae > 15\"  \n",
    "               )'''\n",
    "axes[0,0].set(xlabel='$\\hat{z}_{KED}$ [$mW/m^{2}$]',ylabel='$z$ [$mW/m^{2}$]')\n",
    "axes[0,0].set_title(f\"{sub_figs[0]})   Observed vs predictions (KED)\", loc ='left', pad=20,   y=1.1)\n",
    "axes[0,0].set_xlim([0, 200])\n",
    "axes[0,0].set_ylim([0, 200])\n",
    "axes[0,0].set_xticks([0, 25, 50, 75, 100, 125, 150, 175, 200])\n",
    "\n",
    "#bbox_to_anchor=(2, 0), \n",
    "axes[0,0].legend( frameon=False,loc=\"lower right\")\n",
    "for lh in axes[0,0].get_legend().legendHandles: \n",
    "    lh._sizes = [0] \n",
    "\n",
    "\n",
    "####\n",
    "mean_lr= \"$\\overline{\\hat{z}}_{RF}$\"\n",
    "median_lr= \"$\\widetilde{\\hat{z}}_{RF}$\"\n",
    "std_lr= \"$s_{\\hat{z}_{RF}}$\"\n",
    "\n",
    "sns.kdeplot(y_pred_RF_rab_lr,  ax =axes[0,1],fill=True, \n",
    "            color=\"orange\", label=f'''\n",
    "{mean_lr} : {round(y_pred_RF_rab_lr.mean(),1)}\n",
    "{median_lr} : {round(np.median(y_pred_RF_rab_lr),1)}\n",
    "{std_lr} : {round(y_pred_RF_rab_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_pred_RF_rab_lr.mean() , c='b')\n",
    "\n",
    "\n",
    "mean_ked = \"$\\overline{\\hat{z}}_{KED}$\"\n",
    "median_ked = \"$\\widetilde{\\hat{z}}_{KED}$\"\n",
    "std_ked = \"$s_{\\hat{z}_{KED}}$\"\n",
    "\n",
    "sns.kdeplot(y_pred_RK_rab_lr,  ax =axes[0,1],fill=True, \n",
    "            color=\"r\", label=f'''\n",
    "{mean_ked} : {round(y_pred_RK_rab_lr.mean(),1)}\n",
    "{median_ked} : {round(np.median(y_pred_RK_rab_lr),1)}\n",
    "{std_ked} : {round(y_pred_RK_rab_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_pred_RK_rab_lr.mean() , c='g')\n",
    "\n",
    "mean_t = \"$\\overline{z}$\"\n",
    "median_t = \"$\\widetilde{z}$\"\n",
    "std_t = \"$s_{z}$\"\n",
    "\n",
    "sns.kdeplot(y_test_rab_lr,  ax =axes[0,1],fill=True, \n",
    "            color=\"b\", label=f'''\n",
    "{mean_t}  : {round(y_test_rab_lr.mean(),1)}\n",
    "{median_t}  : {round(np.median(y_test_rab_lr),1)}\n",
    "{std_t} : {round(y_test_rab_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_test_rab_lr.mean() , c='r')\n",
    "\n",
    "axes[0,1].legend( frameon=False, bbox_to_anchor=(1.15, 1.08))\n",
    "axes[0,1].set_yticks([]) \n",
    "\n",
    "axes[0,1].set(xlabel='GHF [$mW/m^{2}$]',ylabel='PDF' )\n",
    "\n",
    "axes[0,1].set_title(f'{sub_figs[2]})   Density Plots', loc ='left', pad=20,   y=1.1)\n",
    "axes[0,1].set_xticks([0, 25, 50, 75, 100, 125, 150, 175, 200])\n",
    "###\n",
    "     \n",
    "     \n",
    "sns.residplot(  x=y_pred_RF_rab_lr, y=y_test_rab_lr, ax =axes[1,0], \n",
    "              scatter_kws={ \"edgecolor\":\"w\", 's':point_size, },\n",
    "     label=  \n",
    "     f\"\"\"     \n",
    "     $Max$ e : {int(max_e_lr)} \n",
    "     $Max$    : {int(Max_lr)}\n",
    "     $Min$     : {int(Min_lr)}\n",
    "     \"\"\")\n",
    "\n",
    "\n",
    "#plot.ax_joint.axvline(x=6)\n",
    "#axes[1,0].axhline(y=threshold , c='red')\n",
    "#axes[1,0].axhline(y=-threshold , c='red')\n",
    "axes[1,0].legend(frameon=False, loc=\"upper right\")\n",
    "for lh in axes[1,0].get_legend().legendHandles: \n",
    "    lh._sizes = [0] \n",
    "\n",
    "axes[1,0].set(xlabel='$\\hat{z}_{RF}$ [$mW/m^{2}$]',ylabel='Residuals' )\n",
    "axes[1,0].set_title(f'{sub_figs[1]})   Residuals vs predictions (RF)', loc ='left', pad=20,   y=1.1)\n",
    "axes[1,0].set_xticks([0, 25, 50, 75, 100, 125, 150, 175, 200])\n",
    "     \n",
    "sns.residplot(  x=y_pred_RK_rab_lr, y=y_test_rab_lr, ax =axes[1,1], \n",
    "              scatter_kws={ \"edgecolor\":\"w\", 's':point_size, },\n",
    "                  label=  \n",
    "     f\"\"\"     \n",
    "     $Max$ e : {int(max_e_rk)} \n",
    "     $Max$    : {int(Max_rk)}\n",
    "     $Min$     : {int(Min_rk)}\n",
    "     \"\"\")\n",
    "\n",
    "\n",
    "#plot.ax_joint.axvline(x=6)\n",
    "#axes[1,1].axhline(y=threshold , c='red')\n",
    "#axes[1,1].axhline(y=-threshold , c='red')\n",
    "\n",
    "\n",
    "axes[1,1].legend(frameon=False, loc=\"upper right\")\n",
    "for lh in axes[1,1].get_legend().legendHandles: \n",
    "    lh._sizes = [0] \n",
    "    \n",
    "axes[1,1].set(xlabel='$\\hat{z}_{KED}$ [$mW/m^{2}$]',ylabel='Residuals' )\n",
    "axes[1,1].set_title(f'{sub_figs[1]})   Residuals vs predictions (KED)', loc ='left', pad=20,   y=1.1)\n",
    "axes[1,1].set_xticks([0, 25, 50, 75, 100, 125, 150, 175, 200])\n",
    "\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_6.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc0bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "KPI_df = pd.DataFrame()\n",
    "\n",
    "#define plotting region (2 rows, 2 columns)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20,10), dpi=300)\n",
    "\n",
    "# Seaborn setting                                                                                                                                              \n",
    "#sns.set(style='white',  font_scale = 3)\n",
    "\n",
    "sns.set(style='white',  font_scale = 2.2)\n",
    "#parameters = {'axes.labelsize': 35,\n",
    "#          'axes.titlesize': 35}\n",
    "#plt.rcParams.update(parameters)\n",
    "font_size = 30\n",
    "\n",
    "point_size = 150\n",
    "\n",
    "#####\n",
    "errors      = abs(y_test_rab_lr - y_pred_RK_rab_lr)\n",
    "errors_lr     = abs(y_test_rab_lr - y_pred_RF_rab_lr)\n",
    "mape        = round( mean_absolute_percentage_error(y_test_rab_lr, y_pred_RK_rab_lr), 2) \n",
    "accuracy    = round(100 - mape *100, 3)\n",
    "mae         = round(mean_absolute_error(y_test_rab_lr, y_pred_RK_rab_lr ), 1)\n",
    "rmse        = round(mean_squared_error(y_test_rab_lr, y_pred_RK_rab_lr , squared=False), 1)\n",
    "nrmse       = round( rmse/(y_test_rab_lr.mean()) , 2) \n",
    "r2          = round(r2_score(y_test_rab_lr, y_pred_RK_rab_lr ), 2)\n",
    "ev          = round( explained_variance_score(y_test_rab_lr, y_pred_RK_rab_lr), 3)\n",
    "mnae        = round( median_absolute_error(y_test_rab_lr, y_pred_RK_rab_lr), 3) \n",
    "mpe         =  round(np.mean((y_test_rab_lr -y_pred_RK_rab_lr)/y_test_rab_lr) , 3)\n",
    "ccc         = round(concordance_correlation_coefficient(y_test_rab_lr, y_pred_RK_rab_lr),2)\n",
    "bias        = round(y_pred_RK_rab_lr.mean() - y_test_rab_lr.mean(), 2)\n",
    "max_e_rk       = round( max_error(y_test_rab_lr, y_pred_RK_rab_lr), 0)\n",
    "min_e_rk       = round( errors.min(), 3)\n",
    "Max_rk         = round(y_pred_RK_rab_lr.max(), 0)\n",
    "Min_rk         = round(y_pred_RK_rab_lr.min(), 0)\n",
    "\n",
    "rsd         = round(np.std(y_pred_RK_rab_lr) / np.mean(y_pred_RK_rab_lr) ,3)\n",
    "\n",
    "rmse_rl        = round(mean_squared_error(y_test_rab_lr, y_pred_RF_rab_lr , squared=False), 1)\n",
    "max_e_lr      = round( max_error(y_test_rab_lr, y_pred_RF_rab_lr), 0)\n",
    "min_e_lr      = round( errors_lr.min(), 3)\n",
    "Max_lr        = round(y_pred_RF_rab_lr.max(), 0)\n",
    "Min_lr        = round(y_pred_RF_rab_lr.min(), 0)\n",
    "\n",
    "KPI_df.loc['NRMSE', f'RK_{label_rab_lr[0][-9:]}'] = nrmse\n",
    "KPI_df.loc['RMSE', f'RK_{label_rab_lr[0][-9:]}'] = rmse\n",
    "KPI_df.loc['MAE', f'RK_{label_rab_lr[0][-9:]}'] = mae\n",
    "KPI_df.loc['MAPE', f'RK_{label_rab_lr[0][-9:]}'] = mape\n",
    "KPI_df.loc['CD', f'RK_{label_rab_lr[0][-9:]}'] = r2\n",
    "KPI_df.loc['EV', f'RK_{label_rab_lr[0][-9:]}'] = ev\n",
    "KPI_df.loc['MAX_E', f'RK_{label_rab_lr[0][-9:]}'] = max_e\n",
    "KPI_df.loc['MIN_E', f'RK_{label_rab_lr[0][-9:]}'] = min_e\n",
    "KPI_df.loc['MedAE', f'RK_{label_rab_lr[0][-9:]}'] = mnae\n",
    "KPI_df.loc['MPE', f'RK_{label_rab_lr[0][-9:]}'] = mpe\n",
    "KPI_df.loc['ACC', f'RK_{label_rab_lr[0][-9:]}'] = accuracy\n",
    "KPI_df.loc['MAX', f'RK_{label_rab_lr[0][-9:]}'] = Max_rk    \n",
    "KPI_df.loc['RSD', f'RK_{label_rab_lr[0][-9:]}'] = rsd\n",
    "KPI_df.loc['CCC', f'RK_{label_rab_lr[0][-9:]}'] = ccc\n",
    "KPI_df.loc['BIAS', f'RK_{label_rab_lr[0][-9:]}'] = bias\n",
    "\n",
    "KPI_df.loc['RI', f'RK_{label_rab_lr[0][-9:]}'] = (rmse_rl - rmse)/rmse_rl * 100\n",
    "\n",
    "mask = np.abs(y_test_rab_lr - y_pred_RK_rab_lr) > threshold\n",
    "\n",
    "sns.regplot(x=y_pred_RK_rab_lr, y=y_test_rab_lr,    ax= axes[0], \n",
    "            line_kws={\"color\": \"k\"} , scatter_kws={ \"edgecolor\":\"w\", 's':point_size, },\n",
    "            \n",
    "             \n",
    "     label=  \n",
    "     f\"\"\"     \n",
    "     $NRMSe$ :   {nrmse} \n",
    "     $R^2$         :   {r2}\n",
    "     $MPe$      : {mpe}\n",
    "     $R_i$          :  {round((rmse_rl - rmse)/rmse_rl,3)}\n",
    "     \"\"\")\n",
    "\n",
    "add_identity(axes[0], color='r', ls='--')\n",
    "#mn = min(plt.gca().axis()) and mx = max(plt.gca().axis())\n",
    "\n",
    "'''sns.scatterplot(x=y_pred_RK_rab_lr[mask],y=y_test_rab_lr[mask], color=\"red\", \n",
    "                s=point_size,  ax= axes[0], edgecolor=\"white\", \n",
    "               #label= \"Mae > 15\"  \n",
    "               )'''\n",
    "axes[0].set(xlabel='$\\hat{y}_{KED}$ [$mW/m^{2}$]',ylabel='$y$ [$mW/m^{2}$]')\n",
    "axes[0].set_title(f\"{sub_figs[0]})   Observed vs KED\", loc ='left', pad=20,   y=1.1)\n",
    "axes[0].set_xlim([0, 200])\n",
    "axes[0].set_ylim([0, 200])\n",
    "\n",
    "\n",
    "#bbox_to_anchor=(2, 0), \n",
    "axes[0].legend( frameon=False,loc=\"lower right\")\n",
    "for lh in axes[0].get_legend().legendHandles: \n",
    "    lh._sizes = [0] \n",
    "\n",
    "\n",
    "####\n",
    "mean_lr= \"$\\overline{\\hat{z}}_{RF}$\"\n",
    "median_lr= \"$\\widetilde{\\hat{z}}_{RF}$\"\n",
    "std_lr= \"$s_{\\hat{z}_{RF}}$\"\n",
    "\n",
    "sns.kdeplot(y_pred_RF_rab_lr,  ax =axes[1],fill=True, \n",
    "            color=\"orange\", label=f'''\n",
    "{mean_lr} : {round(y_pred_RF_rab_lr.mean(),1)}\n",
    "{median_lr} : {round(np.median(y_pred_RF_rab_lr),1)}\n",
    "{std_lr} : {round(y_pred_RF_rab_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_pred_RF_rab_lr.mean() , c='b')\n",
    "\n",
    "\n",
    "mean_ked = \"$\\overline{\\hat{z}}_{KED}$\"\n",
    "median_ked = \"$\\widetilde{\\hat{z}}_{KED}$\"\n",
    "std_ked = \"$s_{\\hat{z}_{KED}}$\"\n",
    "\n",
    "sns.kdeplot(y_pred_RK_rab_lr,  ax =axes[1],fill=True, \n",
    "            color=\"r\", label=f'''\n",
    "{mean_ked} : {round(y_pred_RK_rab_lr.mean(),1)}\n",
    "{median_ked} : {round(np.median(y_pred_RK_rab_lr),1)}\n",
    "{std_ked} : {round(y_pred_RK_rab_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_pred_RK_rab_lr.mean() , c='g')\n",
    "\n",
    "mean_t = \"$\\overline{z}$\"\n",
    "median_t = \"$\\widetilde{z}$\"\n",
    "std_t = \"$s_{z}$\"\n",
    "\n",
    "sns.kdeplot(y_test_rab_lr,  ax =axes[1],fill=True, \n",
    "            color=\"b\", label=f'''\n",
    "{mean_t}  : {round(y_test_rab_lr.mean(),1)}\n",
    "{median_t}  : {round(np.median(y_test_rab_lr),1)}\n",
    "{std_t} : {round(y_test_rab_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_test_rab_lr.mean() , c='r')\n",
    "\n",
    "axes[1].legend( frameon=False, bbox_to_anchor=(1.15, 1.08))\n",
    "\n",
    "axes[1].set(xlabel='GHF [$mW/m^{2}$]',ylabel='PDF' )\n",
    "axes[1].set_title(f'{sub_figs[1]})   Density Plots', loc ='left', pad=20,   y=1.1)\n",
    "     \n",
    "axes[1].set_yticks([]) \n",
    "\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "#fig.savefig(dir_p/'fig'/\"fig_p6.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04db3951",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'Afr_50'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "file_rfe = '04'\n",
    "\n",
    "\n",
    "label_ra_lr = [ label for label in labels_RK_ra_lr if file_rfe in label]\n",
    "\n",
    "\n",
    "label_rab_lr = [ label for label in labels_RK_rab_lr if file_rfe in label]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Afr_50_Q_RK_rab_lr_04 = pd.DataFrame(grids[region].ds[f'RK_{label_rab_lr[0][-6:]}'].T.values.reshape(-1,1))\n",
    "\n",
    "Afr_50_Q_RK_ra_lr_04 = pd.DataFrame(grids[region].ds[f'RK_{label_ra_lr[0][-5:]}'].T.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lon = pd.DataFrame(grids[region].lon.T.reshape(-1,1))\n",
    "lat = pd.DataFrame(grids[region].lat.T.reshape(-1,1))\n",
    "\n",
    "df_Afr_50_rab_lr_04 = pd.concat([lon, lat, Afr_50_Q_RK_rab_lr_04, \n",
    "                          ] , axis=1).dropna()\n",
    "df_Afr_50_rab_lr_04.columns = ['lon', 'lat','Q_RK', ]\n",
    "\n",
    "\n",
    "df_Afr_50_ra_lr_04 = pd.concat([lon, lat, Afr_50_Q_RK_ra_lr_04, \n",
    "                          ] , axis=1).dropna()\n",
    "df_Afr_50_ra_lr_04.columns = ['lon', 'lat','Q_RK', ]\n",
    "\n",
    "\n",
    "\n",
    "df_Afr_50_RK_rab_lr_04 = df_Afr_50_rab_lr_04[['lon', 'lat','Q_RK']]\n",
    "data_RK_rab_lr_04 = df_Afr_50_RK_rab_lr_04.values\n",
    "\n",
    "df_Afr_50_RK_ra_lr_04 = df_Afr_50_ra_lr_04[['lon', 'lat','Q_RK']]\n",
    "data_RK_ra_lr_04 = df_Afr_50_RK_ra_lr_04.values\n",
    "\n",
    "\n",
    "df_Afr_50_Diff_rab_lr_04 = df_Afr_50_rab_lr_04[['lon', 'lat']]\n",
    "df_Afr_50_Diff_rab_lr_04['Q_Diff'] = df_Afr_50_rab_lr['Q_RK'] - df_Afr_50_rab_lr_04['Q_RK']\n",
    "data_Diff_rab_lr_04 =  df_Afr_50_Diff_rab_lr_04.values \n",
    "\n",
    "df_Afr_50_Diff_ra_lr_04 = df_Afr_50_ra_lr_04[['lon', 'lat']]\n",
    "df_Afr_50_Diff_ra_lr_04['Q_Diff'] = df_Afr_50_rab_lr['Q_RK'] - df_Afr_50_ra_lr_04['Q_RK']\n",
    "data_Diff_ra_lr_04 =  df_Afr_50_Diff_ra_lr_04.values \n",
    "\n",
    "\n",
    "#####\n",
    "\n",
    "\n",
    "\n",
    "file_rfe = '16'\n",
    "\n",
    "\n",
    "label_ra_lr = [ label for label in labels_RK_ra_lr if file_rfe in label]\n",
    "\n",
    "\n",
    "label_rab_lr = [ label for label in labels_RK_rab_lr if file_rfe in label]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Afr_50_Q_RK_rab_lr_16 = pd.DataFrame(grids[region].ds[f'RK_{label_rab_lr[0][-6:]}'].T.values.reshape(-1,1))\n",
    "\n",
    "Afr_50_Q_RK_ra_lr_16 = pd.DataFrame(grids[region].ds[f'RK_{label_ra_lr[0][-5:]}'].T.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lon = pd.DataFrame(grids[region].lon.T.reshape(-1,1))\n",
    "lat = pd.DataFrame(grids[region].lat.T.reshape(-1,1))\n",
    "\n",
    "df_Afr_50_rab_lr_16 = pd.concat([lon, lat, Afr_50_Q_RK_rab_lr_16, \n",
    "                          ] , axis=1).dropna()\n",
    "df_Afr_50_rab_lr_16.columns = ['lon', 'lat','Q_RK', ]\n",
    "\n",
    "df_Afr_50_ra_lr_16 = pd.concat([lon, lat, Afr_50_Q_RK_ra_lr_16, \n",
    "                          ] , axis=1).dropna()\n",
    "df_Afr_50_ra_lr_16.columns = ['lon', 'lat','Q_RK', ]\n",
    "\n",
    "df_Afr_50_RK_rab_lr_16 = df_Afr_50_rab_lr_16[['lon', 'lat','Q_RK']]\n",
    "data_RK_rab_lr_16 = df_Afr_50_RK_rab_lr_16.values\n",
    "\n",
    "df_Afr_50_RK_ra_lr_16 = df_Afr_50_ra_lr_16[['lon', 'lat','Q_RK']]\n",
    "data_RK_ra_lr_16 = df_Afr_50_RK_ra_lr_16.values\n",
    "\n",
    "\n",
    "df_Afr_50_Diff_rab_lr_16 = df_Afr_50_rab_lr_16[['lon', 'lat']]\n",
    "df_Afr_50_Diff_rab_lr_16['Q_Diff'] = df_Afr_50_rab_lr['Q_RK'] - df_Afr_50_rab_lr_16['Q_RK']\n",
    "data_Diff_rab_lr_16 =  df_Afr_50_Diff_rab_lr_16.values \n",
    "\n",
    "df_Afr_50_Diff_ra_lr_16 = df_Afr_50_ra_lr_16[['lon', 'lat']]\n",
    "df_Afr_50_Diff_ra_lr_16['Q_Diff'] = df_Afr_50_rab_lr['Q_RK'] - df_Afr_50_ra_lr_16['Q_RK']\n",
    "data_Diff_ra_lr_16 =  df_Afr_50_Diff_ra_lr_16.values \n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "\n",
    "file_rfe = '09'\n",
    "\n",
    "\n",
    "label_ra_lr = [ label for label in labels_RK_ra_lr if file_rfe in label]\n",
    "\n",
    "\n",
    "label_rab_lr = [ label for label in labels_RK_rab_lr if file_rfe in label]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Afr_50_Q_RK_rab_lr_09 = pd.DataFrame(grids[region].ds[f'RK_{label_rab_lr[0][-6:]}'].T.values.reshape(-1,1))\n",
    "\n",
    "Afr_50_Q_RK_ra_lr_09 = pd.DataFrame(grids[region].ds[f'RK_{label_ra_lr[0][-5:]}'].T.values.reshape(-1,1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lon = pd.DataFrame(grids[region].lon.T.reshape(-1,1))\n",
    "lat = pd.DataFrame(grids[region].lat.T.reshape(-1,1))\n",
    "\n",
    "df_Afr_50_rab_lr_09 = pd.concat([lon, lat, Afr_50_Q_RK_rab_lr_09, \n",
    "                          ] , axis=1).dropna()\n",
    "df_Afr_50_rab_lr_09.columns = ['lon', 'lat','Q_RK', ]\n",
    "\n",
    "df_Afr_50_ra_lr_09 = pd.concat([lon, lat, Afr_50_Q_RK_ra_lr_09, \n",
    "                          ] , axis=1).dropna()\n",
    "df_Afr_50_ra_lr_09.columns = ['lon', 'lat','Q_RK', ]\n",
    "\n",
    "\n",
    "df_Afr_50_RK_rab_lr_09 = df_Afr_50_rab_lr_09[['lon', 'lat','Q_RK']]\n",
    "data_RK_rab_lr_09 = df_Afr_50_RK_rab_lr_09.values\n",
    "\n",
    "df_Afr_50_RK_ra_lr_09 = df_Afr_50_ra_lr_09[['lon', 'lat','Q_RK']]\n",
    "data_RK_ra_lr_09 = df_Afr_50_RK_ra_lr_09.values\n",
    "\n",
    "\n",
    "df_Afr_50_Diff_rab_lr_09 = df_Afr_50_rab_lr_09[['lon', 'lat']]\n",
    "df_Afr_50_Diff_rab_lr_09['Q_Diff'] = df_Afr_50_rab_lr['Q_RK'] - df_Afr_50_rab_lr_09['Q_RK']\n",
    "data_Diff_rab_lr_09 =  df_Afr_50_Diff_rab_lr_09.values \n",
    "\n",
    "df_Afr_50_Diff_ra_lr_09 = df_Afr_50_ra_lr_09[['lon', 'lat']]\n",
    "df_Afr_50_Diff_ra_lr_09['Q_Diff'] = df_Afr_50_rab_lr['Q_RK'] - df_Afr_50_ra_lr_09['Q_RK']\n",
    "data_Diff_ra_lr_09 =  df_Afr_50_Diff_ra_lr_09.values \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267cd4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=4,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['A)+o0.3/-1.2'],\n",
    "    margins=[\"0.18c\", \"1c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    #####Kriging\n",
    "    with fig.set_panel(panel=[0, 0]):\n",
    "\n",
    "\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/ 'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='WNse', panel=[0, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_ra_lr_04, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w12c/0.5c+h+e\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", shorelines=\"1p,black\",\n",
    "            borders=[\"1/0.2p,black\"],\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    "   \n",
    "    with fig.set_panel(panel=[0, 1] ):\n",
    "        #####RL\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='broc', #temp 19lev\n",
    "            series=f\"-20/20/1\",\n",
    "            continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='ENsw',  panel=[0, 1])\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_Diff_ra_lr_04, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w12c/0.5c+h+e\")\n",
    "    \n",
    "\n",
    "    with fig.set_panel(panel=[1, 0]):\n",
    "\n",
    "\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj,  panel=[1, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_ra_lr_09, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w12c/0.5c+h+e\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    "   \n",
    "    with fig.set_panel(panel=[1, 1] ):\n",
    "        #####RL\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='broc', #temp 19lev\n",
    "            series=f\"-20/20/1\",\n",
    "            continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj,   panel=[1, 1])\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_Diff_ra_lr_09, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w12c/0.5c+h+e\")\n",
    "            \n",
    "    with fig.set_panel(panel=[2, 0]):\n",
    "\n",
    "\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='WSne',  panel=[2, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_ra_lr_16, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-8)}+w13c/0.5c+h+e\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    "   \n",
    "    with fig.set_panel(panel=[2, 1] ):\n",
    "        #####RL\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='broc', #temp 19lev\n",
    "            series=f\"-20/20/1\",\n",
    "            continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='ESnw',  panel=[2, 1])\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_Diff_ra_lr_16, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-8)}+w13c/0.5c+h+e\")\n",
    "            \n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_s6.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=4,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['A)+o0.3/-1.2'],\n",
    "    margins=[\"0.18c\", \"1c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    #####Kriging\n",
    "    with fig.set_panel(panel=[0, 0]):\n",
    "\n",
    "\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/ 'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='WNse', panel=[0, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rab_lr_04, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w12c/0.5c+h+e\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    "   \n",
    "    with fig.set_panel(panel=[0, 1] ):\n",
    "        #####RL\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='broc', #temp 19lev\n",
    "            series=f\"-20/20/1\",\n",
    "            continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='ENsw',  panel=[0, 1])\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_Diff_rab_lr_04, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w12c/0.5c+h+e\")\n",
    "    \n",
    "\n",
    "    with fig.set_panel(panel=[1, 0]):\n",
    "\n",
    "\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj,  panel=[1, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rab_lr_09, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w12c/0.5c+h+e\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    "   \n",
    "    with fig.set_panel(panel=[1, 1] ):\n",
    "        #####RL\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='broc', #temp 19lev\n",
    "            series=f\"-20/20/1\",\n",
    "            continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj,   panel=[1, 1])\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_Diff_rab_lr_09, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w12c/0.5c+h+e\")\n",
    "            \n",
    "    with fig.set_panel(panel=[2, 0]):\n",
    "\n",
    "\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='WSne',  panel=[2, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rab_lr_16, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-8)}+w13c/0.5c+h+e\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    "   \n",
    "    with fig.set_panel(panel=[2, 1] ):\n",
    "        #####RL\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='broc', #temp 19lev\n",
    "            series=f\"-20/20/1\",\n",
    "            continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='ESnw',  panel=[2, 1])\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_Diff_rab_lr_16, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-8)}+w13c/0.5c+h+e\")\n",
    "            \n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_s8.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "\n",
    "    \n",
    "    \n",
    "tectonics_shp_main = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename in ['CC.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', ]]\n",
    "labels_main = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "              if filename in ['CC.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt']]\n",
    "\n",
    "tectonics_shp_sub = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename not in ['CC.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt',]\n",
    "                    and 'gmt' in filename]\n",
    "labels_sub = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics') \n",
    "             if filename not in ['CC.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt',]\n",
    "             and 'gmt' in filename]\n",
    "\n",
    "volc_erup = pd.read_csv(dir_p/'GMT'/'tectonics'/'volcanic_eruptions.dat', sep='\\s')\n",
    "\n",
    "\n",
    "# congo co KA kalhari\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=1,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['C)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"0c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    #sharex=\"bt\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    #frame=\"WSrt\",\n",
    "):\n",
    "\n",
    "\n",
    "    cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/130',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "    \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame=True,  panel=[0, 0])\n",
    "       \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"A Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"c0.2c\")\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"B Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"t0.22c\")        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"C Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"s0.22c\")   \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"D Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"d0.22c\")  \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='white', label=f'\"Z Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"h0.22c\") \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rab_lr, region=region_gmt, spacing=spacing)\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region_gmt,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             frame=True,\n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            #water=\"lightblue\", \n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #land='darkgrey'\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "        \n",
    "        \n",
    "        for shape, label in zip(tectonics_shp_sub, labels_sub):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1,white,--')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "            #fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, font='15' ,text=label, justify=\"ML\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        for shape, label in zip(tectonics_shp_main, labels_main):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1.5,white')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "                \n",
    "            \n",
    "      \n",
    "        fig.plot(x=volc_erup.Lon, y=volc_erup.Lat,  projection=proj,\n",
    "             color='white', label=f'\"Volcanoes\"',\n",
    "                      pen=\"0.5p\", style=\"a0.25c\")\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        fig.plot(x=hf_final_a.lon, y=hf_final_a.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_a[target], #label=f\"'A Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_b.lon, y=hf_final_b.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_b[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"t0.19c\")\n",
    "        fig.plot(x=hf_final_c.lon, y=hf_final_c.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_c[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"s0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_d.lon, y=hf_final_d.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_d[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"d0.19c\")\n",
    "        fig.plot(x=hf_final_z_afr.longitude, y=hf_final_z_afr.latitude,   cmap=True, projection=proj,\n",
    "             color=hf_final_z_afr[target], #label=\"'C Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"h0.21c\")\n",
    "        '''\n",
    "        fig.plot(x=hf_no_pole_afr.longitude.values, y=hf_no_pole_afr.latitude.values,  \n",
    "                 cmap=True, projection=proj,\n",
    "             color=hf_no_pole_afr[target].values, #label=\"'C Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.16c\")\n",
    "        \n",
    "        fig.plot(x=lon_hf_extreme , y=lat_hf_extreme ,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "        \n",
    "        \n",
    "        fig.text(text=\"_\", x=-19, y=-4, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Major Cratons\", x=-8, y=-4, font=\"13p,Helvetica,black\")\n",
    "        fig.text(text=\"KA : Kalhari Cr.\", x=-11, y=-7, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"CC : Congo Cr.\", x=-11, y=-10, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"RTA :\", x=-11, y=-13, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"BB :\", x=-8, y=-16, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"WAC : W. African Cr.\", x=-7, y=-19, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"SMC : Sah. Metacr.\", x=-8, y=-22, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"AAO :\", x=-8, y=-25, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"--\", x=-19, y=-28, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Minor Cratons\", x=-8, y=-28, font=\"14p,Helvetica,black\") \n",
    "\n",
    "       \n",
    "        cmap= pygmt.makecpt(\n",
    "                    cmap='vik', #temp 19lev\n",
    "                    series=f\"-30/30/3\",\n",
    "                    continuous=True,\n",
    "                    reverse=False,\n",
    "                )\n",
    "\n",
    "       \n",
    "        fig.plot(x=gt_Afr_50_rb_lr_lon, y=gt_Afr_50_rb_lr_lat,   cmap=True, projection=proj,\n",
    "                             size= 0.5 * abs((resid_rb_lr-resid_rb_lr.min())/(resid_rb_lr.max() - resid_rb_lr.min())),    \n",
    "                 color=  resid_rb_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"cc\")'''\n",
    "\n",
    "   \n",
    "\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\", \"x+lGHF\\t[mW/m@+2@+]\\t\\t(Lucazeau,\\t2019)\"], \n",
    "                     position=f\"g{str(afr_lon_max +10)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "    \n",
    "        labels = [ 'KA', \n",
    "                  'NNB', 'KC', 'BB', 'TC', 'ASZ', 'ZC', 'RB']\n",
    "        starts = [[8,-18], \n",
    "                  [8,-31],[35,-32],[47,-10],[47,-5],[46,0], [40,-20],[8,-25]]   \n",
    "        \n",
    "        starts_labels = [ [4,-18], \n",
    "                         [2,-31],[36,-32], [48,-10],[47,-5],[46,0], [40,-20],[4,-25],]   \n",
    "        \n",
    "        ends = [[16,-22], \n",
    "                [23,-31],[32,-27], [32,-6], [34,0], [35,10], [32,-17],[21,-24]]\n",
    "        \n",
    "        for start, end, label ,starts_label in zip(starts, ends, labels, starts_labels):\n",
    "            style = \"=0.3c+s+e+a30+gblue+h0.3+p0.3p,blue\"\n",
    "            data = np.array([start + end])\n",
    "            fig.plot(data=data, style=style, pen=\"1.0p,blue\")\n",
    "\n",
    "            fig.text(\n",
    "                text=label, x=starts_label[0], y=starts_label[1], \n",
    "                font=\"13p,Helvetica-Bold,white\" ,  justify=\"ML\"\n",
    "            )\n",
    "            \n",
    "        labels = [ 'WAC', 'SMC','CC', 'AAO', 'KB', \n",
    "                  'AC', 'CG']\n",
    "        starts_labels = [[-14,25],  [20,26], [18,0],[-8.2,37.3],[23.4,-5], \n",
    "                         [14,-11], [10, 7],]  \n",
    "        for label ,starts_label in zip(labels, starts_labels):\n",
    "            fig.text(\n",
    "                    text=label, x=starts_label[0], y=starts_label[1],  \n",
    "                    font=\"13p,Helvetica-Bold,white\" ,  justify=\"ML\"\n",
    "                )\n",
    "       \n",
    "\n",
    "\n",
    "        #fig.legend(position=\"g29.1/40+w4.7/1\", box='+gwhite', transparency=30)\n",
    "        fig.legend(position=\"g-23/-18\", box=False)\n",
    "\n",
    "   \n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_s9.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "\n",
    "    \n",
    "tectonics_shp_main = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "labels_main = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "              if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "\n",
    "tectonics_shp_sub = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "                    and 'gmt' in filename]\n",
    "labels_sub = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics') \n",
    "             if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "             and 'gmt' in filename]\n",
    "\n",
    "volc_erup = pd.read_csv(dir_p/'GMT'/'tectonics'/'volcanic_eruptions.dat', sep='\\s')\n",
    "# congo co KA kalhari\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=1,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['C)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"0c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    #sharex=\"bt\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    #frame=\"WSrt\",\n",
    "):\n",
    "\n",
    "\n",
    "    cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/130',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "    \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame=True,  panel=[0, 0])\n",
    "       \n",
    "        ''' \n",
    "        fig.plot(x=0, y=0,  projection=proj, cmap=False,\n",
    "              label='\"Residual GHF\"',\n",
    "                      pen=\"0.5p\", style=\"c0.21c\")\n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='green', label='\"GHF > 200\\t[mW/m@+2@+]\"',\n",
    "                      pen=\"0.5p\", style=\"t0.24c\")'''\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rab_lr, region=region_gmt, spacing=spacing)\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region_gmt,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             frame=True,\n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        for shape, label in zip(tectonics_shp_sub, labels_sub):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1,white,--')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "            #fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, font='15' ,text=label, justify=\"ML\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        for shape, label in zip(tectonics_shp_main, labels_main):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1.5,white')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "                \n",
    "            if label == 'RTA':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()-10, y=shape_xy.iloc[:,1].median()+0.5, \n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            elif label == 'AAO':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()+2, y=shape_xy.iloc[:,1].median()+2,\n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            elif label == 'BB':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()-3, y=shape_xy.iloc[:,1].median(),\n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "\n",
    "            else:\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, \n",
    "                         font='15' ,text=label, justify=\"ML\")'''\n",
    "        '''\n",
    "        fig.plot(x=volc_erup.Lon, y=volc_erup.Lat,  projection=proj,\n",
    "             color='white', label=f'\"Eruptions\"',\n",
    "                      pen=\"0.5p\", style=\"a0.25c\")'''\n",
    "        \n",
    "\n",
    "\n",
    "        '''\n",
    "        fig.plot(x=hf_final_a.lon, y=hf_final_a.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_a[target], #label=f\"'A Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_b.lon, y=hf_final_b.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_b[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        fig.plot(x=hf_final_c.lon, y=hf_final_c.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_c[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_d.lon, y=hf_final_d.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_d[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        '''\n",
    "        fig.plot(x=hf_no_pole_afr.longitude.values, y=hf_no_pole_afr.latitude.values,  \n",
    "                 cmap=True, projection=proj,\n",
    "             color=hf_no_pole_afr[target].values, #label=\"'C Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.16c\")\n",
    "        '''\n",
    "        fig.plot(x=lon_hf_extreme , y=lat_hf_extreme ,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "        \n",
    "        \n",
    "        fig.text(text=\"_\", x=-19, y=-4, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Major Cratons\", x=-8, y=-4, font=\"13p,Helvetica,black\")\n",
    "        fig.text(text=\"KA : Kalhari Cr.\", x=-11, y=-7, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"CC : Congo Cr.\", x=-11, y=-10, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"RTA :\", x=-11, y=-13, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"BB :\", x=-8, y=-16, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"WAC : W. African Cr.\", x=-7, y=-19, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"SMC : Sah. Metacr.\", x=-8, y=-22, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"AAO :\", x=-8, y=-25, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"--\", x=-19, y=-28, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Minor Cratons\", x=-8, y=-28, font=\"14p,Helvetica,black\") '''   \n",
    "\n",
    "        '''\n",
    "        cmap= pygmt.makecpt(\n",
    "                    cmap='vik', #temp 19lev\n",
    "                    series=f\"-30/30/3\",\n",
    "                    continuous=True,\n",
    "                    reverse=False,\n",
    "                )'''\n",
    "\n",
    "        '''\n",
    "        fig.plot(x=gt_Afr_50_rb_lr_lon, y=gt_Afr_50_rb_lr_lat,   cmap=True, projection=proj,\n",
    "                             size= 0.5 * abs((resid_rb_lr-resid_rb_lr.min())/(resid_rb_lr.max() - resid_rb_lr.min())),    \n",
    "                 color=  resid_rb_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"cc\")'''\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            #water=\"lightblue\", \n",
    "            #water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #land='darkgrey'\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\", \"x+lGHF\\t[mW/m@+2@+]\\t\\t(Lucazeau,\\t2019)\"], \n",
    "                     position=f\"g{str(afr_lon_max +10)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        #fig.legend(position=\"g29.1/40+w4.7/1\", box='+gwhite', transparency=30)\n",
    "        #fig.legend(position=\"g-23/0+w4.7/1\", box='+gwhite', transparency=30)\n",
    "\n",
    "   \n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_s10.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309dcdc0",
   "metadata": {},
   "source": [
    "# RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93839246",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "# Set figure size and create barplot\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "best_features = 11\n",
    "\n",
    "# Load hyper parameter \n",
    "\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X, y).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X[selected_features],y)\n",
    "\n",
    "obs_cp = obs.copy()\n",
    "obs_selected = obs_cp.set_index('OBS_REF_IDW')\n",
    "\n",
    "\n",
    "selected_labels = obs_selected.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"observable\"])\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "\n",
    "feature_importance.set_index('observable', inplace=True)\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "\n",
    "sns.barplot(x = feature_importance[\"Relative Importance\"], \n",
    "            y = feature_importance[\"Relative Importance\"].index,\n",
    "            palette = reversed(sns.color_palette('YlOrRd', best_features)))\n",
    "\n",
    "\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "#fig.savefig(dir_p/'fig'/\"presentation\" /\"fig_p2b.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba89fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#region = 'Afr_50'\n",
    "\n",
    "region = 'Afr_50'\n",
    "\n",
    "files = [filename for filename in os.listdir(dir_p/'Grids'/'inputs') \n",
    "         if filename.startswith(f\"{region}\") and 'LN' not in filename]\n",
    "labels = [ filename.replace(f'{region}_', '').replace('.nc', '')  for filename in files]\n",
    "\n",
    "paths = [dir_p/'Grids'/'inputs'/f'{file}' for file in files]\n",
    "\n",
    "paths\n",
    "\n",
    "obs['PATHS']  = None\n",
    "#obs.loc['Path'] \n",
    "\n",
    "obs_cp = obs.copy()\n",
    "obs_cp.set_index('OBS_AFR_IDW', inplace=True, drop=True)\n",
    "for file in files:\n",
    "    for index in obs_cp.index:\n",
    "        if index in file:\n",
    "            obs_cp.loc[index,'PATHS'] = dir_p/'Grids'/'inputs'/f'{file}'\n",
    "            #print(file)\n",
    "            print(index)\n",
    "\n",
    "\n",
    "\n",
    "obs_cp = obs_cp.reset_index()\n",
    "####\n",
    "\n",
    "obs_cp.set_index('LABELS', inplace=True, drop=True)\n",
    "\n",
    "reduced_datsets = obs_cp.loc[feature_importance['Relative Importance'].index, :]\n",
    "reduced_datsets = reduced_datsets.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b768f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'Afr_50'\n",
    "#region = 'Afr'\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "\n",
    "\n",
    "files = [filename for filename in os.listdir(dir_p/'Grids'/'inputs') if filename.startswith(f\"{region}\")]\n",
    "labels = [ filename.replace(f'{region}_', '').replace('.nc', '')  for filename in files]\n",
    "for label, file in zip(labels,files):\n",
    "    path = dir_p/'Grids'/'inputs'/f'{file}'\n",
    "    grids[region].ds[f'{label}'] = (('Y', 'X'), grids[region].read_raster(path , src_crs=src_crs))\n",
    "    print(label)\n",
    "print('terminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1431f251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_figs = list('abcdefghijklmnopqrstuvwxyz')\n",
    "\n",
    "#spacing = \"0.5\"\n",
    "#region = 'Afr_50'\n",
    "\n",
    "spacing = \"0.5\"\n",
    "region = 'Afr_50'\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "frames = ['wNes', 'wNes','wNEs','Wnes', 'wnes', 'wnes','wnEs','WneS', 'wneS', 'wneS','wnES','wnES']\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "\n",
    "pygmt.config(FONT='25p')\n",
    "\n",
    "with fig.subplot(\n",
    "    nrows=6,\n",
    "    ncols=4,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    autolabel=['A)+o0.3/-1.5'],\n",
    "    margins=[\"0c\", \"2.7c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    #sharex=\"bt\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    #frame=\"WSrt\",\n",
    "):\n",
    "\n",
    "    with fig.set_panel(panel=0):\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "            #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame='WNes', panel=0)\n",
    "\n",
    "        '''\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rg_lr, region=region_gmt, spacing=spacing)\n",
    "        \n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "        \n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region_gmt,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )'''\n",
    "        \n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            land='darkgrey'\n",
    "            #borders=[\"1/0.5p,black\"],\n",
    "            #water='white',\n",
    "            \n",
    "            )\n",
    "        '''\n",
    "        for shape, label in zip(tectonics_shp_main, labels):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj, \n",
    "                     region=region_gmt,   pen='3,black')      \n",
    "                              #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "                #fig.text(x=shape_xy.iloc[0,0], y=shape_xy.iloc[0,1],  text=label, justify=\"ML\")\n",
    "        '''\n",
    "        fig.plot(x=hf_final_a.lon, y=hf_final_a.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_a[target], #label=f\"'A Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        fig.plot(x=hf_final_b.lon, y=hf_final_b.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_b[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        fig.colorbar(frame=[\"af\", f\"x+lGHF\\t\\t[mW/m@+2@+]\"], \n",
    "                     position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-8.2)}+w12c/0.5c+h+e\")\n",
    "    \n",
    "\n",
    "    for path, cmap_i, grid_label, v_range, label_i ,unit, importance, panel,  in zip(\n",
    "        reduced_datsets['PATHS'], reduced_datsets['CMAPS'],  reduced_datsets['OBS_AFR_IDW'],\n",
    "                    reduced_datsets['V_RANGE_AFR'], reduced_datsets['observable'],\n",
    "        reduced_datsets['UNITS'], feature_importance['Relative Importance'],\n",
    "        list(range(len(reduced_datsets)))):\n",
    "        ''' \n",
    "        for path, cmap_i, grid_label, v_range, label_i ,unit,  panel in zip(\n",
    "            obs['PATHS'], obs['CMAPS'], obs['OBS_AFR_IDW'],\n",
    "                        obs['V_RANGE_AFR'], obs['LABELS'],\n",
    "            obs['UNITS'],  list(range(len(obs)))):'''\n",
    "        \n",
    "        data_z = pd.DataFrame(grids[region].ds[grid_label].T.values.reshape(-1,1))\n",
    "        lon = pd.DataFrame(grids[region].lon.T.reshape(-1,1))\n",
    "        lat = pd.DataFrame(grids[region].lat.T.reshape(-1,1))\n",
    "\n",
    "        data_grid_df = pd.concat([lon, lat, data_z], axis=1).dropna()\n",
    "        data_grid_df.columns = [0,1,2]\n",
    "       \n",
    "        print(label_i)\n",
    "        if grid_label == 'REG':\n",
    "            data_grid_df = data_grid_df.drop(data_grid_df[data_grid_df[2] <= 0].index)\n",
    "            data_grid_df = data_grid_df.drop(data_grid_df[data_grid_df[2] >= 7].index)\n",
    "        if grid_label == 'GliM':\n",
    "            data_grid_df = data_grid_df.drop(data_grid_df[data_grid_df[2] <= 0].index)\n",
    "            data_grid_df = data_grid_df.drop(data_grid_df[data_grid_df[2] >= 17].index)\n",
    "        data_grid = data_grid_df.values\n",
    "        \n",
    "        with fig.set_panel(panel=panel+1):\n",
    "            if cmap_i =='bilbao':\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]}',\n",
    "                #continuous=True,\n",
    "                reverse=True,\n",
    "                )\n",
    "            elif unit == 'class':\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]+1}/1',\n",
    "                categorical=list(range(v_range[0],v_range[1]+1)),\n",
    "                #continuous=True,\n",
    "                )\n",
    "            elif grid_label in ['SV_SPEED_IDW', 'PV_SPEED_IDW']:\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{data_z.min()[0]}/{data_z.max()[0]}',\n",
    "                #continuous=True,\n",
    "                reverse=False,\n",
    "                )\n",
    "            elif grid_label == 'EMAG2':\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]}',\n",
    "                #continuous=True,\n",
    "                reverse=False,\n",
    "                )\n",
    "            else:\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]}',\n",
    "                #continuous=True,\n",
    "                reverse=False,\n",
    "                )\n",
    "                \n",
    "\n",
    "      \n",
    "            #data_xyz = pygmt.grd2xyz(grid=path, region=region_gmt,  spacing=spacing)\n",
    "            #data_grd = pygmt.xyz2grd(x=data_xyz['y'], y=data_xyz['x'], z=data_xyz['z'], region=region_gmt,  spacing=spacing)\n",
    "\n",
    "            fig.basemap(region=region_gmt, projection=proj, frame=frames[panel], panel=panel+1)\n",
    "\n",
    "            if unit == 'class':\n",
    "                #df_gmt = pygmt.nearneighbor(data=data_grid,region=region_gmt,search_radius='40k', spacing=spacing)\n",
    "\n",
    "                df_gmt = pygmt.blockmedian(data=data_grid,region=region_gmt, spacing=spacing)\n",
    "\n",
    "                grd = pygmt.surface(\n",
    "                                     data=df_gmt, # xarray.DataArray containing VSV values\n",
    "                                spacing=spacing\n",
    "                ).round(0)\n",
    "\n",
    "                dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "                #dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "                fig.grdimage(\n",
    "                     grid=grd, # xarray.DataArray containing VSV values\n",
    "                     region=region_gmt,\n",
    "                     projection=proj,\n",
    "                         cmap=cmap,\n",
    "                     \n",
    "                    #shading='+a45+nt0.5'\n",
    "                    shading=dgrid\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                df_gmt = pygmt.blockmean(data=data_grid,region=region_gmt, spacing=spacing)\n",
    "                \n",
    "                if grid_label == 'EMAG2':\n",
    "                    grd = pygmt.xyz2grd(data=data_grid,region=region_gmt, nodata=-99999,\n",
    "                            projection=proj, spacing=spacing)\n",
    "                else:\n",
    "\n",
    "                    grd = pygmt.surface(\n",
    "                         data=df_gmt, # xarray.DataArray containing VSV values\n",
    "                    spacing=spacing\n",
    "                    )\n",
    "\n",
    "                dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "                fig.grdimage(\n",
    "                     grid=grd, # xarray.DataArray containing VSV values\n",
    "                     region=region_gmt,\n",
    "                     projection=proj,\n",
    "                         cmap=cmap,\n",
    "                     \n",
    "                    #shading='+a45+nt0.5'\n",
    "                    shading=dgrid\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "            fig.coast(\n",
    "                projection=proj,\n",
    "                #shorelines=0.5,\n",
    "                water=\"lightblue\", \n",
    "                shorelines=\"0.1p,black\",\n",
    "                borders=[\"1/0.1p,black\"],\n",
    "                lakes=\"lightblue\",\n",
    "                rivers=\"lightblue\" ,\n",
    "                #borders=[\"1/0.5p,black\"],\n",
    "                #water='white',\n",
    "                )\n",
    "            '''\n",
    "            for shape, label in zip(tectonics_shp_main, labels):\n",
    "\n",
    "                shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "                if label_i in ['Bouguer', 'GliM', 'Lith. ρ'] :\n",
    "                        fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj, \n",
    "                                 region=region_gmt,   pen='3,white')   \n",
    "                else:\n",
    "                    fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj, \n",
    "                                 region=region_gmt,   pen='3,black')   '''\n",
    "                                  #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "                    #fig.text(x=shape_xy.iloc[0,0], y=shape_xy.iloc[0,1],  text=label, justify=\"ML\")\n",
    "\n",
    "            print(f'{importance} {label_i}')\n",
    "            fig.colorbar(frame=[\"af\", f'x+l\"{label_i}\"\\t\\t\"[{unit}]\"\\t\\t({str(round(importance*100,1))}\\%)',\n",
    "                                ],\n",
    "                    position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-8.2)}+w12c/0.5c+h+e\")\n",
    "            \n",
    "            #fig.colorbar(frame=[\"af\",],\n",
    "             #      position=f\"g{str(afr_lon_min)}/{str(afr_lat_min-7)}+w11c/0.5c+h\")\n",
    "            #fig.text(x=afr_lon_min + 5, y=afr_lat_min-9, \n",
    "            #text=f\"{label_i}  ({round(importance*100,1)}\\%)\", justify=\"ML\")\n",
    "\n",
    "   \n",
    "    \n",
    "    #### RK \n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"fig_3.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edbb34",
   "metadata": {},
   "source": [
    "# presenatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_figs = list('abcdefghijklmnopqrstuvwxyz')\n",
    "\n",
    "#spacing = \"0.5\"\n",
    "#region = 'Afr_50'\n",
    "\n",
    "spacing = \"0.5\"\n",
    "region = 'Afr_50'\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pygmt.config(FONT='25p')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for path, cmap_i, grid_label, v_range, label_i ,unit, importance, panel,  in zip(\n",
    "    reduced_datsets['PATHS'], reduced_datsets['CMAPS'],  reduced_datsets['OBS_AFR_IDW'],\n",
    "                reduced_datsets['V_RANGE_AFR'], reduced_datsets['observable'],\n",
    "    reduced_datsets['UNITS'], feature_importance['Relative Importance'],\n",
    "    list(range(len(reduced_datsets)))):\n",
    "    fig = pygmt.Figure()\n",
    "    with fig.subplot(\n",
    "    nrows=1,\n",
    "    ncols=1,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['A)+o0.3/-1.5'],\n",
    "    margins=[\"0c\", \"2.7c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    #sharex=\"bt\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    #frame=\"WSrt\",\n",
    "    ):\n",
    "\n",
    "\n",
    "        data_z = pd.DataFrame(grids[region].ds[grid_label].T.values.reshape(-1,1))\n",
    "        lon = pd.DataFrame(grids[region].lon.T.reshape(-1,1))\n",
    "        lat = pd.DataFrame(grids[region].lat.T.reshape(-1,1))\n",
    "\n",
    "        data_grid_df = pd.concat([lon, lat, data_z], axis=1).dropna()\n",
    "        data_grid_df.columns = [0,1,2]\n",
    "\n",
    "        print(label_i)\n",
    "        if grid_label == 'REG':\n",
    "            data_grid_df = data_grid_df.drop(data_grid_df[data_grid_df[2] <= 0].index)\n",
    "            data_grid_df = data_grid_df.drop(data_grid_df[data_grid_df[2] >= 7].index)\n",
    "        if grid_label == 'GliM':\n",
    "            data_grid_df = data_grid_df.drop(data_grid_df[data_grid_df[2] <= 0].index)\n",
    "            data_grid_df = data_grid_df.drop(data_grid_df[data_grid_df[2] >= 17].index)\n",
    "        data_grid = data_grid_df.values\n",
    "\n",
    "        with fig.set_panel(panel=0):\n",
    "            if cmap_i =='bilbao':\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]}',\n",
    "                #continuous=True,\n",
    "                reverse=True,\n",
    "                )\n",
    "            elif unit == 'class':\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]+1}/1',\n",
    "                categorical=list(range(v_range[0],v_range[1]+1)),\n",
    "                #continuous=True,\n",
    "                )\n",
    "            elif grid_label in ['SV_SPEED_IDW', 'PV_SPEED_IDW']:\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{data_z.min()[0]}/{data_z.max()[0]}',\n",
    "                #continuous=True,\n",
    "                reverse=False,\n",
    "                )\n",
    "            elif grid_label == 'EMAG2':\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]}',\n",
    "                #continuous=True,\n",
    "                reverse=False,\n",
    "                )\n",
    "            else:\n",
    "                cmap = pygmt.makecpt(\n",
    "                cmap=cmap_i, #temp 19lev\n",
    "                series=f'{v_range[0]}/{v_range[1]}',\n",
    "                #continuous=True,\n",
    "                reverse=False,\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "            #data_xyz = pygmt.grd2xyz(grid=path, region=region_gmt,  spacing=spacing)\n",
    "            #data_grd = pygmt.xyz2grd(x=data_xyz['y'], y=data_xyz['x'], z=data_xyz['z'], region=region_gmt,  spacing=spacing)\n",
    "\n",
    "            fig.basemap(region=region_gmt, projection=proj, frame='WSne',  panel=0)\n",
    "\n",
    "            if unit == 'class':\n",
    "                #df_gmt = pygmt.nearneighbor(data=data_grid,region=region_gmt,search_radius='40k', spacing=spacing)\n",
    "\n",
    "                df_gmt = pygmt.blockmedian(data=data_grid,region=region_gmt, spacing=spacing)\n",
    "\n",
    "                grd = pygmt.surface(\n",
    "                                     data=df_gmt, # xarray.DataArray containing VSV values\n",
    "                                spacing=spacing\n",
    "                ).round(0)\n",
    "\n",
    "                dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "                #dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "                fig.grdimage(\n",
    "                     grid=grd, # xarray.DataArray containing VSV values\n",
    "                     region=region_gmt,\n",
    "                     projection=proj,\n",
    "                         cmap=cmap,\n",
    "\n",
    "                    #shading='+a45+nt0.5'\n",
    "                    shading=dgrid\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                df_gmt = pygmt.blockmean(data=data_grid,region=region_gmt, spacing=spacing)\n",
    "\n",
    "                if grid_label == 'EMAG2':\n",
    "                    grd = pygmt.xyz2grd(data=data_grid,region=region_gmt, nodata=-99999,\n",
    "                            projection=proj, spacing=spacing)\n",
    "                else:\n",
    "\n",
    "                    grd = pygmt.surface(\n",
    "                         data=df_gmt, # xarray.DataArray containing VSV values\n",
    "                    spacing=spacing\n",
    "                    )\n",
    "\n",
    "                dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "                fig.grdimage(\n",
    "                     grid=grd, # xarray.DataArray containing VSV values\n",
    "                     region=region_gmt,\n",
    "                     projection=proj,\n",
    "                         cmap=cmap,\n",
    "\n",
    "                    #shading='+a45+nt0.5'\n",
    "                    shading=dgrid\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "            fig.coast(\n",
    "                projection=proj,\n",
    "                #shorelines=0.5,\n",
    "                water=\"lightblue\", \n",
    "                shorelines=\"0.1p,black\",\n",
    "                borders=[\"1/0.1p,black\"],\n",
    "                lakes=\"lightblue\",\n",
    "                rivers=\"lightblue\" ,\n",
    "                #water='white',\n",
    "                )\n",
    "            '''\n",
    "            for shape, label in zip(tectonics_shp_main, labels):\n",
    "\n",
    "                shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "                if label_i in ['Bouguer', 'GliM', 'Lith. ρ'] :\n",
    "                        fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj, \n",
    "                                 region=region_gmt,   pen='3,white')   \n",
    "                else:\n",
    "                    fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj, \n",
    "                                 region=region_gmt,   pen='3,black')   '''\n",
    "                                  #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "                    #fig.text(x=shape_xy.iloc[0,0], y=shape_xy.iloc[0,1],  text=label, justify=\"ML\")\n",
    "\n",
    "            fig.colorbar(frame=[\"af\", f'x+l\"{label_i}\"\\t\\t\"[{unit}]\"\\t\\t({str(round(importance*100,1))}\\%)',\n",
    "                                ],\n",
    "                     position=f\"g{str(afr_lon_max +14)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "\n",
    "            #fig.colorbar(frame=[\"af\",],\n",
    "             #      position=f\"g{str(afr_lon_min)}/{str(afr_lat_min-7)}+w11c/0.5c+h\")\n",
    "            #fig.text(x=afr_lon_min + 5, y=afr_lat_min-9, \n",
    "            #text=f\"{label_i}  ({round(importance*100,1)}\\%)\", justify=\"ML\")\n",
    "\n",
    "\n",
    "\n",
    "    #### RK \n",
    "\n",
    "            fig.show(width=800)\n",
    "\n",
    "            fig.savefig(dir_p/'fig'/'presentation'/f\"fig_p16_{panel}.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd83704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "\n",
    "    \n",
    "tectonics_shp_main = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "labels_main = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "              if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "\n",
    "tectonics_shp_sub = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "                    and 'gmt' in filename]\n",
    "labels_sub = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics') \n",
    "             if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "             and 'gmt' in filename]\n",
    "\n",
    "volc_erup = pd.read_csv(dir_p/'GMT'/'tectonics'/'volcanic_eruptions.dat', sep='\\s')\n",
    "# congo co KA kalhari\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=2,\n",
    "    ncols=3,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['A)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"0.6c\"], # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame='WnSe', panel=[0, 0])\n",
    "\n",
    "\n",
    "        '''\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"A Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"c0.21c\")\n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "            cmap=False, label=f'\"B Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"t0.23c\")   \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"C Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"s0.23c\") \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"D Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"d0.23c\") \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"Z Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"h0.23c\") \n",
    "        '''\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            land='darkgrey'\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "                    \n",
    "           \n",
    "\n",
    "\n",
    "        '''\n",
    "        fig.plot(x=hf_final_a.lon, y=hf_final_a.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_a[target], #label=f\"'A Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"c0.21c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_b.lon, y=hf_final_b.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_b[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"t0.23c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_c.lon, y=hf_final_c.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_c[target], #label=\"'C Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"s0.23c\") \n",
    "        \n",
    "        fig.plot(x=hf_final_d.lon, y=hf_final_d.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_d[target], #label=\"'C Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"d0.23c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_d.lon, y=hf_final_d.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_d[target], #label=\"'C Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"h0.23c\")\n",
    "        '''\n",
    "        fig.colorbar(frame=[\"af\", \"x+lGHF\\t[mW/m@+2@+]\\t\\t(Lucazeau,\\t2019)\"], \n",
    "                     position=f\"g{str(afr_lon_max +10)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "\n",
    "\n",
    "\n",
    "    fig.legend(position=\"g-19/-11\", box=False)\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/'presentation'/\"fig_p1a.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf67ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=2,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['A)+o0.3/-1.2'],\n",
    "    #margins=[\"0.18c\", \"0.6c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "    \n",
    "    \n",
    "    cmap= pygmt.makecpt(\n",
    "          cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "    \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RF\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj,  frame='WnSe', panel=[0, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rab_lr, region=region, spacing=spacing)\n",
    "        #df_gmt = pygmt.blockmean(data=data_RK_rab_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "\n",
    "        fig.colorbar(frame=[\"af\", \"y+lGHF\\t[mW/m@+2@+]\"],\n",
    "                 position=f\"g{str(afr_lon_max +14)}/{str(afr_lat_min+1)}+w14.5c/0.5c+v+e\")\n",
    "                 \n",
    "    '''\n",
    "    #####Kriging\n",
    "    with fig.set_panel(panel=[0, 0]):\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='vik', #temp 19lev\n",
    "            series=f\"-15/15/1\",\n",
    "            continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='nSeW', panel=[0, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_OK_rab_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "                water=\"lightblue\", \n",
    "                shorelines=\"0.1p,black\",\n",
    "                borders=[\"1/0.1p,black\"],\n",
    "                lakes=\"lightblue\",\n",
    "                rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "        #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        #fig.colorbar(frame=[\"af\",  \"y+l[mW/m@+2@+]\"], \n",
    "                 #    position=f\"g{str(afr_lon_min+2)}/{str(afr_lat_min-6)}+w11c/0.5c+h+e\")\n",
    "        fig.colorbar(frame=[\"af\", \"y+lGHF\\t[mW/m@+2@+]\"],\n",
    "                     position=f\"g{str(afr_lon_max +14)}/{str(afr_lat_min+1)}+w14.5c/0.5c+v+e\")\n",
    "\n",
    "        '''\n",
    "    \n",
    "   \n",
    "    ###\n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/'presentation'/\"fig_p4c.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badd948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max, afr_lat_min, afr_lat_max]\n",
    "\n",
    "    \n",
    "tectonics_shp_main = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename in ['CC.gmt', 'WAC.gmt',  'KA.gmt', ]]\n",
    "labels_main = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "              if filename in ['CC.gmt', 'WAC.gmt',  'KA.gmt']]\n",
    "\n",
    "tectonics_shp_sub = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename not in ['CC.gmt', 'WAC.gmt',  'KA.gmt',]\n",
    "                    and 'gmt' in filename]\n",
    "labels_sub = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics') \n",
    "             if filename not in ['CC.gmt', 'WAC.gmt', 'KA.gmt',]\n",
    "             and 'gmt' in filename]\n",
    "\n",
    "volc_erup = pd.read_csv(dir_p/'GMT'/'tectonics'/'volcanic_eruptions.dat', sep='\\s')\n",
    "# congo co KA kalhari\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=2,\n",
    "    ncols=3,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['A)+o0.3/-1.2'],\n",
    "    #margins=[\"0c\", \"0.6c\"], # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame='WneS',  panel=[0, 0])\n",
    "        \n",
    "        '''\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='green', label='\"GHF > 200\\t[mW/m@+2@+]\"',\n",
    "                      pen=\"0.5p\", style=\"t0.24c\")\n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj, cmap=False,\n",
    "              label='\"Residual\"',\n",
    "                      pen=\"0.5p\", style=\"c0.21c\")\n",
    "                \n",
    "        '''\n",
    "        \n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rab_lr, region=region_gmt, spacing=spacing)\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region_gmt,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             frame=True,\n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "        \n",
    "        ''' \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False,label=f'\"A Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"c0.2c\")\n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"B Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"c0.19c\") \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"C Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"s0.22c\")  \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"D Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"d0.22c\")        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"Z Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"h0.22c\") \n",
    "        \n",
    "        fig.plot(x=volc_erup.Lon, y=volc_erup.Lat,  projection=proj,\n",
    "             color='white', label=f'\"Volcanoes\"',\n",
    "                      pen=\"0.5p\", style=\"a0.25c\")\n",
    "        '''\n",
    "        \n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        fig.plot(x=hf_final_a_afr.longitude, y=hf_final_a_afr.latitude,  cmap=True, projection=proj,\n",
    "             color=hf_final_a_afr[target], transparency =30,\n",
    "                      pen=\"0.1p,black\", style=\"c0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_b_afr.longitude, y=hf_final_b_afr.latitude,  cmap=True, projection=proj,\n",
    "             color=hf_final_b_afr[target], transparency =30,\n",
    "                      pen=\"0.1p,black\", style=\"c0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_c_afr.longitude, y=hf_final_c_afr.latitude,   cmap=True, projection=proj,\n",
    "             color=hf_final_c_afr[target], transparency =30,\n",
    "                      pen=\"0.1p,black\", style=\"s0.19c\")\n",
    "        fig.plot(x=hf_final_d_afr.longitude, y=hf_final_d_afr.latitude,   cmap=True, projection=proj,\n",
    "             color=hf_final_d_afr[target],transparency =30,\n",
    "                      pen=\"0.1p,black\", style=\"d0.19c\")\n",
    "        fig.plot(x=hf_final_z_afr.longitude, y=hf_final_z_afr.latitude,   cmap=True, projection=proj,\n",
    "             color=hf_final_z_afr[target], transparency =30,\n",
    "                      pen=\"0.1p,black\", style=\"h0.19c\")\n",
    "        \n",
    "        \n",
    "        for shape, label in zip(tectonics_shp_main, labels_main):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj, \n",
    "            region=region_gmt,   pen='1.5,white')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "            \n",
    "            if label =='KC':\n",
    "                fig.text(x=shape_xy.iloc[:,0].mean()-1, y=shape_xy.iloc[:,1].mean(), \n",
    "                         font='15,white' ,text=label, justify=\"ML\")\n",
    "            elif label =='WAC':\n",
    "                fig.text(x=shape_xy.iloc[:,0].mean()-5, y=shape_xy.iloc[:,1].mean()+6, \n",
    "                         font='15,white' ,text=label, justify=\"ML\")\n",
    "            else:\n",
    "                fig.text(x=shape_xy.iloc[:,0].mean()-1, y=shape_xy.iloc[:,1].mean()+6, \n",
    "                             font='15,white' ,text=label, justify=\"ML\")\n",
    "        \n",
    "        '''\n",
    "        for shape, label in zip(tectonics_shp_sub, labels_sub):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj, \n",
    "                     region=region_gmt,   pen='1.5,white,..-')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "            #fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, font='15' ,text=label, justify=\"ML\")\n",
    "            '''\n",
    "            if label == 'ZC_1':\n",
    "                fig.text(x=shape_xy.iloc[:,0].mean()-1, y=shape_xy.iloc[:,1].mean()+4,\n",
    "                         font='11,white' ,text='ZC', justify=\"ML\")\n",
    "            elif label == 'ZC_2':\n",
    "                fig.text(x=shape_xy.iloc[:,0].mean()-1, y=shape_xy.iloc[:,1].mean()+4,\n",
    "                         font='11,white' ,text='ZC', justify=\"ML\")\n",
    "\n",
    "            elif label == 'AAO':\n",
    "                fig.text(x=shape_xy.iloc[:,0].mean()-3, y=shape_xy.iloc[:,1].mean()+9,\n",
    "                         font='11,white' ,text='AAO', justify=\"ML\")\n",
    "            elif label == 'NNB':\n",
    "                fig.text(x=shape_xy.iloc[:,0].mean()-3, y=shape_xy.iloc[:,1].mean()+2,\n",
    "                         font='11,white' ,text='NNB', justify=\"ML\")\n",
    "                \n",
    "            elif label == 'RTA':\n",
    "                fig.text(x=shape_xy.iloc[:,0].mean()-18, y=shape_xy.iloc[:,1].max()+2.5,\n",
    "                         font='11,white' ,text='RTA', justify=\"ML\")\n",
    "            else:\n",
    "                fig.text(x=shape_xy.iloc[:,0].mean()-1, y=shape_xy.iloc[:,1].mean()+4, \n",
    "                         font='11,white' ,text=label, justify=\"ML\")\n",
    "        \n",
    "        \n",
    "        fig.text(text=\"_\", x=-15, y=-17, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Major Cratons\", x=-4.1, y=-17.3, font=\"12.5p,Helvetica,black\")\n",
    "        \n",
    "        fig.text(text=\"..\", x=-15, y=-19.5, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Cratonic Blocks\", x=-3.5, y=-19.5, font=\"12.5p,Helvetica,black\")\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='vik', #temp 19lev\n",
    "            series=f\"-30/30/3\",\n",
    "            continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        fig.plot(x=gt_Afr_50_ra_lr_lon, y=gt_Afr_50_ra_lr_lat,   cmap=True, projection=proj,\n",
    "                 color=  resid_ra_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"c0.21c\")\n",
    "        \n",
    "        \n",
    "        fig.plot(x=gt_Afr_50_rb_lr_lon, y=gt_Afr_50_rb_lr_lat,   cmap=True, projection=proj,\n",
    "                 color=  resid_rb_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"c0.21c\")\n",
    "        \n",
    "        fig.plot(x=lon_hf_extreme_a, y=lat_hf_extreme_a,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "        fig.plot(x=lon_hf_extreme_b, y=lat_hf_extreme_b,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "        \n",
    "\n",
    "        '''\n",
    "        fig.colorbar(frame=[\"af\",\"y+lGHF\\t[mW/m@+2@+]\"], \n",
    "                position=f\"g{str(afr_lon_max +14)}/{str(afr_lat_min+1)}+w14.5c/0.5c+v+e\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig.legend(position=\"g-20/-17\", box=False)\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/'presentation'/\"fig_p5i.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6d98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "KPI_df = pd.DataFrame()\n",
    "\n",
    "#define plotting region (2 rows, 2 columns)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20,10), dpi=300)\n",
    "\n",
    "# Seaborn setting                                                                                                                                              \n",
    "#sns.set(style='white',  font_scale = 3)\n",
    "\n",
    "sns.set(style='white',  font_scale = 2.2)\n",
    "#parameters = {'axes.labelsize': 35,\n",
    "#          'axes.titlesize': 35}\n",
    "#plt.rcParams.update(parameters)\n",
    "font_size = 30\n",
    "\n",
    "point_size = 150\n",
    "\n",
    "#####\n",
    "errors      = abs(y_test_rab_lr - y_pred_RK_rab_lr)\n",
    "errors_lr     = abs(y_test_rab_lr - y_pred_RF_rab_lr)\n",
    "mape        = round( mean_absolute_percentage_error(y_test_rab_lr, y_pred_RK_rab_lr), 2) \n",
    "accuracy    = round(100 - mape *100, 3)\n",
    "mae         = round(mean_absolute_error(y_test_rab_lr, y_pred_RK_rab_lr ), 1)\n",
    "rmse        = round(mean_squared_error(y_test_rab_lr, y_pred_RK_rab_lr , squared=False), 1)\n",
    "nrmse       = round( rmse/(y_test_rab_lr.mean()) , 2) \n",
    "r2          = round(r2_score(y_test_rab_lr, y_pred_RK_rab_lr ), 2)\n",
    "ev          = round( explained_variance_score(y_test_rab_lr, y_pred_RK_rab_lr), 3)\n",
    "mnae        = round( median_absolute_error(y_test_rab_lr, y_pred_RK_rab_lr), 3) \n",
    "mpe         =  round(np.mean((y_test_rab_lr -y_pred_RK_rab_lr)/y_test_rab_lr) , 3)\n",
    "ccc         = round(concordance_correlation_coefficient(y_test_rab_lr, y_pred_RK_rab_lr),2)\n",
    "bias        = round(y_pred_RK_rab_lr.mean() - y_test_rab_lr.mean(), 2)\n",
    "max_e_rk       = round( max_error(y_test_rab_lr, y_pred_RK_rab_lr), 0)\n",
    "min_e_rk       = round( errors.min(), 3)\n",
    "Max_rk         = round(y_pred_RK_rab_lr.max(), 0)\n",
    "Min_rk         = round(y_pred_RK_rab_lr.min(), 0)\n",
    "\n",
    "rsd         = round(np.std(y_pred_RK_rab_lr) / np.mean(y_pred_RK_rab_lr) ,3)\n",
    "\n",
    "rmse_rl        = round(mean_squared_error(y_test_rab_lr, y_pred_RF_rab_lr , squared=False), 1)\n",
    "max_e_lr      = round( max_error(y_test_rab_lr, y_pred_RF_rab_lr), 0)\n",
    "min_e_lr      = round( errors_lr.min(), 3)\n",
    "Max_lr        = round(y_pred_RF_rab_lr.max(), 0)\n",
    "Min_lr        = round(y_pred_RF_rab_lr.min(), 0)\n",
    "\n",
    "KPI_df.loc['NRMSE', f'RK_{label_rab_lr[0][-9:]}'] = nrmse\n",
    "KPI_df.loc['RMSE', f'RK_{label_rab_lr[0][-9:]}'] = rmse\n",
    "KPI_df.loc['MAE', f'RK_{label_rab_lr[0][-9:]}'] = mae\n",
    "KPI_df.loc['MAPE', f'RK_{label_rab_lr[0][-9:]}'] = mape\n",
    "KPI_df.loc['CD', f'RK_{label_rab_lr[0][-9:]}'] = r2\n",
    "KPI_df.loc['EV', f'RK_{label_rab_lr[0][-9:]}'] = ev\n",
    "KPI_df.loc['MAX_E', f'RK_{label_rab_lr[0][-9:]}'] = max_e\n",
    "KPI_df.loc['MIN_E', f'RK_{label_rab_lr[0][-9:]}'] = min_e\n",
    "KPI_df.loc['MedAE', f'RK_{label_rab_lr[0][-9:]}'] = mnae\n",
    "KPI_df.loc['MPE', f'RK_{label_rab_lr[0][-9:]}'] = mpe\n",
    "KPI_df.loc['ACC', f'RK_{label_rab_lr[0][-9:]}'] = accuracy\n",
    "KPI_df.loc['MAX', f'RK_{label_rab_lr[0][-9:]}'] = Max_rk    \n",
    "KPI_df.loc['RSD', f'RK_{label_rab_lr[0][-9:]}'] = rsd\n",
    "KPI_df.loc['CCC', f'RK_{label_rab_lr[0][-9:]}'] = ccc\n",
    "KPI_df.loc['BIAS', f'RK_{label_rab_lr[0][-9:]}'] = bias\n",
    "\n",
    "KPI_df.loc['RI', f'RK_{label_rab_lr[0][-9:]}'] = (rmse_rl - rmse)/rmse_rl * 100\n",
    "\n",
    "mask = np.abs(y_test_rab_lr - y_pred_RK_rab_lr) > threshold\n",
    "\n",
    "sns.regplot(x=y_pred_RK_rab_lr, y=y_test_rab_lr,    ax= axes[0], \n",
    "            line_kws={\"color\": \"k\"} , scatter_kws={ \"edgecolor\":\"w\", 's':point_size, },\n",
    "            \n",
    "             \n",
    "     label=  \n",
    "     f\"\"\"     \n",
    "     $NRMSe$ :   {nrmse} \n",
    "     $R^2$         :   {r2}\n",
    "     $MPe$      : {mpe}\n",
    "     $R_i$          :  {round((rmse_rl - rmse)/rmse_rl,3)}\n",
    "     \"\"\")\n",
    "\n",
    "add_identity(axes[0], color='r', ls='--')\n",
    "#mn = min(plt.gca().axis()) and mx = max(plt.gca().axis())\n",
    "\n",
    "'''sns.scatterplot(x=y_pred_RK_rab_lr[mask],y=y_test_rab_lr[mask], color=\"red\", \n",
    "                s=point_size,  ax= axes[0], edgecolor=\"white\", \n",
    "               #label= \"Mae > 15\"  \n",
    "               )'''\n",
    "axes[0].set(xlabel='$\\hat{y}_{KED}$ [$mW/m^{2}$]',ylabel='$y$ [$mW/m^{2}$]')\n",
    "#axes[0].set_title(f\"{sub_figs[0]})   Observed vs KED\", loc ='left', pad=20,   y=1.1)\n",
    "axes[0].set_xlim([0, 200])\n",
    "axes[0].set_ylim([0, 200])\n",
    "\n",
    "\n",
    "#bbox_to_anchor=(2, 0), \n",
    "axes[0].legend( frameon=False,loc=\"lower right\")\n",
    "for lh in axes[0].get_legend().legendHandles: \n",
    "    lh._sizes = [0] \n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "\n",
    "mean_lr= \"$\\overline{\\hat{z}}_{RF}$\"\n",
    "median_lr= \"$\\widetilde{\\hat{z}}_{RF}$\"\n",
    "std_lr= \"$s_{\\hat{z}_{RF}}$\"\n",
    "\n",
    "sns.kdeplot(y_pred_RF_rab_lr,  ax =axes[1],fill=True, \n",
    "            color=\"orange\", label=f'''\n",
    "{mean_lr} : {round(y_pred_RF_rab_lr.mean(),1)}\n",
    "{median_lr} : {round(np.median(y_pred_RF_rab_lr),1)}\n",
    "{std_lr} : {round(y_pred_RF_rab_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_pred_RF_rab_lr.mean() , c='b')\n",
    "\n",
    "\"\"\" \n",
    "mean_ked = \"$\\overline{\\hat{z}}_{KED}$\"\n",
    "median_ked = \"$\\widetilde{\\hat{z}}_{KED}$\"\n",
    "std_ked = \"$s_{\\hat{z}_{KED}}$\"\n",
    "\n",
    "sns.kdeplot(y_pred_RK_rab_lr,  ax =axes[1],fill=True, \n",
    "            color=\"r\", label=f'''\n",
    "{mean_ked} : {round(y_pred_RK_rab_lr.mean(),1)}\n",
    "{median_ked} : {round(np.median(y_pred_RK_rab_lr),1)}\n",
    "{std_ked} : {round(y_pred_RK_rab_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_pred_RK_rab_lr.mean() , c='g')\n",
    "\"\"\"\n",
    "\n",
    "mean_t = \"$\\overline{z}$\"\n",
    "median_t = \"$\\widetilde{z}$\"\n",
    "std_t = \"$s_{z}$\"\n",
    "\n",
    "sns.kdeplot(y_test_rab_lr,  ax =axes[1],fill=True, \n",
    "            color=\"b\", label=f'''\n",
    "{mean_t}  : {round(y_test_rab_lr.mean(),1)}\n",
    "{median_t}  : {round(np.median(y_test_rab_lr),1)}\n",
    "{std_t} : {round(y_test_rab_lr.std(),1)}\n",
    "                            ''')\n",
    "#axes[0,1].axvline(x=y_test_rab_lr.mean() , c='r')\n",
    "\n",
    "axes[1].legend( frameon=False, bbox_to_anchor=(1.15, 1.08))\n",
    "\n",
    "axes[1].set(xlabel='GHF [$mW/m^{2}$]',ylabel='PDF' )\n",
    "#axes[1].set_title(f'{sub_figs[1]})   Density Plots', loc ='left', pad=20,   y=1.1)\n",
    "     \n",
    "axes[1].set_yticks([]) \n",
    "\n",
    "plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"presentation\" /\"fig_p6a.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3f720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "# Set figure size and create barplot\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "file_label = 'OD_IDW_rab'\n",
    "tarin_Afr_f =  dir_p/ 'data'/'dataset'/'Preprocessed'/f'Training_Afr_{file_label}.csv'\n",
    "\n",
    "\n",
    "train = pd.read_csv(tarin_Afr_f, sep='\\t')\n",
    "\n",
    "\n",
    "X = train[features_idw] \n",
    "y = train[target]\n",
    "\n",
    "X['GLIM']  = X['GLIM'].astype('int').astype('category')\n",
    "X['REG']  = X['REG'].astype('int').astype('category')\n",
    "\n",
    "file_label  = 'OD_IDW_rab'\n",
    "bs_rfr_hyp =  dir_p/'RF_Hyperparameters'/f'RFR_{file_label}.csv'\n",
    "\n",
    "\n",
    "bs_rfr_hyp_df = pd.read_csv(bs_rfr_hyp, sep='\\t')\n",
    "\n",
    "\n",
    "best_params = bs_rfr_hyp_df.to_dict('list')\n",
    "\n",
    "# Load hyper parameter \n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X, y).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X[selected_features],y)\n",
    "\n",
    "obs_selected = obs.set_index('OBS_REF_IDW')\n",
    "\n",
    "#obs.reset_index(inplace=True)\n",
    "selected_labels = obs_selected.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"observable\"])\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "\n",
    "feature_importance.set_index('observable', inplace=True)\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "'''feature_importance['Relative Importance RV'] = 0\n",
    "#feature_importance.loc[selected_labels[12:14], 'NRMSe RV'] = feature_importance.loc[selected_labels[12:14],'NRMSe']\n",
    "\n",
    "feature_importance.iloc[12:, 1] = feature_importance.iloc[12:, 0]'''\n",
    "\n",
    "\n",
    "sns.barplot(x = feature_importance[\"Relative Importance\"], \n",
    "            y = feature_importance[\"Relative Importance\"].index,\n",
    "            palette = reversed(sns.color_palette('YlOrRd', best_features)))\n",
    "\n",
    "'''sns.barplot(x = feature_importance[\"Relative Importance RV\"], \n",
    "            y = feature_importance[\"Relative Importance RV\"].index,\n",
    "            color='grey')'''\n",
    "\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('score')\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"presentation\" /\"fig_p2bb.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d91b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "# Set figure size and create barplot\n",
    "sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "best_features = 12\n",
    "\n",
    "tarin_Afr_f =  dir_p/ 'data'/'dataset'/'Preprocessed'/f'Training_Afr_50_{file_label}.csv'\n",
    "\n",
    "\n",
    "train = pd.read_csv(tarin_Afr_f, sep='\\t')\n",
    "\n",
    "\n",
    "X = train[features_idw] \n",
    "y = train[target]\n",
    "\n",
    "X['GLIM']  = X['GLIM'].astype('int').astype('category')\n",
    "X['REG']  = X['REG'].astype('int').astype('category')\n",
    "\n",
    "file_label  = 'OD_IDW_rab'\n",
    "bs_rfr_hyp =  dir_p/'RF_Hyperparameters'/f'RFR_{file_label}.csv'\n",
    "\n",
    "\n",
    "bs_rfr_hyp_df = pd.read_csv(bs_rfr_hyp, sep='\\t')\n",
    "\n",
    "\n",
    "best_params = bs_rfr_hyp_df.to_dict('list')\n",
    "\n",
    "# Load hyper parameter \n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X, y).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X[selected_features],y)\n",
    "\n",
    "obs_selected = obs.set_index('OBS_REF_IDW')\n",
    "\n",
    "#obs.reset_index(inplace=True)\n",
    "selected_labels = obs_selected.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance_RV = pd.DataFrame(selected_labels, columns = [\"observable\"])\n",
    "feature_importance_RV[\"Relative Importance\"] = regressor.feature_importances_\n",
    "\n",
    "feature_importance_RV.set_index('observable', inplace=True)\n",
    "# Sort by feature importance\n",
    "feature_importance_RV = feature_importance_RV.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "'''feature_importance['Relative Importance RV'] = 0\n",
    "#feature_importance.loc[selected_labels[12:14], 'NRMSe RV'] = feature_importance.loc[selected_labels[12:14],'NRMSe']\n",
    "'''\n",
    "feature_importance_RV = pd.concat([feature_importance_RV,feature_importance.iloc[best_features:, 0]*0])\n",
    "\n",
    "\n",
    "sns.barplot(x = feature_importance_RV[\"Relative Importance\"], \n",
    "            y = feature_importance_RV[\"Relative Importance\"].index,\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 16)))\n",
    "\n",
    "sns.barplot(x = feature_importance_RV[0], \n",
    "            y = feature_importance_RV[0].index,\n",
    "            color='grey')\n",
    "\n",
    "ax.set_ylabel('')\n",
    "ax.set_xlabel('score')\n",
    "\n",
    "# Turn frame off\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.savefig(dir_p/'fig'/\"presentation\" /\"fig_p2cc.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9dc894",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "\n",
    "    \n",
    "tectonics_shp_main = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "labels_main = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "              if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "\n",
    "tectonics_shp_sub = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "                    and 'gmt' in filename]\n",
    "labels_sub = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics') \n",
    "             if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "             and 'gmt' in filename]\n",
    "\n",
    "volc_erup = pd.read_csv(dir_p/'GMT'/'tectonics'/'volcanic_eruptions.dat', sep='\\s')\n",
    "# congo co KA kalhari\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=2,\n",
    "    ncols=3,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['A)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"0.6c\"], # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    sharex=\"b\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    frame=\"lrtb\",\n",
    "):\n",
    "\n",
    "\n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/120',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame='WnSe', panel=[0, 0])\n",
    "\n",
    "\n",
    "        '''\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"A Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"c0.21c\")\n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "            cmap=False, label=f'\"B Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"t0.23c\")   \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"C Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"s0.23c\") \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"D Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"h0.23c\") \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             cmap=False, label=f'\"Z Ratings\"',\n",
    "                      pen=\"0.5p\", style=\"d0.23c\")\n",
    "        \n",
    "        \n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='green', label='\"GHF > 200\\t[mW/m@+2@+]\"',\n",
    "                      pen=\"0.5p\", style=\"t0.24c\")\n",
    "                      \n",
    "        '''\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            land='darkgrey'\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "                    \n",
    "           \n",
    "\n",
    "       \n",
    "        fig.plot(x=hf_no_pole_afr.longitude.values, y=hf_no_pole_afr.latitude.values,  \n",
    "                 cmap=True, projection=proj,\n",
    "             color=hf_no_pole_afr[target].values, #label=\"'C Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"d0.19c\")\n",
    "        \n",
    "        '''\n",
    "        fig.plot(x=hf_final_a.lon, y=hf_final_a.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_a[target], #label=f\"'A Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"c0.20c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_b.lon, y=hf_final_b.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_b[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"t0.21c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_c.lon, y=hf_final_c.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_c[target], #label=\"'C Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"s0.21c\") \n",
    "        \n",
    "        fig.plot(x=hf_final_d.lon, y=hf_final_d.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_d[target], #label=\"'C Rating'\",\n",
    "                      pen=\"0.1p,black\", style=\"h0.21c\")'''       \n",
    "\n",
    "        fig.colorbar(frame=[\"af\", \"x+lGHF\\t[mW/m@+2@+]\\t\\t(Lucazeau,\\t2019)\"], \n",
    "                     position=f\"g{str(afr_lon_max +10)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "\n",
    "    #fig.legend(position=\"g-23/-15\", box=False, )\n",
    "\n",
    "    #fig.legend(position=\"g-19/-19+w4/2.8\", box='+gwhite', transparency=30)\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/'presentation'/\"fig_p1b.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801dad56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "file_label  ='OD_IDW_rab'\n",
    "\n",
    "#### training\n",
    "tarin_Afr_f =  dir_p/ 'data'/'dataset'/'Preprocessed'/f'Training_Afr_50_{file_label}.csv'\n",
    "\n",
    "\n",
    "train = pd.read_csv(tarin_Afr_f, sep='\\t')\n",
    "\n",
    "X = train[features_idw]\n",
    "y = train[target]\n",
    "\n",
    "X['GLIM']  = X['GLIM'].astype('int').astype('category')\n",
    "X['REG']  = X['REG'].astype('int').astype('category')\n",
    "\n",
    "\n",
    " \n",
    "kfold = 10 \n",
    "\n",
    "\n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) \n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "ccc_score = make_scorer(concordance_correlation_coefficient , greater_is_better=True)\n",
    "\n",
    "scoring = {\n",
    "    '$NRMSe$':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    '$R^2$':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'$p_c$': ccc_score,    \n",
    "}\n",
    "\n",
    "\n",
    "results ={}\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "regressor.set_params(**tuned_params)\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "\n",
    "\n",
    "\n",
    "    # Initialize RFECV object\n",
    "    feature_selector = RFECV(regressor, cv = cv, step = 1, #n_jobs=-1, \n",
    "                             scoring = score, verbose = 1)\n",
    "\n",
    "    # Fit RFECV\n",
    "    feature_selector.fit(X, np.ravel(y))\n",
    "    results[key] = feature_selector\n",
    "\n",
    "    # Get selected features\n",
    "    #feature_names = X_train_corr.columns\n",
    "    #selected_features = feature_names[feature_selector.support_].tolist()\n",
    "\n",
    "    print(f'terminated {key} {score}\\n')\n",
    "    print('terminated')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33183cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = 10 \n",
    "cv = KFold(n_splits=kfold, random_state=None, shuffle=True)\n",
    "\n",
    "KPI_Feature = pd.DataFrame()\n",
    "KPI_Feature_CV = pd.DataFrame()\n",
    "results_feature_CV = pd.DataFrame()\n",
    "\n",
    "# Define a function to calculate negative RMSE (as a score)\n",
    "def nrmse(y_true, y_pred):\n",
    "    cost  = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return cost/(y_true.mean()) *-1\n",
    "\n",
    "\n",
    "#scoring = make_scorer(nrmse , greater_is_better=False )\n",
    "nrmse_score = make_scorer(nrmse , greater_is_better=False)\n",
    "\n",
    "\n",
    "scorings = [ make_scorer(nrmse, greater_is_better=False),\n",
    "            #make_scorer(mean_absolute_percentage_error,  greater_is_better=False),\n",
    "            make_scorer(r2_score, greater_is_better=True),\n",
    "            #make_scorer(explained_variance_score, greater_is_better=True),\n",
    "            #make_scorer(concordance_correlation_coefficient, greater_is_better=True),\n",
    "           ]\n",
    "scores_titles = ['$NRMSe$', '$R^2$']\n",
    "for feature in features_idw:  \n",
    "    print(feature)\n",
    "    \n",
    "    if feature in ['REG','GLIM']:\n",
    "        X_train_afr_feature = X[feature].cat.codes\n",
    "    else:\n",
    "        X_train_afr_feature = X[feature]\n",
    "    \n",
    "    regressor = RandomForestRegressor()\n",
    "\n",
    "    tuned_params = {item[11:]: best_params[item][0] for item in best_params}\n",
    "    regressor.set_params(**tuned_params)\n",
    "\n",
    "    scaler = PowerTransformer(method='yeo-johnson',standardize=True)\n",
    "\n",
    "\n",
    "    numeric_transformer = scaler\n",
    "\n",
    "    categorical_transformer = OrdinalEncoder(handle_unknown='use_encoded_value' , unknown_value =-1)\n",
    "\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "       (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n",
    "            (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n",
    "        ]\n",
    "    )\n",
    "    # Append classifier to preprocessing pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    steps=[(\"preprocessor\", preprocessor), (\"regressor\", regressor)]\n",
    "\n",
    "    \n",
    "    # Initialize Pipeline object\n",
    "    pipeline= Pipeline(steps = steps)\n",
    "\n",
    "    model_pipeline = TransformedTargetRegressor(regressor=pipeline, transformer=scaler)\n",
    "    '''\n",
    "\n",
    "    for score_title,  scoring in zip(scores_titles, scorings):\n",
    "        score = cross_val_score(model_pipeline, X_train_afr_feature, y_train_afr, \n",
    "                                  cv=5)\n",
    "\n",
    "\n",
    "        KPI_Feature_CV.loc[score_title, f'RFE_{best_features}'] = score.mean()\n",
    "    '''\n",
    "    regressor.fit(X_train_afr_feature.values.reshape(-1, 1), y.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    y_predict = regressor.predict(X_train_afr_feature.values.reshape(-1, 1))\n",
    "\n",
    "\n",
    "    KPI_Feature.loc['$NRMSe$', f'{feature}'] = nrmse(y, y_predict) *-1\n",
    "    #KPI_Feature.loc['MAPE', f'{feature}'] = mean_absolute_percentage_error(y, y_predict) \n",
    "    KPI_Feature.loc['$R^2$', f'{feature}'] = r2_score(y, y_predict)\n",
    "    #KPI_Feature.loc['EV', f'{feature}'] = explained_variance_score(y, y_predict)\n",
    "    #KPI_Feature.loc['CCC', f'{feature}'] = concordance_correlation_coefficient(y, y_predict)\n",
    "\n",
    "\n",
    "    for score_title,  scoring in zip(scores_titles, scorings):\n",
    "        score = cross_val_score(regressor, \n",
    "                                X_train_afr_feature.values.reshape(-1, 1), \n",
    "                                y.values.reshape(-1, 1),\n",
    "                                scoring=scoring,\n",
    "                                  cv=cv)\n",
    "\n",
    "\n",
    "        if score_title in ['MAPE']:\n",
    "            KPI_Feature_CV.loc[score_title, f'{feature}'] = score.mean() * -1\n",
    "        else:\n",
    "            KPI_Feature_CV.loc[score_title, f'{feature}'] = score.mean()\n",
    "\n",
    "            \n",
    "\n",
    "print('terminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "KPI_Feature_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275c7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e02d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "# Set figure size and create barplot\n",
    "#sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "scoring = {\n",
    "    '$NRMSe$':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    '$R^2$':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'$p_c$': ccc_score,    \n",
    "}\n",
    "\n",
    "# Load hyper parameter \n",
    "sns.set(style='whitegrid',  font_scale = 4)\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X, y).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X[selected_features],y)\n",
    "\n",
    "obs_cp = obs.copy()\n",
    "obs_selected = obs_cp.set_index('OBS_REF_IDW')\n",
    "\n",
    "selected_labels = obs_selected.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"Observables\"])\n",
    "\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "feature_importance[\"OBS_REF_IDW\"] = obs_selected.loc[selected_features , 'LABELS'].index\n",
    "\n",
    "feature_importance = feature_importance.set_index('OBS_REF_IDW')\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "feature_importance['NRMSe']   = KPI_Feature_CV.T['$NRMSe$']\n",
    "feature_importance['$R^2$']   = KPI_Feature_CV.T['$R^2$']\n",
    "\n",
    "feature_importance = feature_importance.set_index('Observables')\n",
    "\n",
    "###\n",
    "\n",
    "\n",
    "\n",
    "selected_labels = feature_importance.index.to_list()\n",
    "feature_importance['$R^2$ RV'] = 0\n",
    "feature_importance.loc[selected_labels[12], '$R^2$ RV'] = feature_importance.loc[selected_labels[12],'$R^2$']\n",
    "feature_importance['NRMSe RV'] = 0\n",
    "feature_importance.loc[selected_labels[12], 'NRMSe RV'] = feature_importance.loc[selected_labels[12],'NRMSe']\n",
    "feature_importance.loc[selected_labels[14:], '$R^2$ RV'] = feature_importance.loc[selected_labels[14:],'$R^2$']\n",
    "feature_importance.loc[selected_labels[14:], 'NRMSe RV'] = feature_importance.loc[selected_labels[14:],'NRMSe']\n",
    "\n",
    "\n",
    "feature_importance['$R^2$ REG'] = 0\n",
    "feature_importance.loc[selected_labels[15], '$R^2$ REG'] = feature_importance.loc[selected_labels[15],'$R^2$']\n",
    "feature_importance['NRMSe REG'] = 0\n",
    "feature_importance.loc[selected_labels[15], 'NRMSe REG'] = feature_importance.loc[selected_labels[15],'NRMSe']\n",
    "\n",
    "feature_importance['Relative Importance REG'] = 0\n",
    "feature_importance.loc[selected_labels[15], 'Relative Importance REG'] = feature_importance.loc[selected_labels[15],'Relative Importance']\n",
    "\n",
    "\n",
    "feature_importance['Optimal'] = 0\n",
    "feature_importance.loc[selected_labels[:11], 'Optimal'] = feature_importance.loc[selected_labels[:11],'Relative Importance']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02692324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "fig, ax = plt.subplots(1,2, figsize=(30, 13),gridspec_kw={'width_ratios': [2, 1.2]})\n",
    "\n",
    "###\n",
    "'''\n",
    "sns.barplot(x = feature_importance['$R^2$'].values, \n",
    "            y = feature_importance['Relative Importance'].index, \n",
    "            ax=ax[0], color='lightblue',\n",
    "            )\n",
    "\n",
    "\n",
    "sns.barplot(x = feature_importance['NRMSe'].values, \n",
    "            y = feature_importance['Relative Importance'].index, \n",
    "            ax=ax[0], color='orange', label='$NRMSe$',\n",
    "            )\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "sns.barplot(x = feature_importance['NRMSe RV'].values, \n",
    "            y = feature_importance['Relative Importance'].index, \n",
    "            ax=ax[0], color='orange', \n",
    "            )\n",
    "\n",
    "sns.barplot(x = feature_importance['$R^2$ RV'].values, \n",
    "            y = feature_importance['Relative Importance'].index, \n",
    "            ax=ax[0], color='lightblue', label='$R^2$',\n",
    "            )\n",
    "\n",
    "sns.barplot(x = feature_importance[\"Relative Importance\"].values, \n",
    "            y = feature_importance[\"Relative Importance\"].index, \n",
    "            ax=ax[0],  color='lightgreen',label=f\"\"\"Relative\n",
    "importance\"\"\"\n",
    "                    )\n",
    "\n",
    "####\n",
    "\n",
    "sns.barplot(x = feature_importance['NRMSe REG'].values, \n",
    "            y = feature_importance['Relative Importance'].index, \n",
    "            ax=ax[0], color='orange',\n",
    "            )\n",
    "\n",
    "\n",
    "sns.barplot(x = feature_importance['$R^2$ REG'].values, \n",
    "            y = feature_importance['Relative Importance'].index, \n",
    "            ax=ax[0], color='lightblue',\n",
    "            )\n",
    "\n",
    "sns.barplot(x = feature_importance[\"Relative Importance REG\"].values, \n",
    "            y = feature_importance[\"Relative Importance\"].index, \n",
    "            ax=ax[0],  color='lightgreen',\n",
    "                    )\n",
    "'''\n",
    "###\n",
    "\n",
    "sns.barplot(x = feature_importance[\"Optimal\"].values, \n",
    "            y = feature_importance[\"Optimal\"].index, \n",
    "            ax=ax[0],  color='lightgreen',\n",
    "                    )\n",
    "    \n",
    "ax[0].set_ylabel('')\n",
    "ax[0].grid(False)\n",
    "\n",
    "# Turn frame off\n",
    "ax[0].set_frame_on(False)\n",
    "ax[0].locator_params(axis='x', nbins=7)\n",
    "#ax[0].legend(loc=[.55, .6], framealpha=0.5)\n",
    "\n",
    "#ax[0].set_title(f'{sub_figs[0]})', loc ='left', pad=20, size=40,  y=1.1)\n",
    "ax[0].set_xlabel(\"Score\")\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    if key == '$NRMSe$':\n",
    "        results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "        if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "            ax[1].plot(range(1, len(results[key].grid_scores_) + 1),                  \n",
    "                       results[key].grid_scores_.mean(axis=1)*-1, color='orange', \n",
    "                       linewidth=6,label=key)\n",
    "            ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "                        results[key].grid_scores_.mean(axis=1)*-1, color='orange',\n",
    "                          s=300, marker='x')\n",
    "\n",
    "        else:\n",
    "            ax[1].plot(range(1, len(results[key].grid_scores_) + 1), \n",
    "                     results[key].grid_scores_.mean(axis=1), color='orange', linewidth=6,\n",
    "                       label=key)\n",
    "            ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "                        results[key].grid_scores_.mean(axis=1), color='orange', s=300, \n",
    "                          marker='x')\n",
    "    else:\n",
    "      \n",
    "        \n",
    "        results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "        if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "            ax[1].plot(range(1, len(results[key].grid_scores_) + 1),                  \n",
    "                       results[key].grid_scores_.mean(axis=1)*-1, color='lightblue', linewidth=6,label=key)\n",
    "            ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "                        results[key].grid_scores_.mean(axis=1)*-1, color='lightblue', s=300, marker='x')\n",
    "\n",
    "        else:\n",
    "            ax[1].plot(range(1, len(results[key].grid_scores_) + 1), \n",
    "                     results[key].grid_scores_.mean(axis=1), color='lightblue', linewidth=6,label=key)\n",
    "            ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "                        results[key].grid_scores_.mean(axis=1), color='lightblue', s=300, marker='x')\n",
    "\n",
    "ax[1].plot(range(1, len(results[key].grid_scores_) + 1), \n",
    "         feature_importance['Relative Importance'].cumsum().values, linewidth=6, label=f'''Importance''', color='lightgreen',)\n",
    "ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "            feature_importance['Relative Importance'].cumsum().values,  \n",
    "          color='lightgreen', s=300, marker='x')\n",
    "\n",
    "ax[1].set_xlabel(\"Number of geo-observables\")\n",
    "ax[1].set_xticks([ 1,3,5,7,9,11,13,15])\n",
    "ax[1].set_ylabel(\"Score\")\n",
    "ax[1].legend(loc=[.3, .18], frameon=False)\n",
    "#ax[1].legend(loc=[.01, .7])\n",
    "#plt.axvline(results[key].n_features_ ,color='r')\n",
    "#ax[1].set_title(f'{sub_figs[1]})', loc ='left', pad=20, size=40,  y=1.1)\n",
    "ax[1].locator_params(axis='y', nbins=10)\n",
    "ax[1].grid(False)\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "fig.savefig(dir_p/'fig'/'presentation'/\"fig_p6d.jpeg\", bbox_inches='tight', dpi=300 )\n",
    "#fig.savefig(dir_p/'fig'/\"fig_8.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c70e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "# Set figure size and create barplot\n",
    "#sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(1,2, figsize=(18, 8))\n",
    "\n",
    "best_features = 16\n",
    "\n",
    "scoring = {\n",
    "    '$NRMSe$':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    '$R^2$':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'$p_c$': ccc_score,    \n",
    "}\n",
    "# Load hyper parameter \n",
    "sns.set(style='whitegrid',  font_scale = 2.2)\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X, y).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X[selected_features],y)\n",
    "\n",
    "obs.reset_index()\n",
    "obs_selected = obs.set_index('OBS_REF_IDW')\n",
    "\n",
    "selected_labels = obs_selected.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"Observables\"])\n",
    "feature_importance = feature_importance.set_index('Observables')\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "\n",
    "sns.barplot(x = feature_importance[\"Relative Importance\"].values, \n",
    "            y = feature_importance[\"Relative Importance\"].index, ax=ax[0],\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 16)),  data = feature_importance)\n",
    "\n",
    "\n",
    "ax[0].set_ylabel('')\n",
    "\n",
    "\n",
    "# Turn frame off\n",
    "ax[0].set_frame_on(False)\n",
    "ax[0].locator_params(axis='x', nbins=7)\n",
    "\n",
    "\n",
    "ax[0].set_title(f'{sub_figs[0]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "    if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "        ax[1].plot(range(1, len(results[key].grid_scores_) + 1),                  results[key].grid_scores_.mean(axis=1)*-1, label=key)\n",
    "        ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "                    results[key].grid_scores_.mean(axis=1)*-1, marker='x')\n",
    "\n",
    "    else:\n",
    "        ax[1].plot(range(1, len(results[key].grid_scores_) + 1), \n",
    "                 results[key].grid_scores_.mean(axis=1), label=key)\n",
    "        ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "                    results[key].grid_scores_.mean(axis=1), marker='x')\n",
    "        \n",
    "ax[1].plot(range(1, len(results[key].grid_scores_) + 1), \n",
    "         feature_importance['Relative Importance'].cumsum().values, label=f'''Cumulative\n",
    "importance''')\n",
    "ax[1].scatter(range(1, len(results[key].grid_scores_) + 1), \n",
    "            feature_importance['Relative Importance'].cumsum().values, marker='x')\n",
    "\n",
    "ax[1].set_xlabel(\"Number of geo-observables\")\n",
    "ax[1].set_xticks([ 1,3,5,7,9,11,13,15])\n",
    "ax[1].set_ylabel(\"Score\")\n",
    "ax[1].legend(loc=[.56, .21])\n",
    "#plt.axvline(results[key].n_features_ ,color='r')\n",
    "ax[1].set_title(f'{sub_figs[1]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "\n",
    "\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "#fig.savefig(dir_p/ 'fig'/\"fig_5.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c84e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance \n",
    "# Get selected features data set\n",
    "# should be scaled\n",
    "\n",
    "sub_figs = list('ABCDEFGHIJKLMNOPQRSTUVWXYZ')\n",
    "\n",
    "# Set figure size and create barplot\n",
    "#sns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.8)\n",
    "fig, ax = plt.subplots(1,2, figsize=(18, 8))\n",
    "\n",
    "best_features = 12\n",
    "\n",
    "scoring = {\n",
    "    '$NRMSe$':nrmse_score,\n",
    "    #'RMSE':'neg_root_mean_squared_error', \n",
    "    #'MAE':'neg_mean_absolute_error', \n",
    "    #'MAPE':'neg_mean_absolute_percentage_error', \n",
    "    '$R^2$':'r2',\n",
    "    #'EV':'explained_variance'   \n",
    "    #'$p_c$': ccc_score,    \n",
    "}\n",
    "# Load hyper parameter \n",
    "sns.set(style='whitegrid',  font_scale = 2.2)\n",
    "\n",
    "rfe = RFE(regressor, n_features_to_select = best_features, step = 1, verbose = 1)\n",
    "selected_features = rfe.fit(X, y).get_feature_names_out()\n",
    "\n",
    "\n",
    "regressor.fit(X[selected_features],y)\n",
    "\n",
    "obs.reset_index()\n",
    "obs_selected = obs.set_index('OBS_REF_IDW')\n",
    "\n",
    "selected_labels = obs_selected.loc[selected_features , 'LABELS'].values\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame(selected_labels, columns = [\"Covaraite\"])\n",
    "feature_importance[\"Relative Importance\"] = regressor.feature_importances_\n",
    "\n",
    "# Sort by feature importance\n",
    "feature_importance = feature_importance.sort_values(by=\"Relative Importance\", ascending=False)\n",
    "\n",
    "\n",
    "sns.barplot(x = \"Relative Importance\", y = \"Covaraite\", ax=ax[0],\n",
    "            palette = reversed(sns.color_palette('YlOrRd', 16)),  data = feature_importance)\n",
    "\n",
    "\n",
    "ax[0].set_ylabel('')\n",
    "\n",
    "\n",
    "# Turn frame off\n",
    "ax[0].set_frame_on(False)\n",
    "ax[0].locator_params(axis='x', nbins=7)\n",
    "\n",
    "\n",
    "ax[0].set_title(f'{sub_figs[0]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "\n",
    "\n",
    "\n",
    "for key, score in scoring.items():\n",
    "    #selected_features = feature_names[results[key].support_].tolist()\n",
    "    # Get Performance Data\n",
    "    print(f\"Optimal number of features for {key} : {results[key].n_features_}\")\n",
    "    results[key].support_rfecv_df = pd.DataFrame(results[key].ranking_,index=X.columns,columns=['Rank']).sort_values(by='Rank',ascending=True)\n",
    "    if results[key].grid_scores_.mean(axis=1).min() < 0:\n",
    "        ax[1].plot(range(1, best_features + 1),  results[key].grid_scores_.mean(axis=1)[:best_features]*-1, label=key)\n",
    "        ax[1].scatter(range(1, best_features + 1), \n",
    "                    results[key].grid_scores_.mean(axis=1)[:best_features]*-1, marker='x')\n",
    "\n",
    "    else:\n",
    "        ax[1].plot(range(1, best_features + 1), \n",
    "                 results[key].grid_scores_.mean(axis=1)[:best_features], label=key)\n",
    "        ax[1].scatter(range(1, best_features + 1), \n",
    "                    results[key].grid_scores_.mean(axis=1)[:best_features], marker='x')\n",
    "        \n",
    "ax[1].plot(range(1, best_features + 1), \n",
    "         feature_importance['Relative Importance'].cumsum()[:best_features].values, label=f'''Cumulative\n",
    "importance''')\n",
    "ax[1].scatter(range(1, best_features + 1), \n",
    "            feature_importance['Relative Importance'].cumsum()[:best_features].values, marker='x')\n",
    "\n",
    "ax[1].set_xlabel(\"Number of geo-observables\")\n",
    "ax[1].set_xticks([ 1,3,5,7,9,11,13,15])\n",
    "ax[1].set_ylabel(\"Score\")\n",
    "ax[1].legend(loc=[.56, .21])\n",
    "#plt.axvline(results[key].n_features_ ,color='r')\n",
    "ax[1].set_title(f'{sub_figs[1]})', loc ='left', pad=20, size=20,  y=1.1)\n",
    "\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Save Figure\n",
    "#fig.savefig(\"fig_5.jpeg\", bbox_inches='tight', dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452f5fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region_gmt= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "\n",
    "    \n",
    "tectonics_shp_main = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "labels_main = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "              if filename in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']]\n",
    "\n",
    "tectonics_shp_sub = [dir_p/'GMT'/'tectonics'/f'{filename}' \\\n",
    "         for filename in os.listdir(dir_p/'GMT'/'tectonics')\n",
    "                   if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "                    and 'gmt' in filename]\n",
    "labels_sub = [filename[:-4]  for filename in os.listdir(dir_p/'GMT'/'tectonics') \n",
    "             if filename not in ['CC.gmt', 'BB.gmt', 'WAC.gmt', 'SMC.gmt', 'KA.gmt', 'AAO.gmt', 'RTA.gmt']\n",
    "             and 'gmt' in filename]\n",
    "\n",
    "volc_erup = pd.read_csv(dir_p/'GMT'/'tectonics'/'volcanic_eruptions.dat', sep='\\s')\n",
    "# congo co KA kalhari\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=1,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['C)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"0c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    #sharex=\"bt\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    #frame=\"WSrt\",\n",
    "):\n",
    "\n",
    "\n",
    "    cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/130',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "    \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        fig.basemap(region=region_gmt, projection=proj, frame=True,  panel=[0, 0])\n",
    "       \n",
    "        ''' \n",
    "        fig.plot(x=0, y=0,  projection=proj, cmap=False,\n",
    "              label='\"Residual GHF\"',\n",
    "                      pen=\"0.5p\", style=\"c0.21c\")\n",
    "        '''\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='green', label='\"GHF > 200\\t[mW/m@+2@+]\"',\n",
    "                      pen=\"0.5p\", style=\"t0.24c\")\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            #water=\"lightblue\", \n",
    "            shorelines=\"1p,black\",\n",
    "            borders=[\"1/0.2p,black\"],\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RK_rab_lr, region=region_gmt, spacing=spacing)\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region_gmt,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             frame=True,\n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        for shape, label in zip(tectonics_shp_sub, labels_sub):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1,white,--')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "            #fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, font='15' ,text=label, justify=\"ML\")\n",
    "            \n",
    "        \n",
    "        \n",
    "        for shape, label in zip(tectonics_shp_main, labels_main):\n",
    "            shape_xy = pd.read_csv(shape, header=None, sep='\\s')\n",
    "            fig.plot(x=shape_xy.iloc[:,0], y=shape_xy.iloc[:,1], projection=proj,  region=region_gmt,   pen='1.5,white')      \n",
    "                          #pen=\"1p,red,--\", style=\"c0.01i\")\n",
    "                \n",
    "            if label == 'RTA':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()-10, y=shape_xy.iloc[:,1].median()+0.5, \n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            elif label == 'AAO':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()+2, y=shape_xy.iloc[:,1].median()+2,\n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "            elif label == 'BB':\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()-3, y=shape_xy.iloc[:,1].median(),\n",
    "                         font='15' ,text=label, justify=\"ML\")\n",
    "\n",
    "            else:\n",
    "                fig.text(x=shape_xy.iloc[:,0].min()+4, y=shape_xy.iloc[:,1].median()-2, \n",
    "                         font='15' ,text=label, justify=\"ML\")'''\n",
    "        '''\n",
    "        fig.plot(x=volc_erup.Lon, y=volc_erup.Lat,  projection=proj,\n",
    "             color='white', label=f'\"Eruptions\"',\n",
    "                      pen=\"0.5p\", style=\"a0.25c\")'''\n",
    "        \n",
    "\n",
    "\n",
    "        '''\n",
    "        fig.plot(x=hf_final_a.lon, y=hf_final_a.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_a[target], #label=f\"'A Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_b.lon, y=hf_final_b.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_b[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        fig.plot(x=hf_final_c.lon, y=hf_final_c.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_c[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "        \n",
    "        fig.plot(x=hf_final_d.lon, y=hf_final_d.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_d[target], #label=\"'B Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.19c\")\n",
    "       \n",
    "        fig.plot(x=hf_no_pole_afr.longitude.values, y=hf_no_pole_afr.latitude.values,  \n",
    "                 cmap=True, projection=proj,\n",
    "             color=hf_no_pole_afr[target].values, #label=\"'C Rating'\",\n",
    "                      pen=\"0.5p,black\", style=\"c0.16c\")\n",
    "        '''\n",
    "        fig.plot(x=lon_hf_extreme , y=lat_hf_extreme ,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "        '''\n",
    "        \n",
    "        fig.text(text=\"_\", x=-19, y=-4, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Major Cratons\", x=-8, y=-4, font=\"13p,Helvetica,black\")\n",
    "        fig.text(text=\"KA : Kalhari Cr.\", x=-11, y=-7, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"CC : Congo Cr.\", x=-11, y=-10, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"RTA :\", x=-11, y=-13, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"BB :\", x=-8, y=-16, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"WAC : W. African Cr.\", x=-7, y=-19, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"SMC : Sah. Metacr.\", x=-8, y=-22, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"AAO :\", x=-8, y=-25, font=\"14p,Helvetica,black\")\n",
    "        fig.text(text=\"--\", x=-19, y=-28, font=\"25p,Helvetica,white\")\n",
    "        fig.text(text=\"Minor Cratons\", x=-8, y=-28, font=\"14p,Helvetica,black\") '''   \n",
    "\n",
    "        '''\n",
    "        cmap= pygmt.makecpt(\n",
    "                    cmap='vik', #temp 19lev\n",
    "                    series=f\"-30/30/3\",\n",
    "                    continuous=True,\n",
    "                    reverse=False,\n",
    "                )'''\n",
    "\n",
    "        '''\n",
    "        fig.plot(x=gt_Afr_50_rb_lr_lon, y=gt_Afr_50_rb_lr_lat,   cmap=True, projection=proj,\n",
    "                             size= 0.5 * abs((resid_rb_lr-resid_rb_lr.min())/(resid_rb_lr.max() - resid_rb_lr.min())),    \n",
    "                 color=  resid_rb_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"cc\")'''\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            #water=\"lightblue\", \n",
    "            shorelines=\"1p,black\",\n",
    "            borders=[\"1/0.2p,black\"],\n",
    "            land='darkgrey'\n",
    "           \n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\", \"x+lGHF\\t[mW/m@+2@+]\\t\\t(Lucazeau,\\t2019)\"], \n",
    "                     position=f\"g{str(afr_lon_max +10)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "        #fig.legend(position=\"g29.1/40+w4.7/1\", box='+gwhite', transparency=30)\n",
    "        fig.legend(position=\"g-23/0+w4.7/1\", box='+gwhite', transparency=30)\n",
    "\n",
    "   \n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/'presentation'/\"fig_p17f.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8259b95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# Calculate mean depth in km from all events within 40x40 minute\n",
    "# bins using blockmean\n",
    "\n",
    "# convert to grid\n",
    "#R region I spacing\n",
    "\n",
    "# Set the region for the plot\n",
    "\n",
    "# Define spacing in x and y direction (40 by 40 minute blocks)\n",
    "spacing = \"0.5\"\n",
    "\n",
    "#proj=f\"l135/-25/-45/-10/2c\"\n",
    "region= [afr_lon_min, afr_lon_max,afr_lat_min, afr_lat_max]\n",
    "proj = 'M5.4i'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = pygmt.Figure()\n",
    "with fig.subplot(\n",
    "    nrows=3,\n",
    "    ncols=2,\n",
    "    #figsize=(\"30c\", \"15c\"),  # width of 15 cm, height of 6 cm\n",
    "    subsize = (\"13.5c\", \"13.5c\"),\n",
    "    #autolabel=['A)+o0.3/-1.2'],\n",
    "    margins=[\"0c\", \"2.4c\"],  # horizontal 0.3 cm and vertical 0.2 cm margins\n",
    "    #title=model[3:],\n",
    "    #sharex=\"bt\",  # shared x-axis on the bottom side\n",
    "    sharey=True,  # shared y-axis on the left side\n",
    "    #frame=\"WSrt\",\n",
    "):\n",
    "\n",
    "\n",
    "    '''      \n",
    "    with fig.set_panel(panel=[0, 0]):\n",
    "\n",
    "\n",
    "        cmap = pygmt.makecpt(\n",
    "            cmap='inferno', #temp 19lev\n",
    "            series='0/50/10',\n",
    "            continuous=True,\n",
    "            reverse=True,)\n",
    "\n",
    "\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='WsNe',  panel=[0, 0])\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_RSD_rab_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "                #frame=[\"+LGHF\", \"xaf\", \"y+l(%)\"]\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lCV\\tof\\tGHF\\t[mW/m@+2@+]\"],\n",
    "           position=f\"g{str(afr_lon_max +10)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "        \n",
    "        \n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "        \n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap=dir_p/'GMT'/'temperature.cpt', #temp 19lev\n",
    "        #cmap='lajolla',\n",
    "            series='40/130',\n",
    "            #truncate = '40/140',\n",
    "            #continuous=True,\n",
    "            reverse=False,\n",
    "        )\n",
    "      \n",
    "        fig.plot(x=hf_final_a.lon, y=hf_final_a.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_a[target], transparency =50,\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        fig.plot(x=hf_final_b.lon, y=hf_final_b.lat,  cmap=True, projection=proj,\n",
    "             color=hf_final_b[target],transparency =50,\n",
    "                      pen=\"0.5p,black\", style=\"c0.21c\")\n",
    "        \n",
    "        fig.colorbar(frame=[\"af\",  \"x+lGHF\\t[mW/m@+2@+]\"],\n",
    "               position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-7)}+w13c/0.5c+h+e\")\n",
    "\n",
    "    '''\n",
    "        \n",
    "    with fig.set_panel(panel=[0, 0] ):\n",
    "        #####RL\n",
    "\n",
    "        cmap= pygmt.makecpt(\n",
    "            cmap='davos', #temp 19lev\n",
    "            series=f\"0/20/1\",\n",
    "            continuous=True,\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        fig.basemap(region=region, projection=proj, frame='eNsw',   panel=[0, 0])\n",
    "        '''\n",
    "        fig.plot(x=0, y=0,  projection=proj,\n",
    "             color='green', label='\"GHF > 200\\t[mW/m@+2@+]\"',\n",
    "                      pen=\"0.5p\", style=\"t0.24c\")\n",
    "        fig.plot(x=0, y=0,  projection=proj, cmap=False,\n",
    "              label='\"Residual of GHF\"',\n",
    "                      pen=\"0.5p\", style=\"c0.21c\")'''\n",
    "\n",
    "\n",
    "        df_gmt = pygmt.blockmean(data=data_UNC_rab_lr, region=region, spacing=spacing)\n",
    "\n",
    "        grd = pygmt.surface(\n",
    "             data=df_gmt, # xarray.DataArray containing VSV values\n",
    "        spacing=spacing\n",
    "        )\n",
    "\n",
    "        dgrid = pygmt.grdgradient(grid=grd, azimuth=0/270, normalize=0.6)\n",
    "\n",
    "        fig.grdimage(\n",
    "             grid=grd, # xarray.DataArray containing VSV values\n",
    "             region=region,\n",
    "             projection=proj,\n",
    "                 cmap=cmap,\n",
    "             \n",
    "            #shading='+a45+nt0.5'\n",
    "            shading=dgrid\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        fig.coast(\n",
    "            projection=proj,\n",
    "            #shorelines=0.5,\n",
    "            water=\"lightblue\", \n",
    "            shorelines=\"0.1p,black\",\n",
    "            borders=[\"1/0.1p,black\"],\n",
    "            lakes=\"lightblue\",\n",
    "            rivers=\"lightblue\" ,\n",
    "            #water='white',\n",
    "            )\n",
    "\n",
    "        fig.colorbar(frame=[\"af\",  \"x+lUncertainity\\tof\\tGHF\\t[mW/m@+2@+]\"],\n",
    "                 position=f\"g{str(afr_lon_max +10)}/{str(afr_lat_min+1)}+w15c/0.5c+v+e\")\n",
    "        \n",
    "        \n",
    "        cmap= pygmt.makecpt(\n",
    "                    cmap='vik', #temp 19lev\n",
    "                    series=f\"-30/30/3\",\n",
    "                    continuous=True,\n",
    "                    reverse=False,\n",
    "                )\n",
    "\n",
    "\n",
    "        '''\n",
    "        fig.plot(x=gt_Afr_50_rab_lr_lon, y=gt_Afr_50_rab_lr_lat,   cmap=True, projection=proj,                                \n",
    "                 color=  resid_rab_lr , label=cmap,\n",
    "                              pen=\"1p,black\", style=\"c0.24c\")  '''    \n",
    "        '''\n",
    "        fig.plot(x=lon_hf_extreme_a, y=lat_hf_extreme_a,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")\n",
    "        fig.plot(x=lon_hf_extreme_b, y=lat_hf_extreme_b,    projection=proj,                               \n",
    "                 color=  'green' ,         pen=\"1p,black\", style=\"t0.24c\")'''\n",
    "\n",
    "        \n",
    "        fig.colorbar(frame=[\"af\",  \"x+lResidual\\tof\\tGHF\\t[mW/m@+2@+]\"],\n",
    "               position=f\"g{str(afr_lon_min-2)}/{str(afr_lat_min-7)}+w13c/0.5c+h+e\")\n",
    "        \n",
    "        fig.legend(position=\"g-23/-10\", box=False)\n",
    "        \n",
    "\n",
    "fig.show(width=800)\n",
    "\n",
    "fig.savefig(dir_p/'fig'/'presentation'/\"fig_p16c.jpg\", dpi=300 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d99edab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
